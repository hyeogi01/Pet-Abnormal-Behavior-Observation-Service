"""
dog_abnormal_omni_train.py
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ê°•ì•„ì§€ ì´ìƒ ì¦ìƒ ë¶„ë¥˜ ëª¨ë¸ (Skin / Eyes)

[í´ëž˜ìŠ¤ ë³€ê²½]
  Eyes 11 â†’ 9í´ëž˜ìŠ¤:
    - dog_ê¶¤ì–‘ì„±ê°ë§‰ì§ˆí™˜ + dog_ë¹„ê¶¤ì–‘ì„±ê°ë§‰ì§ˆí™˜ â†’ dog_ê°ë§‰ì§ˆí™˜ (í†µí•©)
    - dog_ë°±ë‚´ìž¥ ì œê±° (í•µê²½í™”ì™€ ì‹œê°ì  êµ¬ë¶„ ë¶ˆê°€, JSON age ì—†ì´ ë¶ˆê°€)

[JSON ì „ëžµ]
  í•™ìŠµ ì‹œ:
    normal class â†’ feat = zeros (JSON ì œê³µ ì•ˆ í•¨)
    disease class â†’ feat = ì‹¤ì œ JSON ê°’
                  + JSON Modality Dropout(p=0.5):
                    50% í™•ë¥ ë¡œ featë¥¼ zerosë¡œ ëŒ€ì²´
  ì¶”ë¡  ì‹œ:
    ëª¨ë“  class â†’ feat = zeros (JSON ì—†ìŒ)
    â†’ í•™ìŠµì—ì„œ zeros ìƒí™©ì„ ì¶©ë¶„ížˆ ê²½í—˜ â†’ robust

[Modality Dropout ê·¼ê±°]
  - ì´ë¯¸ì§€ íŠ¹ì§•ì´ ì£¼ ë¶„ë¥˜ ê·¼ê±°ë¡œ ê°•ì œë¨
  - JSONì€ í•™ìŠµ ì‹œ refinement ì‹ í˜¸ë¡œë§Œ ê¸°ì—¬
  - normal(zeros) + disease(50% zeros) â†’ "zeros = no info" ì²´ê³„ì  í•™ìŠµ
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"""

import os, gc, json, random, shutil
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision.transforms as transforms
import matplotlib.pyplot as plt

from PIL import Image, ImageFile
from torch.utils.data import Dataset, DataLoader
from torchvision.models import efficientnet_v2_s, EfficientNet_V2_S_Weights
import torch.optim.lr_scheduler as lr_scheduler
from collections import defaultdict
from sklearn.utils.class_weight import compute_class_weight
from tqdm import tqdm

ImageFile.LOAD_TRUNCATED_IMAGES = True

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ CONFIG â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SEED = 42
random.seed(SEED); torch.manual_seed(SEED); np.random.seed(SEED)

SKIN_ROOT = "files/4_Animal_Skin"
EYES_ROOT = "files/5_Animal_Eyes"
WORK_DIR  = "files/work/dog_abnormal_dataset"

DEVICE               = "cuda:1" if torch.cuda.is_available() else "cpu"
EPOCHS               = 100
BATCH_SIZE           = 64
NUM_WORKERS          = 24
LABEL_SMOOTHING      = 0.1
LABEL_SMOOTHING_EYES = 0.05
FREEZE_EPOCHS        = 8
WEIGHT_DECAY         = 5e-4
LR_BACKBONE          = 2e-5
LR_HEAD              = 2e-4

JSON_FEAT_DIM        = 5
JSON_TRAIN_DROPOUT   = 0.5   # disease class JSONì„ 50% í™•ë¥ ë¡œ zeros ëŒ€ì²´
NORMAL_CLASS_NAMES   = {"dog_normal"}
EYES_MERGE_CLASS_CAP = 10000  # ê°ë§‰ì§ˆí™˜ í†µí•© í›„ cap

IMG_SIZE   = 384
IMG_RESIZE = 416

print(f"ðŸ¶ Dog Abnormal Omni | Device: {DEVICE}")
print(f"   Skin+Eyes: EfficientNet+JSON Fusion")
print(f"   JSON strategy: disease=real feat, normal=zeros, inference=zeros")
print(f"   JSON Modality Dropout: p={JSON_TRAIN_DROPOUT}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ BREED SETS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë‹¨ë‘ì¢…: í”¼ë¶€ì£¼ë¦„(ë†í¬Â·ë¯¸ëž€) + ì•ˆê²€ë‚´ë°˜ì¦Â·ìƒ‰ì†Œì¹¨ì°©Â·ìœ ë£¨ì¦ ìœ„í—˜
BRACHYCEPHALIC_DOGS = {
    'ì‹œì¸„', 'í¼ê·¸', 'ë¶ˆë…', 'í”„ë Œì¹˜ë¶ˆë…', 'ë³´ìŠ¤í„´í…Œë¦¬ì–´', 'íŽ˜í‚¤ë‹ˆì¦ˆ',
    'ë¼ì‚¬ì••ì†Œ', 'ì°¨ìš°ì°¨ìš°', 'ë³µì„œ', 'ë§ˆìŠ¤í‹°í”„', 'ë¶ˆë§ˆìŠ¤í‹°í”„', 'ìƒ¤íŽ˜ì´'
}
# ìœ ì „ì„± ë°±ë‚´ìž¥ ì œê±°ë¡œ ì´ ì„¸íŠ¸ëŠ” Skin breed ë‹¤ì–‘ì„±ìœ¼ë¡œ í™œìš©
# (dog_ë°±ë‚´ìž¥ í´ëž˜ìŠ¤ ì œê±°ë¨ â†’ Eyesì—ì„œëŠ” ì§ì ‘ í™œìš©ë„ ë‚®ì•„ì§€ë‚˜ feat ìœ ì§€)
HEREDITARY_CATARACT_DOGS = {
    'ê³¨ë“ ë¦¬íŠ¸ë¦¬ë²„', 'ëž˜ë¸Œë¼ë„ë¦¬íŠ¸ë¦¬ë²„', 'ì‹œë² ë¦¬ì•ˆí—ˆìŠ¤í‚¤',
    'ì•Œëž˜ìŠ¤ì¹¸ë§ë¼ë®¤íŠ¸', 'ë³´ë”ì½œë¦¬', 'ì˜¤ìŠ¤íŠ¸ë ˆì¼ë¦¬ì•ˆì…°í¼ë“œ',
    'ì½”ì»¤ìŠ¤íŒ¨ë‹ˆì–¼', 'ë¯¸ë‹ˆì–´ì²˜ìŠˆë‚˜ìš°ì €', 'í‘œì¤€í‘¸ë“¤'
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ CLASSES â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DOG_SKIN_CLASSES = [
    "dog_normal",
    "dog_ê²°ì ˆ,ì¢…ê´´",
    "dog_ë†í¬,ì—¬ë“œë¦„",
    "dog_ë¯¸ëž€,ê¶¤ì–‘",
    "dog_ë¹„ë“¬,ê°ì§ˆ,ìƒí”¼ì„±ìž”ê³ ë¦¬",
    "dog_íƒœì„ í™”,ê³¼ë‹¤ìƒ‰ì†Œì¹¨ì°©",
]  # 6í´ëž˜ìŠ¤

DOG_EYES_CLASSES = [
    "dog_normal",
    "dog_ê²°ë§‰ì—¼",
    "dog_ê°ë§‰ì§ˆí™˜",          # ê¶¤ì–‘ì„±ê°ë§‰ì§ˆí™˜ + ë¹„ê¶¤ì–‘ì„±ê°ë§‰ì§ˆí™˜ í†µí•©
    "dog_ìƒ‰ì†Œì¹¨ì°©ì„±ê°ë§‰ì—¼",
    "dog_ì•ˆê²€ë‚´ë°˜ì¦",
    "dog_ì•ˆê²€ì—¼",
    "dog_ì•ˆê²€ì¢…ì–‘",
    "dog_ìœ ë£¨ì¦",
    "dog_í•µê²½í™”",
]  # 9í´ëž˜ìŠ¤ (ë°±ë‚´ìž¥ ì œê±°, ê¶¤ì–‘ì„±/ë¹„ê¶¤ì–‘ì„± í†µí•©)

DOG_EYES_MERGE_MAP = {
    "dog_ê¶¤ì–‘ì„±ê°ë§‰ì§ˆí™˜":  "dog_ê°ë§‰ì§ˆí™˜",
    "dog_ë¹„ê¶¤ì–‘ì„±ê°ë§‰ì§ˆí™˜": "dog_ê°ë§‰ì§ˆí™˜",
}
# dog_ë°±ë‚´ìž¥ì€ MERGE_MAPì—ë„ ì—†ìŒ â†’ collect ì‹œ ì•„ì˜ˆ ìˆ˜ì§‘ ì•ˆ ë¨

EYES_SIMILAR_GROUPS = [
    ["dog_ì•ˆê²€ì—¼", "dog_ì•ˆê²€ë‚´ë°˜ì¦"],  # ì•ˆê²€ ê³„ì—´
    # [ë°±ë‚´ìž¥, í•µê²½í™”] ìŒ ì œê±° (ë°±ë‚´ìž¥ í´ëž˜ìŠ¤ ì œê±°ë¨)
]

VAL_RATIO  = 0.1
TEST_RATIO = 0.1

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ LOSS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class WeightedSmoothLoss(nn.Module):
    def __init__(self, class_names, similar_groups=None, class_weights=None,
                 smoothing=LABEL_SMOOTHING, penalty=1.5):
        super().__init__()
        self.smoothing = smoothing; self.penalty = penalty
        self.name_to_idx = {n: i for i, n in enumerate(class_names)}
        self.penalty_pairs = set()
        if similar_groups:
            for g in similar_groups:
                idxs = [self.name_to_idx[n] for n in g if n in self.name_to_idx]
                for i in range(len(idxs)):
                    for j in range(i+1, len(idxs)):
                        self.penalty_pairs.add((idxs[i], idxs[j]))
                        self.penalty_pairs.add((idxs[j], idxs[i]))
        self.register_buffer("weight", class_weights)

    def forward(self, logits, targets):
        log_p  = F.log_softmax(logits, dim=-1)
        nll    = F.nll_loss(log_p, targets, weight=self.weight, reduction="none")
        smooth = -log_p.mean(dim=-1)
        loss   = (1 - self.smoothing) * nll + self.smoothing * smooth
        if self.penalty_pairs:
            preds = logits.argmax(1)
            mask  = torch.ones(len(targets), device=logits.device)
            for b in range(len(targets)):
                if (targets[b].item(), preds[b].item()) in self.penalty_pairs:
                    mask[b] = self.penalty
            loss = loss * mask
        return loss.mean()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ BACKBONE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _efficientnet_backbone():
    b = efficientnet_v2_s(weights=EfficientNet_V2_S_Weights.IMAGENET1K_V1)
    feat = b.classifier[1].in_features  # 1280
    b.classifier = nn.Identity()
    return b, feat

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ JSON PARSING â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _parse_json_feat(json_path: str) -> np.ndarray:
    """
    5-dim: [age_norm, gender, eye_pos, is_brachycephalic, is_hereditary_cataract]

    disease class: JSON ì‹¤ì œê°’ ë°˜í™˜
    normal class / JSON ì—†ìŒ: zeros ë°˜í™˜ â†’ "no info" ì‹ í˜¸
    """
    zeros = np.zeros(5, dtype=np.float32)
    if not os.path.exists(json_path):
        return zeros
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        meta    = data.get('images', {}).get('meta', {})
        age     = float(meta.get('age', 7)) / 20.0
        gender  = float(meta.get('gender', 0))
        breed   = meta.get('breed', '')
        eye_str = meta.get('eye_position', '')
        eye_pos   = 0.0 if 'ì™¼' in eye_str else (1.0 if 'ì˜¤' in eye_str else 0.5)
        is_brachy = 1.0 if any(b in breed for b in BRACHYCEPHALIC_DOGS)       else 0.0
        is_hered  = 1.0 if any(b in breed for b in HEREDITARY_CATARACT_DOGS)  else 0.0
        return np.array([age, gender, eye_pos, is_brachy, is_hered], dtype=np.float32)
    except Exception:
        return zeros

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ MODELS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class _FusionBase(nn.Module):
    """
    EfficientNet(1280) + JSON branch(5â†’32) â†’ concat(1312) â†’ head

    JSON Modality Dropout:
      í•™ìŠµ ì‹œ(self.training=True): ë°°ì¹˜ ë‚´ ê° ìƒ˜í”Œì„ 50% í™•ë¥ ë¡œ feat zeros ì²˜ë¦¬
      ì¶”ë¡  ì‹œ(self.training=False): dropout ë¯¸ì ìš©, feat=zeros ê·¸ëŒ€ë¡œ ì‚¬ìš©
      â†’ í•™ìŠµì—ì„œ zeros ìƒí™©ì„ ì ˆë°˜ ê²½í—˜ â†’ ì¶”ë¡  ì‹œ zerosì— robust
    """
    def __init__(self, num_classes, json_feat_dim, head_hidden,
                 json_dropout_prob=JSON_TRAIN_DROPOUT):
        super().__init__()
        self.json_dropout_prob = json_dropout_prob
        self.backbone, img_feat = _efficientnet_backbone()
        self.feat_branch = nn.Sequential(
            nn.Linear(json_feat_dim, 32),
            nn.LayerNorm(32),
            nn.GELU(),
            nn.Dropout(0.1),
            nn.Linear(32, 32),
            nn.GELU(),
        )
        fused = img_feat + 32   # 1312
        layers = [nn.Dropout(0.5), nn.Linear(fused, head_hidden[0]),
                  nn.BatchNorm1d(head_hidden[0]), nn.GELU()]
        for i in range(1, len(head_hidden)):
            layers += [nn.Dropout(0.4), nn.Linear(head_hidden[i-1], head_hidden[i]),
                       nn.BatchNorm1d(head_hidden[i]), nn.GELU()]
        layers += [nn.Dropout(0.4), nn.Linear(head_hidden[-1], num_classes)]
        self.head = nn.Sequential(*layers)

    def forward(self, img, feat):
        img_f = self.backbone(img)
        if self.training and self.json_dropout_prob > 0:
            keep_mask = (
                torch.rand(feat.size(0), 1, device=feat.device)
                > self.json_dropout_prob
            ).float()
            feat = feat * keep_mask
        json_f = self.feat_branch(feat)
        return self.head(torch.cat([img_f, json_f], dim=1))


class SkinModel(_FusionBase):
    """Head: 1312â†’256â†’6 (dog 6í´ëž˜ìŠ¤)"""
    def __init__(self, num_classes, json_feat_dim=JSON_FEAT_DIM):
        super().__init__(num_classes, json_feat_dim, head_hidden=[256])


class EyesModel(_FusionBase):
    """Head: 1312â†’512â†’256â†’9 (dog 9í´ëž˜ìŠ¤, 2-hidden)"""
    def __init__(self, num_classes, json_feat_dim=JSON_FEAT_DIM):
        super().__init__(num_classes, json_feat_dim, head_hidden=[512, 256])

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ TRANSFORMS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SKIN_TRANSFORM_TRAIN = transforms.Compose([
    transforms.Resize((IMG_RESIZE, IMG_RESIZE)),
    transforms.RandomCrop(IMG_SIZE),
    transforms.RandomHorizontalFlip(),
    transforms.RandomVerticalFlip(),
    transforms.RandomRotation(degrees=90),
    transforms.ColorJitter(brightness=0.15, contrast=0.15, saturation=0.05),
    transforms.RandomAdjustSharpness(sharpness_factor=2, p=0.3),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),
    transforms.RandomErasing(p=0.2, scale=(0.02, 0.1)),
])
EYES_TRANSFORM_TRAIN = transforms.Compose([
    transforms.Resize((IMG_RESIZE, IMG_RESIZE)),
    transforms.RandomCrop(IMG_SIZE),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(15),
    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.2, hue=0.05),
    transforms.RandomApply([transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 0.5))], p=0.2),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),
])
TRANSFORM_VAL = transforms.Compose([
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),
])

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ DATASETS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class FusionDataset(Dataset):
    """
    í•™ìŠµ/ê²€ì¦ìš© ê³µìš© ë°ì´í„°ì…‹.

    normal class â†’ feat = zeros (JSON ì—†ìŒ)
    disease class â†’ feat = ì‹¤ì œ JSON ê°’ (Modality Dropoutì€ model.forwardì—ì„œ ì²˜ë¦¬)
    """
    def __init__(self, samples, transform, normal_class_names=NORMAL_CLASS_NAMES,
                 class_list=None):
        self.samples   = samples
        self.transform = transform
        self.normal_indices = set()
        if class_list:
            for i, name in enumerate(class_list):
                if name in normal_class_names:
                    self.normal_indices.add(i)

    def __len__(self): return len(self.samples)

    def __getitem__(self, idx):
        p, l = self.samples[idx]
        img  = self.transform(Image.open(p).convert("RGB"))
        if l in self.normal_indices:
            feat = np.zeros(JSON_FEAT_DIM, dtype=np.float32)
        else:
            feat = _parse_json_feat(os.path.splitext(p)[0] + ".json")
        return img, torch.tensor(feat, dtype=torch.float32), l


class InferenceDataset(Dataset):
    """
    ì¶”ë¡  ì „ìš© ë°ì´í„°ì…‹. feat = zeros (í•­ìƒ).
    í•™ìŠµ ì‹œ Modality Dropoutìœ¼ë¡œ zeros ìƒí™©ì„ ê²½í—˜í–ˆìœ¼ë¯€ë¡œ robust.
    """
    def __init__(self, samples, transform):
        self.samples   = samples
        self.transform = transform

    def __len__(self): return len(self.samples)

    def __getitem__(self, idx):
        p, l = self.samples[idx]
        img  = self.transform(Image.open(p).convert("RGB"))
        feat = np.zeros(JSON_FEAT_DIM, dtype=np.float32)
        return img, torch.tensor(feat, dtype=torch.float32), l

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ DATA PREPARATION â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _task_ready(name):
    p = os.path.join(WORK_DIR, "train", name)
    return os.path.isdir(p) and len(os.listdir(p)) > 0

def collect_copy_split(src_root, task_name, class_list,
                        merge_map=None, merged_cap=None, skip_classes=None):
    """
    skip_classes: ìˆ˜ì§‘ì—ì„œ ì•„ì˜ˆ ì œì™¸í•  ì›ë³¸ í´ëž˜ìŠ¤ëª… set
                  (dog_ë°±ë‚´ìž¥ì²˜ëŸ¼ ì‚¬ìš© ì•ˆ í•˜ëŠ” í´ëž˜ìŠ¤)
    """
    rng = random.Random(SEED)
    name_to_idx = {n: i for i, n in enumerate(class_list)}
    skip_classes = skip_classes or set()
    class_files  = defaultdict(list); seen = set()

    src_classes = list(class_list)
    if merge_map:
        for k in merge_map:
            if k not in src_classes: src_classes.append(k)

    for cls in src_classes:
        if cls in skip_classes: continue
        d = os.path.join(src_root, cls)
        if not os.path.isdir(d): continue
        dest_cls = merge_map.get(cls, cls) if merge_map else cls
        if dest_cls not in name_to_idx: continue
        dest_idx = name_to_idx[dest_cls]
        for f in os.listdir(d):
            if not f.lower().endswith((".jpg", ".jpeg", ".png")): continue
            fp = os.path.join(d, f)
            if fp in seen: continue
            seen.add(fp); class_files[dest_idx].append(fp)

    if merged_cap:
        for idx in list(class_files.keys()):
            cap = merged_cap.get(class_list[idx])
            if cap and len(class_files[idx]) > cap:
                rng.shuffle(class_files[idx])
                class_files[idx] = class_files[idx][:cap]

    for split in ["train", "val", "test"]:
        for cls in class_list:
            os.makedirs(os.path.join(WORK_DIR, split, task_name, cls), exist_ok=True)

    train_s, val_s = [], []
    for idx, paths in class_files.items():
        cls = class_list[idx]; rng.shuffle(paths); n = len(paths)
        nv = max(1, int(n * VAL_RATIO)); nt = max(1, int(n * TEST_RATIO))
        splits_map = {"train": paths[:n-nv-nt], "val": paths[n-nv-nt:n-nt], "test": paths[n-nt:]}
        for sname, spaths in splits_map.items():
            dst = os.path.join(WORK_DIR, sname, task_name, cls)
            for src in spaths:
                d_img = os.path.join(dst, os.path.basename(src))
                if not os.path.exists(d_img): shutil.copy2(src, d_img)
                # disease classë§Œ JSON ë³µì‚¬ (normalì€ JSON ì—†ìŒ)
                if cls not in NORMAL_CLASS_NAMES:
                    json_src = os.path.splitext(src)[0] + ".json"
                    json_dst = os.path.splitext(d_img)[0] + ".json"
                    if os.path.exists(json_src) and not os.path.exists(json_dst):
                        shutil.copy2(json_src, json_dst)
            wp = [(os.path.join(dst, os.path.basename(s)), idx) for s in spaths]
            if sname == "train": train_s.extend(wp)
            elif sname == "val":  val_s.extend(wp)
    print(f"  âœ… {task_name}: train={len(train_s)} val={len(val_s)}")
    return train_s, val_s

def load_from_dir(task_dir, class_list):
    name_to_idx = {n: i for i, n in enumerate(class_list)}
    samples = []
    for cls in sorted(os.listdir(task_dir)):
        d = os.path.join(task_dir, cls)
        if not os.path.isdir(d) or cls not in name_to_idx: continue
        for f in os.listdir(d):
            if f.lower().endswith((".jpg", ".jpeg", ".png")):
                samples.append((os.path.join(d, f), name_to_idx[cls]))
    return samples

def class_weights_from_samples(samples, n_classes):
    labels = [l for _, l in samples]
    w = compute_class_weight('balanced', classes=np.arange(n_classes), y=labels)
    return torch.tensor(w, dtype=torch.float).to(DEVICE)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ HELPERS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def make_loader(samples, transform, shuffle, drop_last=False, class_list=None):
    ds = FusionDataset(samples, transform, class_list=class_list)
    return DataLoader(ds, batch_size=BATCH_SIZE, shuffle=shuffle,
                      num_workers=NUM_WORKERS, pin_memory=True,
                      persistent_workers=True, prefetch_factor=2,
                      multiprocessing_context="fork", drop_last=drop_last)

def clear(): gc.collect(); torch.cuda.empty_cache()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ HISTORY PLOT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _save_history_plot(history, best_acc):
    fig, axes = plt.subplots(1, 3, figsize=(18, 5))
    ax = axes[0]
    ax.plot([h["skin_train"] for h in history], "b--", linewidth=1.5, alpha=0.7, label="Skin Train")
    ax.plot([h["skin_val"]   for h in history], "b-",  linewidth=2.5, label="Skin Val")
    ax.set_ylim(0, 1); ax.set_title("Skin Accuracy (Train vs Val)"); ax.legend(); ax.grid(True, alpha=0.3)
    if len(history) > 1:
        ax.set_xlabel(f"Epoch  |  gap={(history[-1]['skin_train']-history[-1]['skin_val'])*100:.1f}%")
    ax = axes[1]
    ax.plot([h["eyes_train"] for h in history], "r--", linewidth=1.5, alpha=0.7, label="Eyes Train")
    ax.plot([h["eyes_val"]   for h in history], "r-",  linewidth=2.5, label="Eyes Val")
    ax.set_ylim(0, 1); ax.set_title("Eyes Accuracy (Train vs Val)"); ax.legend(); ax.grid(True, alpha=0.3)
    if len(history) > 1:
        ax.set_xlabel(f"Epoch  |  gap={(history[-1]['eyes_train']-history[-1]['eyes_val'])*100:.1f}%")
    ax = axes[2]
    ax.plot([h["skin_lr"] for h in history], "b-", linewidth=1.5, label="Skin LR (head)")
    ax.plot([h["eyes_lr"] for h in history], "r-", linewidth=1.5, label="Eyes LR (head)")
    ax.set_title("Learning Rate (WarmRestarts Tâ‚€=20)"); ax.legend(); ax.grid(True, alpha=0.3)
    for restart in [20, 40, 60, 80]:
        if restart < len(history):
            ax.axvline(x=restart, color="gray", linestyle=":", alpha=0.5)
    plt.suptitle(f"Dog Abnormal Omni | Best Avg {best_acc*100:.1f}%", fontweight="bold")
    plt.tight_layout(); plt.savefig("dog_abnormal_omni_history.png", dpi=150); plt.close()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ TRAIN/VAL â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def val_loop(model, samples, transform, class_list):
    """val: ì‹¤ì œ JSON feat ì‚¬ìš©. model.eval() â†’ Modality Dropout ë¯¸ì ìš©."""
    loader = make_loader(samples, transform, shuffle=False,
                         drop_last=False, class_list=class_list)
    model.to(DEVICE).eval(); c, t = 0, 0
    with torch.no_grad():
        for imgs, feats, labels in loader:
            imgs, feats, labels = imgs.to(DEVICE), feats.to(DEVICE), labels.to(DEVICE)
            with torch.amp.autocast("cuda"):
                out = model(imgs, feats)
            c += (out.argmax(1) == labels).sum().item(); t += labels.size(0)
    del loader; clear(); model.cpu(); clear()
    return c / t if t > 0 else 0.0

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ TRAINING â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def train():
    if _task_ready("skin"):
        print("âœ… skin ready")
        skin_train = load_from_dir(os.path.join(WORK_DIR, "train", "skin"), DOG_SKIN_CLASSES)
        skin_val   = load_from_dir(os.path.join(WORK_DIR, "val",   "skin"), DOG_SKIN_CLASSES)
    else:
        print("ðŸ“¦ Preparing skin (dog)...")
        skin_train, skin_val = collect_copy_split(SKIN_ROOT, "skin", DOG_SKIN_CLASSES)

    if _task_ready("eyes"):
        print("âœ… eyes ready")
        eyes_train = load_from_dir(os.path.join(WORK_DIR, "train", "eyes"), DOG_EYES_CLASSES)
        eyes_val   = load_from_dir(os.path.join(WORK_DIR, "val",   "eyes"), DOG_EYES_CLASSES)
    else:
        print("ðŸ“¦ Preparing eyes (dog): ê°ë§‰ì§ˆí™˜ í†µí•©, ë°±ë‚´ìž¥ ì œê±°, cap=10,000...")
        eyes_train, eyes_val = collect_copy_split(
            EYES_ROOT, "eyes", DOG_EYES_CLASSES,
            merge_map  = DOG_EYES_MERGE_MAP,
            merged_cap = {"dog_ê°ë§‰ì§ˆí™˜": EYES_MERGE_CLASS_CAP},
            skip_classes = {"dog_ë°±ë‚´ìž¥"},   # ë°±ë‚´ìž¥ í´ëž˜ìŠ¤ ì™„ì „ ì œì™¸
        )

    skin_w    = class_weights_from_samples(skin_train, len(DOG_SKIN_CLASSES))
    eyes_w    = class_weights_from_samples(eyes_train, len(DOG_EYES_CLASSES))
    skin_crit = WeightedSmoothLoss(DOG_SKIN_CLASSES, class_weights=skin_w,
                                    smoothing=LABEL_SMOOTHING)
    eyes_crit = WeightedSmoothLoss(DOG_EYES_CLASSES, similar_groups=EYES_SIMILAR_GROUPS,
                                    class_weights=eyes_w, smoothing=LABEL_SMOOTHING_EYES)

    skin_model = SkinModel(len(DOG_SKIN_CLASSES), json_feat_dim=JSON_FEAT_DIM)
    eyes_model = EyesModel(len(DOG_EYES_CLASSES), json_feat_dim=JSON_FEAT_DIM)

    for m in [skin_model, eyes_model]:
        for p in m.backbone.parameters(): p.requires_grad = False
    print(f"  ðŸ”’ Backbone frozen for {FREEZE_EPOCHS} epochs")

    def make_opt(m):
        return torch.optim.AdamW([
            {"params": m.backbone.parameters(),
             "lr": LR_BACKBONE, "weight_decay": WEIGHT_DECAY},
            {"params": [p for n, p in m.named_parameters() if "backbone" not in n],
             "lr": LR_HEAD, "weight_decay": WEIGHT_DECAY},
        ])
    skin_opt = make_opt(skin_model); eyes_opt = make_opt(eyes_model)

    def make_sched(opt):
        return lr_scheduler.CosineAnnealingWarmRestarts(opt, T_0=20, T_mult=1, eta_min=1e-7)
    skin_sched = make_sched(skin_opt); eyes_sched = make_sched(eyes_opt)

    skin_scaler = torch.amp.GradScaler("cuda")
    eyes_scaler = torch.amp.GradScaler("cuda")
    best_acc, history = 0.0, []

    for epoch in range(EPOCHS):
        print(f"\n{'='*55}\nEpoch {epoch+1}/{EPOCHS}\n{'='*55}")
        if epoch == FREEZE_EPOCHS:
            for m in [skin_model, eyes_model]:
                for p in m.backbone.parameters(): p.requires_grad = True
            print("  ðŸ”“ Backbone unfrozen")

        def train_task(name, model, samples, crit, transform, opt,
                       scaler, sched, epoch_float, class_list):
            model.to(DEVICE).train()
            loader = make_loader(samples, transform, shuffle=True,
                                 drop_last=True, class_list=class_list)
            ls, c, t = 0, 0, 0; n_batches = len(loader)
            for bi, (imgs, feats, labels) in enumerate(
                    tqdm(loader, desc=f"  {name}", ncols=100, leave=True)):
                imgs, feats, labels = imgs.to(DEVICE), feats.to(DEVICE), labels.to(DEVICE)
                opt.zero_grad()
                with torch.amp.autocast("cuda"):
                    out = model(imgs, feats); loss = crit(out, labels)
                scaler.scale(loss).backward(); scaler.unscale_(opt)
                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
                prev = scaler.get_scale(); scaler.step(opt); scaler.update()
                if scaler.get_scale() == prev: sched.step(epoch_float + bi / n_batches)
                ls += loss.item(); c += (out.argmax(1)==labels).sum().item(); t += labels.size(0)
            del loader; clear(); model.cpu(); clear()
            return ls / (t // BATCH_SIZE + 1), c / t

        print("\n[1/2] Skin")
        s_loss, s_tacc = train_task("Skin", skin_model, skin_train, skin_crit,
                                    SKIN_TRANSFORM_TRAIN, skin_opt, skin_scaler, skin_sched,
                                    epoch, DOG_SKIN_CLASSES)
        print("\n[2/2] Eyes")
        e_loss, e_tacc = train_task("Eyes", eyes_model, eyes_train, eyes_crit,
                                    EYES_TRANSFORM_TRAIN, eyes_opt, eyes_scaler, eyes_sched,
                                    epoch, DOG_EYES_CLASSES)

        skin_vacc = val_loop(skin_model, skin_val, TRANSFORM_VAL, DOG_SKIN_CLASSES); clear()
        eyes_vacc = val_loop(eyes_model, eyes_val, TRANSFORM_VAL, DOG_EYES_CLASSES); clear()
        avg = (skin_vacc + eyes_vacc) / 2

        skin_lr = skin_opt.param_groups[1]["lr"]
        eyes_lr = eyes_opt.param_groups[1]["lr"]
        print(f"\nðŸ“Š Ep{epoch+1} | Skin Train {s_tacc*100:.1f}% Val {skin_vacc*100:.1f}% LR={skin_lr:.2e}"
              f" | Eyes Train {e_tacc*100:.1f}% Val {eyes_vacc*100:.1f}% LR={eyes_lr:.2e}"
              f" | Avg {avg*100:.1f}%")

        history.append({"epoch": epoch+1,
                         "skin_train": s_tacc, "skin_val": skin_vacc,
                         "eyes_train": e_tacc, "eyes_val": eyes_vacc,
                         "avg": avg, "skin_lr": skin_lr, "eyes_lr": eyes_lr})

        if avg > best_acc:
            best_acc = avg
            torch.save({
                "skin_model":         skin_model.state_dict(),
                "eyes_model":         eyes_model.state_dict(),
                "dog_skin_classes":   DOG_SKIN_CLASSES,
                "dog_eyes_classes":   DOG_EYES_CLASSES,
                "json_feat_dim":      JSON_FEAT_DIM,
                "json_train_dropout": JSON_TRAIN_DROPOUT,
                "best_epoch":         epoch+1,
                "best_acc":           best_acc,
                "history":            history,
            }, "dog_abnormal_omni_best.pth")
            print(f"  ðŸ’¾ Saved! Avg {best_acc*100:.1f}%")

        _save_history_plot(history, best_acc)

    print(f"\nðŸŽ‰ Done! Best Avg: {best_acc*100:.1f}%")


if __name__ == "__main__":
    train()
