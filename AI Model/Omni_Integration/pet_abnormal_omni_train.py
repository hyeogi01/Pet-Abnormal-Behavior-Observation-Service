import os
import gc
import random
import shutil
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import numpy as np

from PIL import Image, ImageFile
from torch.utils.data import Dataset, DataLoader
from transformers import get_cosine_schedule_with_warmup
from torchvision.models import efficientnet_v2_s, EfficientNet_V2_S_Weights  # [v2] ResNet50 â†’ EfficientNet-V2-S
from collections import defaultdict
from tqdm import tqdm

ImageFile.LOAD_TRUNCATED_IMAGES = True

# ===============================
# CONFIG
# ===============================

SEED = 42
random.seed(SEED)
torch.manual_seed(SEED)

DEVICE = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

EPOCHS        = 50
BATCH_SIZE    = 32          # [v2] 384Ã—384 ì´ë¯¸ì§€ â†’ VRAM ì¦ê°€ â†’ 64â†’32
NUM_WORKERS   = 24
LR_BACKBONE   = 2e-5       # [v2] EfficientNet backbone (ResNet 5e-6 â†’ 2e-5)
LR_HEAD       = 2e-4       # [v2] Head (5e-4 â†’ 2e-4, EfficientNet ì•ˆì •ì„± ê³ ë ¤)
FREEZE_EPOCHS = 5
LABEL_SMOOTHING = 0.1

# [v2] EfficientNet-V2-S ê¶Œì¥ í•´ìƒë„ 384Ã—384
IMG_SIZE   = 384
IMG_RESIZE = 416

VAL_RATIO  = 0.1
TEST_RATIO = 0.1

WORK_DIR = "files/work/abnormal_dataset"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CLASS DEFINITIONS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# â”€â”€ 4_Animal_Skin â”€â”€
# [v2] cat/dog ë¶„ë¦¬: ê³µìœ  backbone + species-specific head ë°©ì‹.
# - 2ë‹¨ê³„ cascade (ì¢… ë¶„ë¥˜ â†’ í”¼ë¶€ ë¶„ë¥˜) ëŒ€ì‹  species-conditioned head ì±„íƒ.
#   ì´ìœ : (1) ì‹¤ì„œë¹„ìŠ¤ì—ì„œ ì‚¬ìš©ìëŠ” ì¢…ì„ ì´ë¯¸ ì•
#         (2) cascadeëŠ” ì¢… ì˜¤ë¥˜ â†’ ì§ˆí™˜ ì˜¤ë¥˜ ì „íŒŒ ìœ„í—˜
#         (3) head ë¶„ë¦¬ë§Œìœ¼ë¡œ cat/dog cross-species ê°„ì„­ ì œê±° íš¨ê³¼ ë™ì¼
CAT_SKIN_CLASSES = [
    "cat_normal", "cat_ê²°ì ˆ,ì¢…ê´´", "cat_ë†í¬,ì—¬ë“œë¦„",
    "cat_ë¹„ë“¬,ê°ì§ˆ,ìƒí”¼ì„±ì”ê³ ë¦¬",
]
DOG_SKIN_CLASSES = [
    "dog_normal", "dog_ê²°ì ˆ,ì¢…ê´´", "dog_ë†í¬,ì—¬ë“œë¦„",
    "dog_ë¯¸ë€,ê¶¤ì–‘", "dog_ë¹„ë“¬,ê°ì§ˆ,ìƒí”¼ì„±ì”ê³ ë¦¬",
]
# ë°ì´í„° ìˆ˜ì§‘ ë° split ì‹œ ì „ì²´ ëª©ë¡ ì‚¬ìš© (ìˆœì„œ ê³ ì •: cat â†’ dog)
SKIN_CLASSES = CAT_SKIN_CLASSES + DOG_SKIN_CLASSES

# â”€â”€ 5_Animal_Eyes â”€â”€
# [v2] í†µí•© í›„ 17í´ë˜ìŠ¤ (Eyes_class.txt ê¸°ì¤€)
# âš ï¸  ê¸°ì¡´ 21í´ë˜ìŠ¤(ìƒ/í•˜, ë°±ë‚´ì¥ 3ë‹¨ê³„)ë¡œ ì¤€ë¹„ëœ WORK_DIR/eyes í´ë”ê°€ ìˆë‹¤ë©´
#     í•´ë‹¹ í´ë” ì‚­ì œ í›„ ì¬ì‹¤í–‰ í•„ìš” (ìƒˆ í´ë˜ìŠ¤ëª… í´ë”ë¡œ ì¬ë³µì‚¬)
EYES_CLASSES = [
    "cat_normal", "cat_ê°ë§‰ê¶¤ì–‘", "cat_ê°ë§‰ë¶€ê³¨í¸",
    "cat_ê²°ë§‰ì—¼", "cat_ë¹„ê¶¤ì–‘ì„±ê°ë§‰ì—¼", "cat_ì•ˆê²€ì—¼",
    "dog_normal", "dog_ê²°ë§‰ì—¼", "dog_ê¶¤ì–‘ì„±ê°ë§‰ì§ˆí™˜",
    "dog_ë¹„ê¶¤ì–‘ì„±ê°ë§‰ì§ˆí™˜", "dog_ë°±ë‚´ì¥", "dog_ìƒ‰ì†Œì¹¨ì°©ì„±ê°ë§‰ì—¼",
    "dog_ì•ˆê²€ë‚´ë°˜ì¦", "dog_ì•ˆê²€ì—¼", "dog_ì•ˆê²€ì¢…ì–‘",
    "dog_ìœ ë£¨ì¦", "dog_í•µê²½í™”",
]

EYES_SIMILAR_GROUPS = [
    ["dog_ê¶¤ì–‘ì„±ê°ë§‰ì§ˆí™˜", "dog_ë¹„ê¶¤ì–‘ì„±ê°ë§‰ì§ˆí™˜"],   # ê°ë§‰ ìœ í˜• í˜¼ë™ ë°©ì§€
    ["dog_ì•ˆê²€ì—¼", "dog_ì•ˆê²€ë‚´ë°˜ì¦"],                  # ì•ˆê²€ ê´€ë ¨ í˜¼ë™ ë°©ì§€
]


# ===============================
# LOSS: Hierarchical-Aware CE
# ===============================

class HierarchicalWeightedLoss(nn.Module):
    """
    CrossEntropyLoss + Label Smoothing + ìœ ì‚¬ í´ë˜ìŠ¤ í˜¼ë™ í˜ë„í‹°

    Args:
        class_names    : í•™ìŠµ taskì— í•´ë‹¹í•˜ëŠ” í´ë˜ìŠ¤ ì´ë¦„ ë¦¬ìŠ¤íŠ¸
        similar_groups : ìœ ì‚¬ í´ë˜ìŠ¤ ë¬¶ìŒ [[cls_a, cls_b], ...]
        class_weights  : í´ë˜ìŠ¤ ë¶ˆê· í˜• ë³´ì • weight í…ì„œ
        smoothing      : label smoothing Îµ
        extra_penalty  : ê°™ì€ ê·¸ë£¹ ë‚´ ì˜¤ë¶„ë¥˜ ì‹œ loss ë°°ìœ¨
    """

    def __init__(
        self,
        class_names,
        similar_groups=None,
        class_weights=None,
        smoothing=LABEL_SMOOTHING,
        extra_penalty=1.5,
    ):
        super().__init__()
        self.smoothing     = smoothing
        self.extra_penalty = extra_penalty
        self.num_classes   = len(class_names)
        self.class_names   = class_names
        self.name_to_idx   = {n: i for i, n in enumerate(class_names)}

        self.penalty_pairs = set()
        if similar_groups:
            for group in similar_groups:
                idxs = [self.name_to_idx[n] for n in group if n in self.name_to_idx]
                for i in range(len(idxs)):
                    for j in range(i + 1, len(idxs)):
                        self.penalty_pairs.add((idxs[i], idxs[j]))
                        self.penalty_pairs.add((idxs[j], idxs[i]))

        self.register_buffer("weight", class_weights)

    def forward(self, logits, targets):
        B, C   = logits.shape
        device = logits.device

        log_prob    = F.log_softmax(logits, dim=-1)
        smooth_loss = -log_prob.mean(dim=-1)
        nll_loss    = F.nll_loss(log_prob, targets, weight=self.weight, reduction="none")
        base_loss   = (1 - self.smoothing) * nll_loss + self.smoothing * smooth_loss

        if self.penalty_pairs:
            pred_classes = logits.argmax(dim=-1)
            penalty_mask = torch.ones(B, device=device)
            for b in range(B):
                t = targets[b].item()
                p = pred_classes[b].item()
                if (t, p) in self.penalty_pairs:
                    penalty_mask[b] = self.extra_penalty
            base_loss = base_loss * penalty_mask

        return base_loss.mean()


# ===============================
# CLASS WEIGHT COMPUTATION
# ===============================

def compute_class_weights(sample_counts: dict, class_names: list) -> torch.Tensor:
    """Inverse-frequency ë°©ì‹ìœ¼ë¡œ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ë¥¼ ê³„ì‚°í•œë‹¤."""
    counts  = torch.tensor([sample_counts.get(n, 1) for n in class_names], dtype=torch.float)
    weights = 1.0 / counts
    weights = weights / weights.sum() * len(class_names)
    return weights


# ===============================
# BACKBONE & MODEL
# [v2] ResNet50 â†’ EfficientNet-V2-S
# ===============================

def _efficientnet_backbone():
    """
    [v2] EfficientNet-V2-S backbone.
    classifierë¥¼ Identityë¡œ êµì²´í•˜ê³  feat_dim(1280) ë°˜í™˜.

    ResNet50 ëŒ€ë¹„ ì¥ì :
    - í”¼ë¶€/ì•ˆêµ¬ ë¯¸ì„¸ ì§ˆê° íŒ¨í„´ì—ì„œ ìš°ìˆ˜í•œ íŠ¹ì§• ì¶”ì¶œ
    - ë” ì ì€ íŒŒë¼ë¯¸í„°ë¡œ ë” ë†’ì€ ì„±ëŠ¥ (28M vs 25M)
    - MBConv + Fused-MBConvì˜ ë³µí•© êµ¬ì¡° â†’ ì„¸ë°€í•œ íŒ¨í„´ í•™ìŠµ
    - ê¶Œì¥ ì…ë ¥ í•´ìƒë„ 384Ã—384 (IMG_SIZEì™€ ì¼ì¹˜)
    """
    backbone = efficientnet_v2_s(weights=EfficientNet_V2_S_Weights.IMAGENET1K_V1)
    feat_dim = backbone.classifier[1].in_features  # 1280
    backbone.classifier = nn.Identity()
    return backbone, feat_dim


class SqueezeExcitation(nn.Module):
    """1-D Squeeze-Excitation for feature vectors (after global avg pool)."""

    def __init__(self, channels: int, reduction: int = 16):
        super().__init__()
        self.se = nn.Sequential(
            nn.Linear(channels, channels // reduction, bias=False),
            nn.ReLU(),
            nn.Linear(channels // reduction, channels, bias=False),
            nn.Sigmoid(),
        )

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return x * self.se(x)


def _classification_head(feat_dim: int, hidden: int, num_classes: int,
                          dropout1: float = 0.4, dropout2: float = 0.3) -> nn.Module:
    """ê³µí†µ ë¶„ë¥˜ í—¤ë“œ íŒ©í† ë¦¬ (BN í¬í•¨ìœ¼ë¡œ í•™ìŠµ ì•ˆì •ì„± ê°•í™”)."""
    return nn.Sequential(
        nn.Dropout(dropout1),
        nn.Linear(feat_dim, hidden),
        nn.BatchNorm1d(hidden),
        nn.GELU(),
        nn.Dropout(dropout2),
        nn.Linear(hidden, num_classes),
    )


class AnomalyMultiBackbone(nn.Module):
    """
    [v2] EfficientNet-V2-S ê¸°ë°˜ ì´ìƒ ì¦ìƒ Omni ëª¨ë¸

    â”œâ”€â”€ skin_backbone (ê³µìœ , EfficientNet-V2-S, feat=1280)
    â”‚   â”œâ”€â”€ skin_cat_head â†’ cat í”¼ë¶€ì§ˆí™˜ 4í´ë˜ìŠ¤
    â”‚   â””â”€â”€ skin_dog_head â†’ dog í”¼ë¶€ì§ˆí™˜ 5í´ë˜ìŠ¤
    â”‚
    â””â”€â”€ eyes_backbone (EfficientNet-V2-S + SE Attention, feat=1280)
        â””â”€â”€ eyes_head â†’ ì•ˆêµ¬ì§ˆí™˜ 17í´ë˜ìŠ¤

    [v2 ì„¤ê³„ ë³€ê²½]
    - Skin: ë‹¨ì¼ 9-class â†’ cat(4) / dog(5) species-conditioned head ë¶„ë¦¬
      â†’ cat/dog cross-species ê°„ì„­ ì œê±°, ê° ì¢…ì— íŠ¹í™”ëœ íŠ¹ì§• í•™ìŠµ
    - ê³µìœ  backboneì´ cat/dog í”¼ë¶€ ê³µí†µ íŠ¹ì§• í•™ìŠµ í›„ headì—ì„œ ë¶„ê¸°
    - Inference ì‹œ pet_typeìœ¼ë¡œ ì ì ˆí•œ head ì„ íƒ (cascade ë¶ˆí•„ìš”)
    """

    def __init__(
        self,
        num_cat_skin: int,
        num_dog_skin: int,
        num_eyes: int,
    ):
        super().__init__()

        # â”€â”€ Skin: ê³µìœ  backbone + species-specific heads â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        self.skin_backbone, skin_feat = _efficientnet_backbone()
        self.skin_cat_head = _classification_head(skin_feat, 256, num_cat_skin)
        self.skin_dog_head = _classification_head(skin_feat, 256, num_dog_skin)

        # â”€â”€ Eyes: backbone + SE + head â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        self.eyes_backbone, eyes_feat = _efficientnet_backbone()
        self.eyes_se   = SqueezeExcitation(eyes_feat, reduction=16)
        self.eyes_head = _classification_head(eyes_feat, 512, num_eyes,
                                              dropout1=0.4, dropout2=0.3)

    def freeze_backbones(self):
        for p in self.skin_backbone.parameters():
            p.requires_grad = False
        for p in self.eyes_backbone.parameters():
            p.requires_grad = False

    def unfreeze_backbones(self):
        for p in self.skin_backbone.parameters():
            p.requires_grad = True
        for p in self.eyes_backbone.parameters():
            p.requires_grad = True

    def forward(self, x: torch.Tensor, task: str) -> torch.Tensor:
        if task == "skin_cat":
            return self.skin_cat_head(self.skin_backbone(x))
        elif task == "skin_dog":
            return self.skin_dog_head(self.skin_backbone(x))
        elif task == "eyes":
            feat = self.eyes_se(self.eyes_backbone(x))
            return self.eyes_head(feat)
        raise ValueError(f"Unknown task: {task!r}. Use 'skin_cat', 'skin_dog', or 'eyes'.")


# ===============================
# INFERENCE: Multi-Image Ensemble
# ===============================

def predict_anomaly(
    model: AnomalyMultiBackbone,
    images: list,
    task: str,
    pet_type: str,
    device=DEVICE,
) -> dict:
    """
    [v2] species-conditioned êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì •.
    - task="skin": pet_type â†’ skin_cat / skin_dog head ì§ì ‘ ì„ íƒ
      (ê¸°ì¡´ 21â†’17 ë§ˆìŠ¤í‚¹ ë°©ì‹ ë¶ˆí•„ìš”, ë‹¨ìˆœí•´ì§)
    - task="eyes": 17í´ë˜ìŠ¤ ì¤‘ pet_typeì— í•´ë‹¹í•˜ëŠ” í´ë˜ìŠ¤ë§Œ í•„í„°ë§

    Args:
        images   : PIL.Image ë¦¬ìŠ¤íŠ¸ (ìµœëŒ€ 5ì¥ ê¶Œì¥, ì•™ìƒë¸”)
        task     : "skin" | "eyes"
        pet_type : "cat" | "dog"
    """
    transform = transforms.Compose([
        transforms.Resize((IMG_SIZE, IMG_SIZE)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),
    ])

    model.eval()
    model.to(device)

    if task == "skin":
        actual_task = f"skin_{pet_type}"                                        # "skin_cat" or "skin_dog"
        class_names = CAT_SKIN_CLASSES if pet_type == "cat" else DOG_SKIN_CLASSES
    elif task == "eyes":
        actual_task = "eyes"
        valid_idxs  = [i for i, n in enumerate(EYES_CLASSES) if n.startswith(pet_type + "_")]
        class_names = [EYES_CLASSES[i] for i in valid_idxs]
    else:
        raise ValueError(f"Unknown task: {task!r}")

    with torch.no_grad():
        probs_accum = torch.zeros(len(class_names), device=device)
        for img in images:
            tensor = transform(img).unsqueeze(0).to(device)
            logits = model(tensor, task=actual_task)

            if task == "eyes":
                # 17í´ë˜ìŠ¤ ì¤‘ í•´ë‹¹ ì¢… í´ë˜ìŠ¤ë§Œ softmax
                masked = torch.full((len(EYES_CLASSES),), float("-inf"), device=device)
                masked[valid_idxs] = logits[0][valid_idxs]
                probs_accum += F.softmax(masked, dim=-1)[valid_idxs]
            else:
                # skin: head ì¶œë ¥ì´ ì´ë¯¸ í•´ë‹¹ ì¢…ë§Œ í¬í•¨
                probs_accum += F.softmax(logits[0], dim=-1)

        probs_accum /= len(images)

    result = sorted(
        [(class_names[i], probs_accum[i].item()) for i in range(len(class_names))],
        key=lambda x: x[1], reverse=True,
    )
    return {
        "predicted_class": result[0][0],
        "confidence":      result[0][1],
        "top3":            result[:3],
    }


# ===============================
# DATA SPLIT & COPY UTILITY
# ===============================

def _task_ready(task_name: str) -> bool:
    """í•´ë‹¹ taskì˜ train í´ë”ê°€ ì¡´ì¬í•˜ê³  ë¹„ì–´ìˆì§€ ì•Šìœ¼ë©´ True."""
    task_train = os.path.join(WORK_DIR, "train", task_name)
    return os.path.isdir(task_train) and len(os.listdir(task_train)) > 0


def collect_copy_split(
    root_dir: str,
    task_name: str,
    class_names: list,
    val_ratio: float  = VAL_RATIO,
    test_ratio: float = TEST_RATIO,
    seed: int         = SEED,
) -> tuple:
    """
    root_dir í•˜ìœ„ class ë””ë ‰í† ë¦¬ì—ì„œ ì´ë¯¸ì§€ë¥¼ ìˆ˜ì§‘í•˜ê³ 
    í´ë˜ìŠ¤ë³„ stratified split í›„ WORK_DIRì— íŒŒì¼ì„ ë¬¼ë¦¬ì ìœ¼ë¡œ ë³µì‚¬í•œë‹¤.

    Returns:
        train_samples, val_samples
        ê° ì›ì†Œ: (img_path: str, label_idx: int)  â† WORK_DIR ë‚´ ë³µì‚¬ëœ ê²½ë¡œ
    """
    rng         = random.Random(seed)
    name_to_idx = {n: i for i, n in enumerate(class_names)}
    class_files = defaultdict(list)
    seen_paths  = set()

    for class_name in class_names:
        class_dir = os.path.join(root_dir, class_name)
        if not os.path.isdir(class_dir):
            continue
        label_idx = name_to_idx[class_name]
        for fname in os.listdir(class_dir):
            if not fname.lower().endswith((".jpg", ".jpeg", ".png")):
                continue
            fpath = os.path.join(class_dir, fname)
            if fpath in seen_paths:
                continue
            seen_paths.add(fpath)
            class_files[label_idx].append(fpath)

    for split in ["train", "val", "test"]:
        for class_name in class_names:
            os.makedirs(os.path.join(WORK_DIR, split, task_name, class_name), exist_ok=True)

    train_samples, val_samples = [], []

    for label_idx, paths in class_files.items():
        class_name = class_names[label_idx]
        rng.shuffle(paths)
        n       = len(paths)
        n_val   = max(1, int(n * val_ratio))
        n_test  = max(1, int(n * test_ratio))
        n_train = n - n_val - n_test

        if n_train <= 0:
            print(f"  âš ï¸  '{class_name}': ìƒ˜í”Œ ìˆ˜({n})ê°€ ë„ˆë¬´ ì ì–´ trainì´ 0ê°œì…ë‹ˆë‹¤.")
            n_train, n_val, n_test = n, 0, 0

        split_map = {
            "train": paths[:n_train],
            "val"  : paths[n_train:n_train + n_val],
            "test" : paths[n_train + n_val:],
        }

        for split_name, split_paths in split_map.items():
            dst_dir = os.path.join(WORK_DIR, split_name, task_name, class_name)
            for src in tqdm(split_paths, desc=f"  copy {task_name}/{split_name}/{class_name}", leave=False):
                dst = os.path.join(dst_dir, os.path.basename(src))
                if not os.path.exists(dst):
                    shutil.copy2(src, dst)
                if split_name == "train":
                    train_samples.append((dst, label_idx))
                elif split_name == "val":
                    val_samples.append((dst, label_idx))

    print(f"  â†’ {task_name}: train {len(train_samples)} | val {len(val_samples)}"
          f" | test â†’ {os.path.join(WORK_DIR, 'test', task_name)}/")
    return train_samples, val_samples


def count_samples_from_split(samples: list, class_names: list) -> dict:
    """splitëœ samplesì—ì„œ class_nameë³„ ê°œìˆ˜ë¥¼ ë°˜í™˜ (class_weight ê³„ì‚°ìš©)."""
    idx_to_name = {i: n for i, n in enumerate(class_names)}
    counts      = defaultdict(int)
    for _, label_idx in samples:
        counts[idx_to_name[label_idx]] += 1
    return dict(counts)


# ===============================
# DATASETS
# ===============================

class AnomalyDataset(Dataset):
    """
    [v2] EfficientNet-V2-S ê¶Œì¥ í•´ìƒë„ 384Ã—384 ì ìš©.
    Skin augmentation ì™„í™”: í”¼ë¶€ìƒ‰Â·ì§ˆê°ì´ ì§„ë‹¨ í•µì‹¬ ë‹¨ì„œì´ë¯€ë¡œ ColorJitter ì–µì œ.
    Eyes augmentation ìœ ì§€: ì•ˆêµ¬ ìƒ‰ ë³€í™”(ì¶©í˜ˆ, í˜¼íƒ)ê°€ ì§„ë‹¨ ë‹¨ì„œì´ë¯€ë¡œ ìœ ì§€.
    """

    # [v2] Skin: ColorJitter ì™„í™”, RandomAdjustSharpness ì¶”ê°€ (ì§ˆê° ê°•ì¡°)
    TRANSFORM_SKIN_TRAIN = transforms.Compose([
        transforms.Resize((IMG_RESIZE, IMG_RESIZE)),            # 416
        transforms.RandomCrop(IMG_SIZE),                        # 384
        transforms.RandomHorizontalFlip(),
        transforms.ColorJitter(brightness=0.15, contrast=0.15, saturation=0.05),  # ì™„í™”
        transforms.RandomAdjustSharpness(sharpness_factor=2, p=0.3),              # ì§ˆê° ê°•ì¡°
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),
    ])

    # Eyes: ìƒ‰ ë³€í™”ê°€ ì§„ë‹¨ ë‹¨ì„œ â†’ ì ë‹¹í•œ augmentation ìœ ì§€ + GaussianBlur ì¶”ê°€
    TRANSFORM_EYES_TRAIN = transforms.Compose([
        transforms.Resize((IMG_RESIZE, IMG_RESIZE)),            # 416
        transforms.RandomCrop(IMG_SIZE),                        # 384
        transforms.RandomHorizontalFlip(),
        transforms.RandomVerticalFlip(),
        transforms.RandomRotation(15),
        transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.2, hue=0.05),
        transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 0.5), p=0.2),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),
    ])

    TRANSFORM_VAL = transforms.Compose([
        transforms.Resize((IMG_SIZE, IMG_SIZE)),                # 384
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),
    ])

    def __init__(self, samples: list, is_train: bool = True, task: str = "skin"):
        self.samples = samples
        if is_train and task == "eyes":
            self.transform = self.TRANSFORM_EYES_TRAIN
        elif is_train:
            self.transform = self.TRANSFORM_SKIN_TRAIN
        else:
            self.transform = self.TRANSFORM_VAL

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        img_path, label = self.samples[idx]
        img = Image.open(img_path).convert("RGB")
        return self.transform(img), label


# ===============================
# TRAIN FUNCTION
# ===============================

def train(
    skin_root: str = "files/4_Animal_Skin",
    eyes_root: str = "files/5_Animal_Eyes",
):
    print(f"ğŸ¯ Device: {DEVICE}")
    print(f"   Backbone : EfficientNet-V2-S (feat=1280)")
    print(f"   IMG_SIZE : {IMG_SIZE}Ã—{IMG_SIZE}")
    print(f"   BATCH    : {BATCH_SIZE}  LR_BB={LR_BACKBONE}  LR_HEAD={LR_HEAD}")

    # â”€â”€ Dataset Preparation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if _task_ready("skin"):
        print("\nâœ… skin already prepared, loading from WORK_DIR...")
        skin_train_samples = _load_samples_from_dir(
            os.path.join(WORK_DIR, "train", "skin"), SKIN_CLASSES
        )
        skin_val_samples = _load_samples_from_dir(
            os.path.join(WORK_DIR, "val", "skin"), SKIN_CLASSES
        )
    else:
        print("\nğŸ“¦ Splitting & Copying Skin dataset...")
        skin_train_samples, skin_val_samples = collect_copy_split(
            skin_root, "skin", SKIN_CLASSES
        )

    if _task_ready("eyes"):
        print("âœ… eyes already prepared, loading from WORK_DIR...")
        eyes_train_samples = _load_samples_from_dir(
            os.path.join(WORK_DIR, "train", "eyes"), EYES_CLASSES
        )
        eyes_val_samples = _load_samples_from_dir(
            os.path.join(WORK_DIR, "val", "eyes"), EYES_CLASSES
        )
    else:
        print("\nğŸ“¦ Splitting & Copying Eyes dataset...")
        eyes_train_samples, eyes_val_samples = collect_copy_split(
            eyes_root, "eyes", EYES_CLASSES
        )

    # â”€â”€ [v2] speciesë³„ skin ìƒ˜í”Œ ë¶„ë¦¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # SKIN_CLASSES = CAT(0~3) + DOG(4~8) ìˆœì„œ ê³ ì •
    # cat: global label_idx 0~3 â†’ local 0~3 (ê·¸ëŒ€ë¡œ)
    # dog: global label_idx 4~8 â†’ local 0~4 (N_CAT ë¹¼ì¤Œ)
    N_CAT = len(CAT_SKIN_CLASSES)

    skin_cat_train = [(p, l)         for p, l in skin_train_samples if l < N_CAT]
    skin_dog_train = [(p, l - N_CAT) for p, l in skin_train_samples if l >= N_CAT]
    skin_cat_val   = [(p, l)         for p, l in skin_val_samples   if l < N_CAT]
    skin_dog_val   = [(p, l - N_CAT) for p, l in skin_val_samples   if l >= N_CAT]

    print(f"\n  ğŸ“Š Skin split by species:")
    print(f"     cat â†’ train: {len(skin_cat_train)}  val: {len(skin_cat_val)}")
    print(f"     dog â†’ train: {len(skin_dog_train)}  val: {len(skin_dog_val)}")
    print(f"  ğŸ“Š Eyes â†’ train: {len(eyes_train_samples)}  val: {len(eyes_val_samples)}")

    # â”€â”€ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    cat_skin_counts   = count_samples_from_split(skin_cat_train,   CAT_SKIN_CLASSES)
    dog_skin_counts   = count_samples_from_split(skin_dog_train,   DOG_SKIN_CLASSES)
    eyes_train_counts = count_samples_from_split(eyes_train_samples, EYES_CLASSES)

    cat_skin_weights = compute_class_weights(cat_skin_counts,   CAT_SKIN_CLASSES).to(DEVICE)
    dog_skin_weights = compute_class_weights(dog_skin_counts,   DOG_SKIN_CLASSES).to(DEVICE)
    eyes_weights     = compute_class_weights(eyes_train_counts, EYES_CLASSES).to(DEVICE)

    # â”€â”€ Loss â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    skin_cat_criterion = HierarchicalWeightedLoss(
        class_names=CAT_SKIN_CLASSES,
        class_weights=cat_skin_weights,
        smoothing=LABEL_SMOOTHING,
    )
    skin_dog_criterion = HierarchicalWeightedLoss(
        class_names=DOG_SKIN_CLASSES,
        class_weights=dog_skin_weights,
        smoothing=LABEL_SMOOTHING,
    )
    eyes_criterion = HierarchicalWeightedLoss(
        class_names=EYES_CLASSES,
        similar_groups=EYES_SIMILAR_GROUPS,
        class_weights=eyes_weights,
        smoothing=LABEL_SMOOTHING,
        extra_penalty=1.5,
    )

    # â”€â”€ ëª¨ë¸ / Optimizer / Scheduler â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    model = AnomalyMultiBackbone(
        num_cat_skin=len(CAT_SKIN_CLASSES),
        num_dog_skin=len(DOG_SKIN_CLASSES),
        num_eyes=len(EYES_CLASSES),
    ).to(DEVICE)

    model.freeze_backbones()
    print(f"\n  ğŸ”’ Backbone frozen for first {FREEZE_EPOCHS} epochs (head-only training)")

    # [v2] skin_cat_head + skin_dog_head â†’ ë‹¨ì¼ optimizerë¡œ ê´€ë¦¬
    #      backboneì€ cat/dog ìˆœì„œë¡œ ê°ê° ì—…ë°ì´íŠ¸ â†’ ì–‘ìª½ íŠ¹ì§• ëª¨ë‘ í•™ìŠµ
    skin_optimizer = torch.optim.AdamW([
        {"params": model.skin_backbone.parameters(),  "lr": LR_BACKBONE, "weight_decay": 1e-4},
        {"params": model.skin_cat_head.parameters(),  "lr": LR_HEAD,     "weight_decay": 1e-4},
        {"params": model.skin_dog_head.parameters(),  "lr": LR_HEAD,     "weight_decay": 1e-4},
    ])
    eyes_optimizer = torch.optim.AdamW([
        {"params": model.eyes_backbone.parameters(),  "lr": LR_BACKBONE, "weight_decay": 1e-4},
        {"params": model.eyes_se.parameters(),        "lr": LR_HEAD,     "weight_decay": 1e-4},
        {"params": model.eyes_head.parameters(),      "lr": LR_HEAD,     "weight_decay": 1e-4},
    ])

    # scheduler step ìˆ˜: cat ë°°ì¹˜ + dog ë°°ì¹˜ í•©ì‚°
    _skin_cat_batches     = (len(skin_cat_train) + BATCH_SIZE - 1) // BATCH_SIZE
    _skin_dog_batches     = (len(skin_dog_train) + BATCH_SIZE - 1) // BATCH_SIZE
    _skin_steps_per_epoch = _skin_cat_batches + _skin_dog_batches
    _eyes_steps_per_epoch = (len(eyes_train_samples) + BATCH_SIZE - 1) // BATCH_SIZE

    skin_scheduler = get_cosine_schedule_with_warmup(
        skin_optimizer,
        num_warmup_steps  = _skin_steps_per_epoch * 2,          # 2 epoch warmup
        num_training_steps= _skin_steps_per_epoch * EPOCHS,
    )
    eyes_scheduler = get_cosine_schedule_with_warmup(
        eyes_optimizer,
        num_warmup_steps  = _eyes_steps_per_epoch * 3,          # 3 epoch warmup
        num_training_steps= _eyes_steps_per_epoch * EPOCHS,
    )

    skin_scaler = torch.amp.GradScaler("cuda")
    eyes_scaler = torch.amp.GradScaler("cuda")

    history      = []
    best_avg_acc = 0.0
    best_epoch   = 0

    # â”€â”€ Training Loop â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    for epoch in range(EPOCHS):
        print(f"\n{'='*60}")
        print(f"Epoch {epoch + 1}/{EPOCHS}")
        print(f"{'='*60}")

        if epoch == FREEZE_EPOCHS:
            model.unfreeze_backbones()
            print(f"  ğŸ”“ Backbone unfrozen at epoch {epoch+1} "
                  f"(backbone_lr={LR_BACKBONE}, head_lr={LR_HEAD})")

        # â”€â”€ 1. Skin (Cat) Training â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        print("\n[Train 1/3] Skin â€” Cat")
        model.train()

        cat_skin_ds     = AnomalyDataset(skin_cat_train, is_train=True, task="skin")
        cat_skin_loader = DataLoader(
            cat_skin_ds, batch_size=BATCH_SIZE, shuffle=True,
            num_workers=NUM_WORKERS, pin_memory=True,
            persistent_workers=(NUM_WORKERS > 0), prefetch_factor=4,
        )

        cat_loss_sum, cat_correct, cat_total = 0.0, 0, 0
        for images, labels in tqdm(cat_skin_loader, desc=f"  CatSkin Ep{epoch+1:02d}", ncols=110, leave=True):
            images, labels = images.to(DEVICE), labels.to(DEVICE)
            skin_optimizer.zero_grad()
            with torch.amp.autocast("cuda"):
                outputs = model(images, task="skin_cat")
                loss    = skin_cat_criterion(outputs, labels)
            skin_scaler.scale(loss).backward()
            skin_scaler.unscale_(skin_optimizer)
            torch.nn.utils.clip_grad_norm_(
                list(model.skin_backbone.parameters()) +
                list(model.skin_cat_head.parameters()), 1.0
            )
            skin_scaler.step(skin_optimizer)
            skin_scaler.update()
            skin_scheduler.step()

            cat_loss_sum += loss.item() * images.size(0)
            cat_correct  += (outputs.argmax(1) == labels).sum().item()
            cat_total    += images.size(0)

        cat_skin_train_loss = cat_loss_sum / cat_total
        cat_skin_train_acc  = cat_correct  / cat_total

        del cat_skin_ds, cat_skin_loader
        gc.collect(); torch.cuda.empty_cache()

        # â”€â”€ 2. Skin (Dog) Training â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        print("\n[Train 2/3] Skin â€” Dog")
        model.train()

        dog_skin_ds     = AnomalyDataset(skin_dog_train, is_train=True, task="skin")
        dog_skin_loader = DataLoader(
            dog_skin_ds, batch_size=BATCH_SIZE, shuffle=True,
            num_workers=NUM_WORKERS, pin_memory=True,
            persistent_workers=(NUM_WORKERS > 0), prefetch_factor=4,
        )

        dog_loss_sum, dog_correct, dog_total = 0.0, 0, 0
        for images, labels in tqdm(dog_skin_loader, desc=f"  DogSkin Ep{epoch+1:02d}", ncols=110, leave=True):
            images, labels = images.to(DEVICE), labels.to(DEVICE)
            skin_optimizer.zero_grad()
            with torch.amp.autocast("cuda"):
                outputs = model(images, task="skin_dog")
                loss    = skin_dog_criterion(outputs, labels)
            skin_scaler.scale(loss).backward()
            skin_scaler.unscale_(skin_optimizer)
            torch.nn.utils.clip_grad_norm_(
                list(model.skin_backbone.parameters()) +
                list(model.skin_dog_head.parameters()), 1.0
            )
            skin_scaler.step(skin_optimizer)
            skin_scaler.update()
            skin_scheduler.step()

            dog_loss_sum += loss.item() * images.size(0)
            dog_correct  += (outputs.argmax(1) == labels).sum().item()
            dog_total    += images.size(0)

        dog_skin_train_loss = dog_loss_sum / dog_total
        dog_skin_train_acc  = dog_correct  / dog_total

        del dog_skin_ds, dog_skin_loader
        gc.collect(); torch.cuda.empty_cache()

        # â”€â”€ 3. Eyes Training â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        print("\n[Train 3/3] Eyes")
        model.train()

        eyes_train_ds     = AnomalyDataset(eyes_train_samples, is_train=True, task="eyes")
        eyes_train_loader = DataLoader(
            eyes_train_ds, batch_size=BATCH_SIZE, shuffle=True,
            num_workers=NUM_WORKERS, pin_memory=True,
            persistent_workers=(NUM_WORKERS > 0), prefetch_factor=4,
        )

        eyes_loss_sum, eyes_correct, eyes_total = 0.0, 0, 0
        for images, labels in tqdm(eyes_train_loader, desc=f"  Eyes  Ep{epoch+1:02d}", ncols=110, leave=True):
            images, labels = images.to(DEVICE), labels.to(DEVICE)
            eyes_optimizer.zero_grad()
            with torch.amp.autocast("cuda"):
                outputs = model(images, task="eyes")
                loss    = eyes_criterion(outputs, labels)
            eyes_scaler.scale(loss).backward()
            eyes_scaler.unscale_(eyes_optimizer)
            torch.nn.utils.clip_grad_norm_(
                list(model.eyes_backbone.parameters()) +
                list(model.eyes_se.parameters()) +
                list(model.eyes_head.parameters()), 1.0
            )
            eyes_scaler.step(eyes_optimizer)
            eyes_scaler.update()
            eyes_scheduler.step()

            eyes_loss_sum += loss.item() * images.size(0)
            eyes_correct  += (outputs.argmax(1) == labels).sum().item()
            eyes_total    += images.size(0)

        eyes_train_loss = eyes_loss_sum / eyes_total
        eyes_train_acc  = eyes_correct  / eyes_total

        del eyes_train_ds, eyes_train_loader
        gc.collect(); torch.cuda.empty_cache()

        # â”€â”€ 4. Validation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        print("\n[Val] Skin (Cat / Dog) & Eyes")
        model.eval()

        def _run_val(ds_samples, task_str, criterion, desc):
            """ê³µí†µ val ë£¨í”„ í—¬í¼."""
            ds     = AnomalyDataset(ds_samples, is_train=False)
            loader = DataLoader(
                ds, batch_size=BATCH_SIZE, shuffle=False,
                num_workers=NUM_WORKERS // 2, pin_memory=True,
                persistent_workers=(NUM_WORKERS // 2 > 0), prefetch_factor=4,
            )
            loss_sum, correct, total = 0.0, 0, 0
            with torch.no_grad():
                for images, labels in tqdm(loader, desc=desc, ncols=110, leave=False):
                    images, labels = images.to(DEVICE), labels.to(DEVICE)
                    with torch.amp.autocast("cuda"):
                        outputs = model(images, task=task_str)
                        loss    = criterion(outputs, labels)
                    loss_sum += loss.item() * images.size(0)
                    correct  += (outputs.argmax(1) == labels).sum().item()
                    total    += images.size(0)
            del ds, loader
            gc.collect(); torch.cuda.empty_cache()
            return loss_sum / total, correct / total

        cat_skin_val_loss, cat_skin_val_acc = _run_val(
            skin_cat_val, "skin_cat", skin_cat_criterion, "  CatSkin Val"
        )
        dog_skin_val_loss, dog_skin_val_acc = _run_val(
            skin_dog_val, "skin_dog", skin_dog_criterion, "  DogSkin Val"
        )
        eyes_val_loss, eyes_val_acc = _run_val(
            eyes_val_samples, "eyes", eyes_criterion, "  Eyes    Val"
        )

        skin_val_acc = (cat_skin_val_acc + dog_skin_val_acc) / 2
        avg_val_acc  = (cat_skin_val_acc + dog_skin_val_acc + eyes_val_acc) / 3

        print(f"\nğŸ“Š Epoch {epoch+1} Results:")
        print(f"  Skin Cat â”‚ Train Loss: {cat_skin_train_loss:.4f}  Acc: {cat_skin_train_acc*100:.2f}%"
              f"  â”‚  Val Loss: {cat_skin_val_loss:.4f}  Acc: {cat_skin_val_acc*100:.2f}%")
        print(f"  Skin Dog â”‚ Train Loss: {dog_skin_train_loss:.4f}  Acc: {dog_skin_train_acc*100:.2f}%"
              f"  â”‚  Val Loss: {dog_skin_val_loss:.4f}  Acc: {dog_skin_val_acc*100:.2f}%")
        print(f"  Eyes     â”‚ Train Loss: {eyes_train_loss:.4f}  Acc: {eyes_train_acc*100:.2f}%"
              f"  â”‚  Val Loss: {eyes_val_loss:.4f}  Acc: {eyes_val_acc*100:.2f}%")
        print(f"  Skin Avg Val Acc: {skin_val_acc*100:.2f}%  â”‚  "
              f"Overall Avg (cat+dog+eyes)/3: {avg_val_acc*100:.2f}%")

        history.append({
            'epoch'               : epoch + 1,
            'cat_skin_train_loss' : cat_skin_train_loss,
            'cat_skin_train_acc'  : cat_skin_train_acc,
            'cat_skin_val_loss'   : cat_skin_val_loss,
            'cat_skin_val_acc'    : cat_skin_val_acc,
            'dog_skin_train_loss' : dog_skin_train_loss,
            'dog_skin_train_acc'  : dog_skin_train_acc,
            'dog_skin_val_loss'   : dog_skin_val_loss,
            'dog_skin_val_acc'    : dog_skin_val_acc,
            'skin_val_acc'        : skin_val_acc,
            'eyes_train_loss'     : eyes_train_loss,
            'eyes_train_acc'      : eyes_train_acc,
            'eyes_val_loss'       : eyes_val_loss,
            'eyes_val_acc'        : eyes_val_acc,
            'avg_val_acc'         : avg_val_acc,
        })

        if avg_val_acc > best_avg_acc:
            best_avg_acc = avg_val_acc
            best_epoch   = epoch + 1
            torch.save(
                {
                    "model"            : model.state_dict(),
                    "skin_optimizer"   : skin_optimizer.state_dict(),
                    "eyes_optimizer"   : eyes_optimizer.state_dict(),
                    "skin_scheduler"   : skin_scheduler.state_dict(),
                    "eyes_scheduler"   : eyes_scheduler.state_dict(),
                    "epoch"            : epoch + 1,
                    "best_avg_acc"     : best_avg_acc,
                    "skin_classes"     : SKIN_CLASSES,
                    "cat_skin_classes" : CAT_SKIN_CLASSES,
                    "dog_skin_classes" : DOG_SKIN_CLASSES,
                    "eyes_classes"     : EYES_CLASSES,
                    "work_dir"         : WORK_DIR,
                    "history"          : history,
                },
                "pet_abnormal_omni_best.pth",
            )
            print(f"  ğŸ’¾ Saved best model! (Epoch {best_epoch} | Val Avg Acc: {best_avg_acc*100:.2f}%)")

    print(f"\nğŸ† Training Finished.")
    print(f"   Best Epoch: {best_epoch} | Best Val Avg Acc: {best_avg_acc*100:.2f}%")
    print(f"   Test set: {os.path.join(WORK_DIR, 'test')}/")

    # â”€â”€ í•™ìŠµ ê³¡ì„  ì‹œê°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("\nğŸ“ˆ Generating training history plot...")

    epochs_x = [h['epoch'] for h in history]
    fig, axes = plt.subplots(2, 3, figsize=(20, 10))

    # Row 0: Loss
    axes[0, 0].plot(epochs_x, [h['cat_skin_train_loss'] for h in history], 'b-',  label='Train')
    axes[0, 0].plot(epochs_x, [h['cat_skin_val_loss']   for h in history], 'b--', label='Val')
    axes[0, 0].axvline(best_epoch, color='gray', linestyle=':', alpha=0.7)
    axes[0, 0].set_title('Skin Cat Loss'); axes[0, 0].legend(); axes[0, 0].grid(True, alpha=0.3)

    axes[0, 1].plot(epochs_x, [h['dog_skin_train_loss'] for h in history], 'g-',  label='Train')
    axes[0, 1].plot(epochs_x, [h['dog_skin_val_loss']   for h in history], 'g--', label='Val')
    axes[0, 1].axvline(best_epoch, color='gray', linestyle=':', alpha=0.7)
    axes[0, 1].set_title('Skin Dog Loss'); axes[0, 1].legend(); axes[0, 1].grid(True, alpha=0.3)

    axes[0, 2].plot(epochs_x, [h['eyes_train_loss'] for h in history], 'r-',  label='Train')
    axes[0, 2].plot(epochs_x, [h['eyes_val_loss']   for h in history], 'r--', label='Val')
    axes[0, 2].axvline(best_epoch, color='gray', linestyle=':', alpha=0.7)
    axes[0, 2].set_title('Eyes Loss'); axes[0, 2].legend(); axes[0, 2].grid(True, alpha=0.3)

    # Row 1: Accuracy
    axes[1, 0].plot(epochs_x, [h['cat_skin_train_acc'] for h in history], 'b-',  label='Train')
    axes[1, 0].plot(epochs_x, [h['cat_skin_val_acc']   for h in history], 'b--', label='Val')
    axes[1, 0].axvline(best_epoch, color='gray', linestyle=':', alpha=0.7)
    axes[1, 0].set_title('Skin Cat Accuracy'); axes[1, 0].set_ylim(0, 1)
    axes[1, 0].legend(); axes[1, 0].grid(True, alpha=0.3)

    axes[1, 1].plot(epochs_x, [h['dog_skin_train_acc'] for h in history], 'g-',  label='Train')
    axes[1, 1].plot(epochs_x, [h['dog_skin_val_acc']   for h in history], 'g--', label='Val')
    axes[1, 1].axvline(best_epoch, color='gray', linestyle=':', alpha=0.7)
    axes[1, 1].set_title('Skin Dog Accuracy'); axes[1, 1].set_ylim(0, 1)
    axes[1, 1].legend(); axes[1, 1].grid(True, alpha=0.3)

    axes[1, 2].plot(epochs_x, [h['eyes_train_acc'] for h in history], 'r-',  label='Train')
    axes[1, 2].plot(epochs_x, [h['eyes_val_acc']   for h in history], 'r--', label='Val')
    axes[1, 2].axvline(best_epoch, color='gray', linestyle=':', alpha=0.7)
    axes[1, 2].set_title('Eyes Accuracy'); axes[1, 2].set_ylim(0, 1)
    axes[1, 2].legend(); axes[1, 2].grid(True, alpha=0.3)

    plt.suptitle(
        f'Anomaly Model v2 (EfficientNet-V2-S) | Best Ep {best_epoch} | Avg {best_avg_acc*100:.1f}%',
        fontsize=13, fontweight='bold'
    )
    plt.tight_layout()
    plt.savefig('pet_abnormal_omni_history.png', dpi=150, bbox_inches='tight')
    plt.close()
    print("  âœ… Saved: pet_abnormal_omni_history.png")


def _load_samples_from_dir(task_dir: str, class_names: list) -> list:
    """
    WORK_DIR í•˜ìœ„ task í´ë”ì—ì„œ samples ë¦¬ìŠ¤íŠ¸ë¥¼ ë³µì›í•œë‹¤.
    (ì¬í•™ìŠµ ì‹œ íŒŒì¼ ë³µì‚¬ë¥¼ skipí•˜ê³  ê¸°ì¡´ WORK_DIRì—ì„œ ë°”ë¡œ ë¡œë“œ)
    """
    name_to_idx = {n: i for i, n in enumerate(class_names)}
    samples     = []
    for class_name in sorted(os.listdir(task_dir)):
        class_dir = os.path.join(task_dir, class_name)
        if not os.path.isdir(class_dir) or class_name not in name_to_idx:
            continue
        label_idx = name_to_idx[class_name]
        for fname in os.listdir(class_dir):
            if fname.lower().endswith((".jpg", ".jpeg", ".png")):
                samples.append((os.path.join(class_dir, fname), label_idx))
    return samples


# ===============================
# ENTRY POINT
# ===============================

if __name__ == "__main__":
    train()
