{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "790f7a53",
   "metadata": {},
   "source": [
    "## í´ë˜ìŠ¤ë³„ íŒŒì¼ ê°œìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5a2acf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               JPG Count\n",
      "dog_happy          17355\n",
      "dog_sad            14206\n",
      "dog_anxious        11590\n",
      "dog_relaxed         8699\n",
      "dog_angry           8564\n",
      "dog_confused        3286\n",
      "cat_relaxed         2999\n",
      "cat_happy           1221\n",
      "cat_attentive        997\n",
      "cat_sad              171\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "import pandas as pd  # í…Œì´ë¸” ë³´ê¸° í¸í•¨\n",
    "\n",
    "root_dir = Path('./files/2_Animal_emotions')\n",
    "jpg_counts = Counter()\n",
    "\n",
    "# 1_Animal_Behavior ë°”ë¡œ ì•„ë˜ í´ë”ë§Œ ëŒ€ìƒ\n",
    "for subdir in root_dir.iterdir():\n",
    "    if subdir.is_dir():\n",
    "        jpg_count = len(list(subdir.rglob('*.jpg')))\n",
    "        jpg_counts[subdir.name] = jpg_count\n",
    "\n",
    "# í…Œì´ë¸” ì¶œë ¥\n",
    "df = pd.DataFrame.from_dict(jpg_counts, orient='index', columns=['JPG Count']).sort_values('JPG Count', ascending=False)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dd1319",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b3e32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ Device: cuda:1\n",
      "\n",
      "ğŸ“¦ Collecting behavior...\n",
      "  â†’ 757113 samples, 25 classes\n",
      "  ğŸ¯ Target: 100000 samples\n",
      "  ğŸ“Š 25 classes â†’ max 4000 per class\n",
      "    CAT_ARCH: 2296/2296\n",
      "    CAT_ARMSTRETCH: 4000/38483\n",
      "    CAT_FOOTPUSH: 4000/9517\n",
      "    CAT_GETDOWN: 4000/13421\n",
      "    CAT_GROOMING: 4000/65029\n",
      "    CAT_HEADING: 4000/11237\n",
      "    CAT_LAYDOWN: 4000/21474\n",
      "    CAT_LYING: 4000/12119\n",
      "    CAT_ROLL: 4000/8513\n",
      "    CAT_SITDOWN: 4000/18401\n",
      "    CAT_TAILING: 4000/36960\n",
      "    CAT_WALKRUN: 4000/30498\n",
      "    DOG_BODYLOWER: 4000/79772\n",
      "    DOG_BODYSCRATCH: 4000/15783\n",
      "    DOG_BODYSHAKE: 4000/15296\n",
      "    DOG_FEETUP: 4000/34365\n",
      "    DOG_FOOTUP: 4000/52506\n",
      "    DOG_HEADING: 4000/19052\n",
      "    DOG_LYING: 4000/32129\n",
      "    DOG_MOUNTING: 4000/5211\n",
      "    DOG_SIT: 4000/79182\n",
      "    DOG_TAILING: 4000/35824\n",
      "    DOG_TAILLOW: 4000/8376\n",
      "    DOG_TURN: 4000/21554\n",
      "    DOG_WALKRUN: 4000/90115\n",
      "  âœ… Total sampled: 98296\n",
      "\n",
      "ğŸ“¦ Collecting emotion...\n",
      "  â†’ 69113 samples, 10 classes\n",
      "  ğŸ¯ Target: 100000 samples\n",
      "  ğŸ“Š 10 classes â†’ max 10000 per class\n",
      "    cat_attentive: 997/997\n",
      "    cat_happy: 1221/1221\n",
      "    cat_relaxed: 2999/2999\n",
      "    cat_sad: 171/171\n",
      "    dog_angry: 8589/8589\n",
      "    dog_anxious : 10000/11590\n",
      "    dog_confused: 3286/3286\n",
      "    dog_happy: 10000/17355\n",
      "    dog_relaxed: 8699/8699\n",
      "    dog_sad: 10000/14206\n",
      "  âœ… Total sampled: 55962\n",
      "\n",
      "ğŸ“¦ Collecting sound...\n",
      "  â†’ 1248 samples, 16 classes\n",
      "  ğŸ¯ Min samples per class: 50\n",
      "    cat_aggressive: 50/20\n",
      "    cat_huntingMind: 30/10\n",
      "    cat_mating: 30/10\n",
      "    cat_paining: 30/10\n",
      "    cat_positive: 50/20\n",
      "    cat_resting: 30/10\n",
      "    cat_threat: 50/19\n",
      "    dog_bark: 632/316\n",
      "    dog_breath: 124/62\n",
      "    dog_cough: 230/115\n",
      "    dog_growl: 130/65\n",
      "    dog_howling: 302/151\n",
      "    dog_playing: 182/91\n",
      "    dog_sneeze: 220/110\n",
      "    dog_tracheal_collapse: 178/89\n",
      "    dog_whining: 300/150\n",
      "  âœ… Total sampled: 2568\n",
      "\n",
      "ğŸ“‹ Splitting & Copying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Dataset ready\n",
      "\n",
      "ğŸ”„ Loading datasets...\n",
      "  ğŸ“Š behavior: 11884 samples, 25 classes\n",
      "  ğŸ“Š behavior: 5276 samples, 25 classes\n",
      "  ğŸ“Š emotion: 44766 samples, 10 classes\n",
      "  ğŸ“Š emotion: 5592 samples, 10 classes\n",
      "  ğŸ“Š sound: 1014 samples, 16 classes, augment=True\n",
      "  ğŸ“Š sound: 234 samples, 16 classes, augment=False\n",
      "\n",
      "ğŸ“¦ DataLoaders:\n",
      "  Behavior: 743 train batches, 330 val batches\n",
      "  Emotion: 2798 train batches, 350 val batches\n",
      "  Sound: 64 train batches, 15 val batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 211/211 [00:00<00:00, 528.54it/s, Materializing param=wav2vec2.masked_spec_embed]                                            \n",
      "\u001b[1mWav2Vec2ForSequenceClassification LOAD REPORT\u001b[0m from: facebook/wav2vec2-base\n",
      "Key                          | Status     | \n",
      "-----------------------------+------------+-\n",
      "project_hid.weight           | UNEXPECTED | \n",
      "quantizer.codevectors        | UNEXPECTED | \n",
      "quantizer.weight_proj.weight | UNEXPECTED | \n",
      "project_q.weight             | UNEXPECTED | \n",
      "project_hid.bias             | UNEXPECTED | \n",
      "quantizer.weight_proj.bias   | UNEXPECTED | \n",
      "project_q.bias               | UNEXPECTED | \n",
      "projector.bias               | MISSING    | \n",
      "classifier.bias              | MISSING    | \n",
      "classifier.weight            | MISSING    | \n",
      "projector.weight             | MISSING    | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\u001b[3m\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Epoch 1/30\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 2.5759\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.5105\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sound:   0%|          | 0/64 [00:00<?, ?it/s]/tmp/ipykernel_1870996/62025557.py:475: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  audio_scheduler.step()  # ğŸ”¥ Scheduler\n",
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.6593\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 2.5759 | Acc 0.4737 (47.4%)\n",
      "  Emotion:  Loss 1.5105 | Acc 0.6445 (64.4%)\n",
      "  Sound:    Loss 1.6593 | Acc 0.2094 (20.9%)\n",
      "  Average Acc: 0.4425 (44.3%)\n",
      "  ğŸ’¾ Saved new best model! (Acc: 0.4425)\n",
      "\n",
      "============================================================\n",
      "Epoch 2/30\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 2.1043\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.4145\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.6344\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 2.1043 | Acc 0.5533 (55.3%)\n",
      "  Emotion:  Loss 1.4145 | Acc 0.6758 (67.6%)\n",
      "  Sound:    Loss 1.6344 | Acc 0.2265 (22.6%)\n",
      "  Average Acc: 0.4852 (48.5%)\n",
      "  ğŸ’¾ Saved new best model! (Acc: 0.4852)\n",
      "\n",
      "============================================================\n",
      "Epoch 3/30\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.9115\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.3625\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.5753\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 1.9115 | Acc 0.5953 (59.5%)\n",
      "  Emotion:  Loss 1.3625 | Acc 0.6951 (69.5%)\n",
      "  Sound:    Loss 1.5753 | Acc 0.3419 (34.2%)\n",
      "  Average Acc: 0.5441 (54.4%)\n",
      "  ğŸ’¾ Saved new best model! (Acc: 0.5441)\n",
      "\n",
      "============================================================\n",
      "Epoch 4/30\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.7590\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.3302\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.5030\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 1.7590 | Acc 0.6365 (63.6%)\n",
      "  Emotion:  Loss 1.3302 | Acc 0.6951 (69.5%)\n",
      "  Sound:    Loss 1.5030 | Acc 0.4188 (41.9%)\n",
      "  Average Acc: 0.5835 (58.3%)\n",
      "  ğŸ’¾ Saved new best model! (Acc: 0.5835)\n",
      "\n",
      "============================================================\n",
      "Epoch 5/30\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.6864\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.2991\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.4465\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 1.6864 | Acc 0.6499 (65.0%)\n",
      "  Emotion:  Loss 1.2991 | Acc 0.7132 (71.3%)\n",
      "  Sound:    Loss 1.4465 | Acc 0.4786 (47.9%)\n",
      "  Average Acc: 0.6139 (61.4%)\n",
      "  ğŸ’¾ Saved new best model! (Acc: 0.6139)\n",
      "\n",
      "============================================================\n",
      "Epoch 6/30\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.6112\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.2599\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.3987\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 1.6112 | Acc 0.6653 (66.5%)\n",
      "  Emotion:  Loss 1.2599 | Acc 0.7039 (70.4%)\n",
      "  Sound:    Loss 1.3987 | Acc 0.5085 (50.9%)\n",
      "  Average Acc: 0.6259 (62.6%)\n",
      "  ğŸ’¾ Saved new best model! (Acc: 0.6259)\n",
      "\n",
      "============================================================\n",
      "Epoch 7/30\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.5614\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.2410\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.3478\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 1.5614 | Acc 0.6784 (67.8%)\n",
      "  Emotion:  Loss 1.2410 | Acc 0.7235 (72.4%)\n",
      "  Sound:    Loss 1.3478 | Acc 0.5128 (51.3%)\n",
      "  Average Acc: 0.6382 (63.8%)\n",
      "  ğŸ’¾ Saved new best model! (Acc: 0.6382)\n",
      "\n",
      "============================================================\n",
      "Epoch 8/30\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.5103\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.2220\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.3129\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 1.5103 | Acc 0.6768 (67.7%)\n",
      "  Emotion:  Loss 1.2220 | Acc 0.7210 (72.1%)\n",
      "  Sound:    Loss 1.3129 | Acc 0.5513 (55.1%)\n",
      "  Average Acc: 0.6497 (65.0%)\n",
      "  ğŸ’¾ Saved new best model! (Acc: 0.6497)\n",
      "\n",
      "============================================================\n",
      "Epoch 9/30\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.4838\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.2044\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.2669\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 1.4838 | Acc 0.6869 (68.7%)\n",
      "  Emotion:  Loss 1.2044 | Acc 0.7335 (73.4%)\n",
      "  Sound:    Loss 1.2669 | Acc 0.5171 (51.7%)\n",
      "  Average Acc: 0.6458 (64.6%)\n",
      "\n",
      "============================================================\n",
      "Epoch 10/30\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.4580\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.1840\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.2140\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 1.4580 | Acc 0.6854 (68.5%)\n",
      "  Emotion:  Loss 1.1840 | Acc 0.7334 (73.3%)\n",
      "  Sound:    Loss 1.2140 | Acc 0.6026 (60.3%)\n",
      "  Average Acc: 0.6738 (67.4%)\n",
      "  ğŸ’¾ Saved new best model! (Acc: 0.6738)\n",
      "\n",
      "============================================================\n",
      "Epoch 11/30\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.4824\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.1672\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.1774\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 1.4824 | Acc 0.6935 (69.4%)\n",
      "  Emotion:  Loss 1.1672 | Acc 0.7300 (73.0%)\n",
      "  Sound:    Loss 1.1774 | Acc 0.6282 (62.8%)\n",
      "  Average Acc: 0.6839 (68.4%)\n",
      "  ğŸ’¾ Saved new best model! (Acc: 0.6839)\n",
      "\n",
      "============================================================\n",
      "Epoch 12/30\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.4816\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.1676\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.1462\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 1.4816 | Acc 0.6958 (69.6%)\n",
      "  Emotion:  Loss 1.1676 | Acc 0.7437 (74.4%)\n",
      "  Sound:    Loss 1.1462 | Acc 0.6496 (65.0%)\n",
      "  Average Acc: 0.6964 (69.6%)\n",
      "  ğŸ’¾ Saved new best model! (Acc: 0.6964)\n",
      "\n",
      "============================================================\n",
      "Epoch 13/30\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.4426\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.1477\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.0959\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 1.4426 | Acc 0.6941 (69.4%)\n",
      "  Emotion:  Loss 1.1477 | Acc 0.7541 (75.4%)\n",
      "  Sound:    Loss 1.0959 | Acc 0.6410 (64.1%)\n",
      "  Average Acc: 0.6964 (69.6%)\n",
      "  ğŸ’¾ Saved new best model! (Acc: 0.6964)\n",
      "\n",
      "============================================================\n",
      "Epoch 14/30\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.4328\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.1455\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.0760\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 1.4328 | Acc 0.6975 (69.7%)\n",
      "  Emotion:  Loss 1.1455 | Acc 0.7480 (74.8%)\n",
      "  Sound:    Loss 1.0760 | Acc 0.6667 (66.7%)\n",
      "  Average Acc: 0.7041 (70.4%)\n",
      "  ğŸ’¾ Saved new best model! (Acc: 0.7041)\n",
      "\n",
      "============================================================\n",
      "Epoch 15/30\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.4099\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.1394\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.0232\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 1.4099 | Acc 0.7047 (70.5%)\n",
      "  Emotion:  Loss 1.1394 | Acc 0.7484 (74.8%)\n",
      "  Sound:    Loss 1.0232 | Acc 0.6410 (64.1%)\n",
      "  Average Acc: 0.6980 (69.8%)\n",
      "\n",
      "============================================================\n",
      "Epoch 16/30\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.4009\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.1245\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.9861\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 1.4009 | Acc 0.7002 (70.0%)\n",
      "  Emotion:  Loss 1.1245 | Acc 0.7191 (71.9%)\n",
      "  Sound:    Loss 0.9861 | Acc 0.6838 (68.4%)\n",
      "  Average Acc: 0.7010 (70.1%)\n",
      "\n",
      "============================================================\n",
      "Epoch 17/30\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.3990\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.1284\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.9584\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 1.3990 | Acc 0.7045 (70.5%)\n",
      "  Emotion:  Loss 1.1284 | Acc 0.7327 (73.3%)\n",
      "  Sound:    Loss 0.9584 | Acc 0.6368 (63.7%)\n",
      "  Average Acc: 0.6913 (69.1%)\n",
      "\n",
      "============================================================\n",
      "Epoch 18/30\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.3870\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.1277\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.9207\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 1.3870 | Acc 0.7132 (71.3%)\n",
      "  Emotion:  Loss 1.1277 | Acc 0.7348 (73.5%)\n",
      "  Sound:    Loss 0.9207 | Acc 0.7137 (71.4%)\n",
      "  Average Acc: 0.7206 (72.1%)\n",
      "  ğŸ’¾ Saved new best model! (Acc: 0.7206)\n",
      "\n",
      "============================================================\n",
      "Epoch 19/30\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.4027\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.1137\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.9031\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 1.4027 | Acc 0.7055 (70.5%)\n",
      "  Emotion:  Loss 1.1137 | Acc 0.7487 (74.9%)\n",
      "  Sound:    Loss 0.9031 | Acc 0.6880 (68.8%)\n",
      "  Average Acc: 0.7141 (71.4%)\n",
      "\n",
      "============================================================\n",
      "Epoch 20/30\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.3429\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.1040\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.8662\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 1.3429 | Acc 0.7092 (70.9%)\n",
      "  Emotion:  Loss 1.1040 | Acc 0.7359 (73.6%)\n",
      "  Sound:    Loss 0.8662 | Acc 0.7265 (72.6%)\n",
      "  Average Acc: 0.7239 (72.4%)\n",
      "  ğŸ’¾ Saved new best model! (Acc: 0.7239)\n",
      "\n",
      "============================================================\n",
      "Epoch 21/30\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.3515\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.0959\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.8618\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 1.3515 | Acc 0.7083 (70.8%)\n",
      "  Emotion:  Loss 1.0959 | Acc 0.7446 (74.5%)\n",
      "  Sound:    Loss 0.8618 | Acc 0.6838 (68.4%)\n",
      "  Average Acc: 0.7122 (71.2%)\n",
      "\n",
      "============================================================\n",
      "Epoch 22/30\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.3242\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.0965\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.8325\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 1.3242 | Acc 0.7151 (71.5%)\n",
      "  Emotion:  Loss 1.0965 | Acc 0.7500 (75.0%)\n",
      "  Sound:    Loss 0.8325 | Acc 0.7222 (72.2%)\n",
      "  Average Acc: 0.7291 (72.9%)\n",
      "  ğŸ’¾ Saved new best model! (Acc: 0.7291)\n",
      "\n",
      "============================================================\n",
      "Epoch 23/30\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.3704\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.0932\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.8138\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 1.3704 | Acc 0.7056 (70.6%)\n",
      "  Emotion:  Loss 1.0932 | Acc 0.7276 (72.8%)\n",
      "  Sound:    Loss 0.8138 | Acc 0.7607 (76.1%)\n",
      "  Average Acc: 0.7313 (73.1%)\n",
      "  ğŸ’¾ Saved new best model! (Acc: 0.7313)\n",
      "\n",
      "============================================================\n",
      "Epoch 24/30\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.3693\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.0950\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.7929\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 1.3693 | Acc 0.7130 (71.3%)\n",
      "  Emotion:  Loss 1.0950 | Acc 0.7604 (76.0%)\n",
      "  Sound:    Loss 0.7929 | Acc 0.7479 (74.8%)\n",
      "  Average Acc: 0.7404 (74.0%)\n",
      "  ğŸ’¾ Saved new best model! (Acc: 0.7404)\n",
      "\n",
      "============================================================\n",
      "Epoch 25/30\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.3497\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.0866\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.7773\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 1.3497 | Acc 0.7081 (70.8%)\n",
      "  Emotion:  Loss 1.0866 | Acc 0.7609 (76.1%)\n",
      "  Sound:    Loss 0.7773 | Acc 0.7692 (76.9%)\n",
      "  Average Acc: 0.7461 (74.6%)\n",
      "  ğŸ’¾ Saved new best model! (Acc: 0.7461)\n",
      "\n",
      "============================================================\n",
      "Epoch 26/30\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.3401\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.0827\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.7718\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 1.3401 | Acc 0.7237 (72.4%)\n",
      "  Emotion:  Loss 1.0827 | Acc 0.7421 (74.2%)\n",
      "  Sound:    Loss 0.7718 | Acc 0.7436 (74.4%)\n",
      "  Average Acc: 0.7365 (73.6%)\n",
      "\n",
      "============================================================\n",
      "Epoch 27/30\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.3252\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.0831\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.7536\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 1.3252 | Acc 0.7168 (71.7%)\n",
      "  Emotion:  Loss 1.0831 | Acc 0.7461 (74.6%)\n",
      "  Sound:    Loss 0.7536 | Acc 0.7607 (76.1%)\n",
      "  Average Acc: 0.7412 (74.1%)\n",
      "\n",
      "============================================================\n",
      "Epoch 28/30\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.3155\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.0789\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.7393\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 1.3155 | Acc 0.7147 (71.5%)\n",
      "  Emotion:  Loss 1.0789 | Acc 0.7439 (74.4%)\n",
      "  Sound:    Loss 0.7393 | Acc 0.7821 (78.2%)\n",
      "  Average Acc: 0.7469 (74.7%)\n",
      "  ğŸ’¾ Saved new best model! (Acc: 0.7469)\n",
      "\n",
      "============================================================\n",
      "Epoch 29/30\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.3260\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.0798\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.7236\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 1.3260 | Acc 0.7111 (71.1%)\n",
      "  Emotion:  Loss 1.0798 | Acc 0.7523 (75.2%)\n",
      "  Sound:    Loss 0.7236 | Acc 0.7906 (79.1%)\n",
      "  Average Acc: 0.7514 (75.1%)\n",
      "  ğŸ’¾ Saved new best model! (Acc: 0.7514)\n",
      "\n",
      "============================================================\n",
      "Epoch 30/30\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.3356\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.0616\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.7275\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 1.3356 | Acc 0.7140 (71.4%)\n",
      "  Emotion:  Loss 1.0616 | Acc 0.7552 (75.5%)\n",
      "  Sound:    Loss 0.7275 | Acc 0.7906 (79.1%)\n",
      "  Average Acc: 0.7533 (75.3%)\n",
      "  ğŸ’¾ Saved new best model! (Acc: 0.7533)\n",
      "\n",
      "ğŸ“ˆ Generating training history plot...\n",
      "  âœ… Saved: pet_omni_improved_history.png\n",
      "\n",
      "ğŸ‰ Training Finished!\n",
      "  Best Average Acc: 0.7533 (75.3%)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import Wav2Vec2ForSequenceClassification, Wav2Vec2FeatureExtractor, get_linear_schedule_with_warmup\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet34, ResNet34_Weights\n",
    "from PIL import Image\n",
    "import librosa\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# =========================\n",
    "# 0. ì„¤ì •\n",
    "# =========================\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "BEHAVIOR_ROOT = \"files/1_Animal_Behavior\"\n",
    "EMOTION_ROOT = \"files/2_Animal_emotions\"\n",
    "SOUND_ROOT = \"files/3_Animal_Sound\"\n",
    "WORK_DIR = \"files/work/omni_dataset\"\n",
    "\n",
    "MAX_SAMPLES_BEHAVIOR = 100000\n",
    "MAX_SAMPLES_EMOTION = 100000\n",
    "MIN_SAMPLES_PER_SOUND_CLASS = 50  # ğŸ”¥ Sound ì˜¤ë²„ìƒ˜í”Œë§\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 30\n",
    "LR_VIDEO = 5e-5\n",
    "LR_AUDIO = 1e-5  # ğŸ”¥ Backboneë„ í•™ìŠµí•˜ë¯€ë¡œ ë‚®ì€ LR\n",
    "DEVICE = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "NUM_WORKERS = 24\n",
    "SR = 16000\n",
    "MAX_AUDIO_LEN = SR * 5\n",
    "\n",
    "LOSS_WEIGHTS = {\n",
    "    \"behavior\": 1.0,\n",
    "    \"emotion\": 0.8,\n",
    "    \"sound\": 0.6\n",
    "}\n",
    "\n",
    "AUDIO_MODEL_NAME = \"facebook/wav2vec2-base\"\n",
    "FEATURE_EXTRACTOR = Wav2Vec2FeatureExtractor.from_pretrained(AUDIO_MODEL_NAME)\n",
    "\n",
    "print(f\"ğŸ¯ Device: {DEVICE}\")\n",
    "\n",
    "# =========================\n",
    "# ğŸ”¥ Audio Augmentation\n",
    "# =========================\n",
    "def augment_audio(waveform, p=0.5):\n",
    "    \"\"\"ì˜¤ë””ì˜¤ ì¦ê°•\"\"\"\n",
    "    if random.random() > p:\n",
    "        return waveform\n",
    "    \n",
    "    # Pitch shift\n",
    "    n_steps = random.uniform(-2, 2)\n",
    "    waveform = librosa.effects.pitch_shift(waveform, sr=SR, n_steps=n_steps)\n",
    "    \n",
    "    # Time stretch\n",
    "    rate = random.uniform(0.9, 1.1)\n",
    "    stretched = librosa.effects.time_stretch(waveform, rate=rate)\n",
    "    if len(stretched) > MAX_AUDIO_LEN:\n",
    "        stretched = stretched[:MAX_AUDIO_LEN]\n",
    "    else:\n",
    "        stretched = np.pad(stretched, (0, MAX_AUDIO_LEN - len(stretched)))\n",
    "    waveform = stretched\n",
    "    \n",
    "    # Add noise\n",
    "    noise = np.random.normal(0, 0.003, len(waveform))\n",
    "    waveform = waveform * 0.99 + noise\n",
    "    \n",
    "    return waveform\n",
    "\n",
    "# =========================\n",
    "# 1. Dataset Preparation\n",
    "# =========================\n",
    "def collect_samples(root, exts):\n",
    "    samples = []\n",
    "    for class_dir in sorted(os.listdir(root)):\n",
    "        class_path = os.path.join(root, class_dir)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "        \n",
    "        for root_dir, _, files in os.walk(class_path):\n",
    "            for filename in files:\n",
    "                if any(filename.lower().endswith(ext) for ext in exts):\n",
    "                    file_path = os.path.join(root_dir, filename)\n",
    "                    samples.append((class_dir, file_path))\n",
    "    \n",
    "    print(f\"  â†’ {len(samples)} samples, {len(set(s[0] for s in samples))} classes\")\n",
    "    return samples\n",
    "\n",
    "def sample_balanced(samples, max_total_samples):\n",
    "    class_samples = defaultdict(list)\n",
    "    for label, path in samples:\n",
    "        class_samples[label].append(path)\n",
    "    \n",
    "    num_classes = len(class_samples)\n",
    "    max_per_class = max_total_samples // num_classes\n",
    "    \n",
    "    print(f\"  ğŸ¯ Target: {max_total_samples} samples\")\n",
    "    print(f\"  ğŸ“Š {num_classes} classes â†’ max {max_per_class} per class\")\n",
    "    \n",
    "    sampled = []\n",
    "    for label, paths in class_samples.items():\n",
    "        n_samples = min(len(paths), max_per_class)\n",
    "        selected = random.sample(paths, n_samples)\n",
    "        sampled.extend([(label, p) for p in selected])\n",
    "        print(f\"    {label}: {n_samples}/{len(paths)}\")\n",
    "    \n",
    "    print(f\"  âœ… Total sampled: {len(sampled)}\")\n",
    "    return sampled\n",
    "\n",
    "def sample_balanced_audio(samples, min_per_class):\n",
    "    \"\"\"ğŸ”¥ Soundìš© ì˜¤ë²„ìƒ˜í”Œë§\"\"\"\n",
    "    class_samples = defaultdict(list)\n",
    "    for label, path in samples:\n",
    "        class_samples[label].append(path)\n",
    "    \n",
    "    print(f\"  ğŸ¯ Min samples per class: {min_per_class}\")\n",
    "    \n",
    "    sampled = []\n",
    "    for label, paths in class_samples.items():\n",
    "        # ì˜¤ë²„ìƒ˜í”Œë§ (ë¶€ì¡±í•œ í´ë˜ìŠ¤ëŠ” ì¤‘ë³µ í—ˆìš©)\n",
    "        n_needed = max(min_per_class, len(paths) * 2)\n",
    "        selected = random.choices(paths, k=min(n_needed, len(paths) * 3))\n",
    "        sampled.extend([(label, p) for p in selected])\n",
    "        print(f\"    {label}: {len(selected)}/{len(paths)}\")\n",
    "    \n",
    "    print(f\"  âœ… Total sampled: {len(sampled)}\")\n",
    "    return sampled\n",
    "\n",
    "def split_and_copy(samples, task_name):\n",
    "    random.shuffle(samples)\n",
    "    class_samples = defaultdict(list)\n",
    "    \n",
    "    for label, path in samples:\n",
    "        class_samples[label].append(path)\n",
    "    \n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        os.makedirs(os.path.join(WORK_DIR, split, task_name), exist_ok=True)\n",
    "    \n",
    "    for label, paths in class_samples.items():\n",
    "        n = len(paths)\n",
    "        n_train = int(n * 0.8)\n",
    "        n_val = int(n * 0.1)\n",
    "        \n",
    "        splits = {\n",
    "            \"train\": paths[:n_train],\n",
    "            \"val\": paths[n_train:n_train+n_val],\n",
    "            \"test\": paths[n_train+n_val:]\n",
    "        }\n",
    "        \n",
    "        for split_name, split_paths in splits.items():\n",
    "            for src in tqdm(split_paths, desc=f\"{task_name}/{split_name}/{label}\", leave=False):\n",
    "                dst_dir = os.path.join(WORK_DIR, split_name, task_name, label)\n",
    "                os.makedirs(dst_dir, exist_ok=True)\n",
    "                \n",
    "                dst_path = os.path.join(dst_dir, f\"{label}_{os.path.basename(src)}\")\n",
    "                shutil.copy(src, dst_path)\n",
    "\n",
    "def prepare_dataset():\n",
    "    if os.path.exists(WORK_DIR):\n",
    "        shutil.rmtree(WORK_DIR)\n",
    "    \n",
    "    print(\"\\nğŸ“¦ Collecting behavior...\")\n",
    "    behavior_all = collect_samples(BEHAVIOR_ROOT, ['.jpg', '.png', '.jpeg'])\n",
    "    behavior = sample_balanced(behavior_all, MAX_SAMPLES_BEHAVIOR)\n",
    "    \n",
    "    print(\"\\nğŸ“¦ Collecting emotion...\")\n",
    "    emotion_all = collect_samples(EMOTION_ROOT, ['.jpg', '.png', '.jpeg'])\n",
    "    emotion = sample_balanced(emotion_all, MAX_SAMPLES_EMOTION)\n",
    "    \n",
    "    print(\"\\nğŸ“¦ Collecting sound...\")\n",
    "    sound_all = collect_samples(SOUND_ROOT, ['.wav', '.mp3', '.m4a'])\n",
    "    sound = sample_balanced_audio(sound_all, MIN_SAMPLES_PER_SOUND_CLASS)  # ğŸ”¥ ì˜¤ë²„ìƒ˜í”Œë§\n",
    "    \n",
    "    print(\"\\nğŸ“‹ Splitting & Copying...\")\n",
    "    split_and_copy(behavior, \"behavior\")\n",
    "    split_and_copy(emotion, \"emotion\")\n",
    "    split_and_copy(sound, \"sound\")\n",
    "    \n",
    "    print(\"\\nâœ… Dataset ready\")\n",
    "\n",
    "# =========================\n",
    "# 2. Dataset Classes\n",
    "# =========================\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, task_dir, augment=False):\n",
    "        self.samples = []\n",
    "        self.label_to_id = {}\n",
    "        \n",
    "        for label in sorted(os.listdir(task_dir)):\n",
    "            label_dir = os.path.join(task_dir, label)\n",
    "            if not os.path.isdir(label_dir):\n",
    "                continue\n",
    "            \n",
    "            self.label_to_id[label] = len(self.label_to_id)\n",
    "            \n",
    "            for file in os.listdir(label_dir):\n",
    "                if file.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
    "                    self.samples.append((os.path.join(label_dir, file), label))\n",
    "        \n",
    "        print(f\"  ğŸ“Š {os.path.basename(task_dir)}: {len(self.samples)} samples, {len(self.label_to_id)} classes\")\n",
    "        \n",
    "        if augment:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize((256,256)),\n",
    "                transforms.RandomCrop(224),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ColorJitter(0.2, 0.2, 0.2),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize((224,224)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "            ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.samples[idx]\n",
    "        img = Image.open(path).convert(\"RGB\")\n",
    "        img = self.transform(img)\n",
    "        return img, self.label_to_id[label]\n",
    "\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, task_dir, augment=False):\n",
    "        self.samples = []\n",
    "        self.label_to_id = {}\n",
    "        self.augment = augment  # ğŸ”¥ ì¦ê°• í”Œë˜ê·¸\n",
    "        \n",
    "        for label in sorted(os.listdir(task_dir)):\n",
    "            label_dir = os.path.join(task_dir, label)\n",
    "            if not os.path.isdir(label_dir):\n",
    "                continue\n",
    "            \n",
    "            self.label_to_id[label] = len(self.label_to_id)\n",
    "            \n",
    "            for file in os.listdir(label_dir):\n",
    "                if file.lower().endswith(('.wav','.mp3','.m4a')):\n",
    "                    self.samples.append((os.path.join(label_dir,file), label))\n",
    "        \n",
    "        print(f\"  ğŸ“Š {os.path.basename(task_dir)}: {len(self.samples)} samples, {len(self.label_to_id)} classes, augment={augment}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.samples[idx]\n",
    "        \n",
    "        try:\n",
    "            waveform, _ = librosa.load(path, sr=SR, mono=True)\n",
    "        except:\n",
    "            waveform = np.zeros(MAX_AUDIO_LEN)\n",
    "        \n",
    "        # ğŸ”¥ ì¦ê°• ì ìš©\n",
    "        if self.augment:\n",
    "            waveform = augment_audio(waveform)\n",
    "        \n",
    "        if len(waveform) > MAX_AUDIO_LEN:\n",
    "            waveform = waveform[:MAX_AUDIO_LEN]\n",
    "        else:\n",
    "            waveform = np.pad(waveform,(0,MAX_AUDIO_LEN-len(waveform)))\n",
    "        \n",
    "        inputs = FEATURE_EXTRACTOR(waveform, sampling_rate=SR, return_tensors=\"pt\")\n",
    "        return inputs.input_values.squeeze(0), self.label_to_id[label]\n",
    "\n",
    "# =========================\n",
    "# 3. Models\n",
    "# =========================\n",
    "class VideoMultiBackbone(nn.Module):\n",
    "    def __init__(self, num_b, num_e):\n",
    "        super().__init__()\n",
    "        \n",
    "        backbone_b = resnet34(weights=ResNet34_Weights.IMAGENET1K_V1)\n",
    "        in_features_b = backbone_b.fc.in_features\n",
    "        backbone_b.fc = nn.Identity()\n",
    "        self.behavior_backbone = backbone_b\n",
    "        self.behavior_head = nn.Linear(in_features_b, num_b)\n",
    "        \n",
    "        backbone_e = resnet34(weights=ResNet34_Weights.IMAGENET1K_V1)\n",
    "        in_features_e = backbone_e.fc.in_features\n",
    "        backbone_e.fc = nn.Identity()\n",
    "        self.emotion_backbone = backbone_e\n",
    "        self.emotion_head = nn.Linear(in_features_e, num_e)\n",
    "    \n",
    "    def forward(self, x, task):\n",
    "        if task == \"behavior\":\n",
    "            feat = self.behavior_backbone(x)\n",
    "            return self.behavior_head(feat)\n",
    "        elif task == \"emotion\":\n",
    "            feat = self.emotion_backbone(x)\n",
    "            return self.emotion_head(feat)\n",
    "        else:\n",
    "            raise ValueError(\"Task must be 'behavior' or 'emotion'\")\n",
    "\n",
    "class AudioModel(nn.Module):\n",
    "    def __init__(self, num_classes, freeze_backbone=False):  # ğŸ”¥ ê¸°ë³¸ê°’ False\n",
    "        super().__init__()\n",
    "        self.model = Wav2Vec2ForSequenceClassification.from_pretrained(\n",
    "            AUDIO_MODEL_NAME,\n",
    "            num_labels=num_classes,\n",
    "            ignore_mismatched_sizes=True\n",
    "        )\n",
    "        \n",
    "        # ğŸ”¥ Freeze ì˜µì…˜ (ê¸°ë³¸: ì „ì²´ í•™ìŠµ)\n",
    "        if freeze_backbone:\n",
    "            for param in self.model.wav2vec2.parameters():\n",
    "                param.requires_grad = False\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(input_values=x).logits\n",
    "\n",
    "# =========================\n",
    "# 4. Training\n",
    "# =========================\n",
    "def mixup_data(x, y, alpha=0.4):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    \n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "    \n",
    "    mixed_x = lam * x + (1 - lam) * x[index]\n",
    "    y_a, y_b = y, y[index]\n",
    "    \n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def train():\n",
    "    prepare_dataset()\n",
    "    \n",
    "    print(\"\\nğŸ”„ Loading datasets...\")\n",
    "    behavior_train = ImageDataset(os.path.join(WORK_DIR,\"train\",\"behavior\"), augment=True)\n",
    "    behavior_val = ImageDataset(os.path.join(WORK_DIR,\"val\",\"behavior\"), augment=False)\n",
    "    \n",
    "    emotion_train = ImageDataset(os.path.join(WORK_DIR,\"train\",\"emotion\"), augment=True)\n",
    "    emotion_val = ImageDataset(os.path.join(WORK_DIR,\"val\",\"emotion\"), augment=False)\n",
    "    \n",
    "    sound_train = AudioDataset(os.path.join(WORK_DIR,\"train\",\"sound\"), augment=True)  # ğŸ”¥ ì¦ê°•\n",
    "    sound_val = AudioDataset(os.path.join(WORK_DIR,\"val\",\"sound\"), augment=False)\n",
    "    \n",
    "    behavior_train_loader = DataLoader(behavior_train, BATCH_SIZE, True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "    behavior_val_loader = DataLoader(behavior_val, BATCH_SIZE, False, num_workers=NUM_WORKERS//2, pin_memory=True)\n",
    "    \n",
    "    emotion_train_loader = DataLoader(emotion_train, BATCH_SIZE, True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "    emotion_val_loader = DataLoader(emotion_val, BATCH_SIZE, False, num_workers=NUM_WORKERS//2, pin_memory=True)\n",
    "    \n",
    "    sound_train_loader = DataLoader(sound_train, BATCH_SIZE, True, num_workers=2, pin_memory=True)\n",
    "    sound_val_loader = DataLoader(sound_val, BATCH_SIZE, False, num_workers=2, pin_memory=True)\n",
    "    \n",
    "    print(f\"\\nğŸ“¦ DataLoaders:\")\n",
    "    print(f\"  Behavior: {len(behavior_train_loader)} train batches, {len(behavior_val_loader)} val batches\")\n",
    "    print(f\"  Emotion: {len(emotion_train_loader)} train batches, {len(emotion_val_loader)} val batches\")\n",
    "    print(f\"  Sound: {len(sound_train_loader)} train batches, {len(sound_val_loader)} val batches\")\n",
    "    \n",
    "    # ëª¨ë¸\n",
    "    video_model = VideoMultiBackbone(\n",
    "        len(behavior_train.label_to_id),\n",
    "        len(emotion_train.label_to_id)\n",
    "    ).to(DEVICE)\n",
    "    \n",
    "    audio_model = AudioModel(\n",
    "        len(sound_train.label_to_id),\n",
    "        freeze_backbone=False  # ğŸ”¥ ì „ì²´ í•™ìŠµ\n",
    "    ).to(DEVICE)\n",
    "    \n",
    "    # ğŸ”¥ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°\n",
    "    sound_labels = [sound_train.label_to_id[label] for _, label in sound_train.samples]\n",
    "    class_weights = compute_class_weight('balanced', classes=np.arange(len(sound_train.label_to_id)), y=sound_labels)\n",
    "    class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(DEVICE)\n",
    "    \n",
    "    # Optimizer\n",
    "    video_opt = torch.optim.AdamW(video_model.parameters(), lr=LR_VIDEO, weight_decay=0.01)\n",
    "    audio_opt = torch.optim.AdamW(audio_model.parameters(), lr=LR_AUDIO, weight_decay=0.01)\n",
    "    \n",
    "    # ğŸ”¥ Scheduler (Soundìš©)\n",
    "    total_steps = len(sound_train_loader) * EPOCHS\n",
    "    warmup_steps = 100\n",
    "    audio_scheduler = get_linear_schedule_with_warmup(\n",
    "        audio_opt, num_warmup_steps=warmup_steps, num_training_steps=total_steps\n",
    "    )\n",
    "    \n",
    "    # Scaler\n",
    "    video_scaler = torch.amp.GradScaler(\"cuda\")\n",
    "    audio_scaler = torch.amp.GradScaler(\"cuda\")\n",
    "    \n",
    "    # Loss\n",
    "    criterion_video = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "    criterion_audio = nn.CrossEntropyLoss(weight=class_weights_tensor)  # ğŸ”¥ ê°€ì¤‘ì¹˜ ì ìš©\n",
    "    \n",
    "    best_avg_acc = 0\n",
    "    history = []\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        video_model.train()\n",
    "        audio_model.train()\n",
    "        \n",
    "        loss_b_total, loss_e_total, loss_s_total = 0, 0, 0\n",
    "        \n",
    "        # -------- 1. Behavior --------\n",
    "        print(f\"\\nğŸ¾ Training Behavior...\")\n",
    "        for imgs, labels in tqdm(behavior_train_loader, desc=\"Behavior\", leave=False):\n",
    "            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "            \n",
    "            with torch.amp.autocast(\"cuda\"):\n",
    "                imgs, labels_a, labels_b, lam = mixup_data(imgs, labels)\n",
    "                logits = video_model(imgs, \"behavior\")\n",
    "                loss = lam * criterion_video(logits, labels_a) + (1 - lam) * criterion_video(logits, labels_b)\n",
    "            \n",
    "            video_opt.zero_grad()\n",
    "            video_scaler.scale(loss).backward()\n",
    "            video_scaler.step(video_opt)\n",
    "            video_scaler.update()\n",
    "            \n",
    "            loss_b_total += loss.item()\n",
    "        \n",
    "        avg_loss_b = loss_b_total / len(behavior_train_loader)\n",
    "        print(f\"  â†’ Avg Loss: {avg_loss_b:.4f}\")\n",
    "        \n",
    "        # -------- 2. Emotion --------\n",
    "        print(f\"\\nğŸ˜Š Training Emotion...\")\n",
    "        for imgs, labels in tqdm(emotion_train_loader, desc=\"Emotion\", leave=False):\n",
    "            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "            \n",
    "            with torch.amp.autocast(\"cuda\"):\n",
    "                imgs, labels_a, labels_b, lam = mixup_data(imgs, labels)\n",
    "                logits = video_model(imgs, \"emotion\")\n",
    "                loss = lam * criterion_video(logits, labels_a) + (1 - lam) * criterion_video(logits, labels_b)\n",
    "            \n",
    "            video_opt.zero_grad()\n",
    "            video_scaler.scale(loss).backward()\n",
    "            video_scaler.step(video_opt)\n",
    "            video_scaler.update()\n",
    "            \n",
    "            loss_e_total += loss.item()\n",
    "        \n",
    "        avg_loss_e = loss_e_total / len(emotion_train_loader)\n",
    "        print(f\"  â†’ Avg Loss: {avg_loss_e:.4f}\")\n",
    "        \n",
    "        # -------- 3. Sound (ê°œì„ ) --------\n",
    "        print(f\"\\nğŸ”Š Training Sound...\")\n",
    "        for audios, labels in tqdm(sound_train_loader, desc=\"Sound\", leave=False):\n",
    "            audios, labels = audios.to(DEVICE), labels.to(DEVICE)\n",
    "            \n",
    "            audio_opt.zero_grad()\n",
    "            \n",
    "            with torch.amp.autocast(\"cuda\"):\n",
    "                logits = audio_model(audios)\n",
    "                loss = criterion_audio(logits, labels) * LOSS_WEIGHTS[\"sound\"]\n",
    "            \n",
    "            audio_scaler.scale(loss).backward()\n",
    "            audio_scaler.unscale_(audio_opt)\n",
    "            torch.nn.utils.clip_grad_norm_(audio_model.parameters(), 1.0)  # ğŸ”¥ Gradient clipping\n",
    "            audio_scaler.step(audio_opt)\n",
    "            audio_scaler.update()\n",
    "            audio_scheduler.step()  # ğŸ”¥ Scheduler\n",
    "            \n",
    "            loss_s_total += loss.item()\n",
    "        \n",
    "        avg_loss_s = loss_s_total / len(sound_train_loader)\n",
    "        print(f\"  â†’ Avg Loss: {avg_loss_s:.4f}\")\n",
    "        \n",
    "        # -------- Validation --------\n",
    "        print(f\"\\nğŸ” Validation...\")\n",
    "        video_model.eval()\n",
    "        audio_model.eval()\n",
    "        \n",
    "        # Behavior Val\n",
    "        correct_b, total_b = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in tqdm(behavior_val_loader, desc=\"Val Behavior\", leave=False):\n",
    "                imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "                logits = video_model(imgs, \"behavior\")\n",
    "                pred = logits.argmax(-1)\n",
    "                correct_b += (pred == labels).sum().item()\n",
    "                total_b += labels.size(0)\n",
    "        acc_b = correct_b / total_b\n",
    "        \n",
    "        # Emotion Val\n",
    "        correct_e, total_e = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in tqdm(emotion_val_loader, desc=\"Val Emotion\", leave=False):\n",
    "                imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "                logits = video_model(imgs, \"emotion\")\n",
    "                pred = logits.argmax(-1)\n",
    "                correct_e += (pred == labels).sum().item()\n",
    "                total_e += labels.size(0)\n",
    "        acc_e = correct_e / total_e\n",
    "        \n",
    "        # Sound Val\n",
    "        correct_s, total_s = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for audios, labels in tqdm(sound_val_loader, desc=\"Val Sound\", leave=False):\n",
    "                audios, labels = audios.to(DEVICE), labels.to(DEVICE)\n",
    "                logits = audio_model(audios)\n",
    "                pred = logits.argmax(-1)\n",
    "                correct_s += (pred == labels).sum().item()\n",
    "                total_s += labels.size(0)\n",
    "        acc_s = correct_s / total_s\n",
    "        \n",
    "        avg_acc = (acc_b + acc_e + acc_s) / 3\n",
    "        \n",
    "        print(f\"\\nğŸ“Š Results:\")\n",
    "        print(f\"  Behavior: Loss {avg_loss_b:.4f} | Acc {acc_b:.4f} ({acc_b*100:.1f}%)\")\n",
    "        print(f\"  Emotion:  Loss {avg_loss_e:.4f} | Acc {acc_e:.4f} ({acc_e*100:.1f}%)\")\n",
    "        print(f\"  Sound:    Loss {avg_loss_s:.4f} | Acc {acc_s:.4f} ({acc_s*100:.1f}%)\")\n",
    "        print(f\"  Average Acc: {avg_acc:.4f} ({avg_acc*100:.1f}%)\")\n",
    "        \n",
    "        history.append({\n",
    "            'epoch': epoch+1,\n",
    "            'loss_b': avg_loss_b,\n",
    "            'loss_e': avg_loss_e,\n",
    "            'loss_s': avg_loss_s,\n",
    "            'acc_b': acc_b,\n",
    "            'acc_e': acc_e,\n",
    "            'acc_s': acc_s,\n",
    "            'acc_avg': avg_acc\n",
    "        })\n",
    "        \n",
    "        if avg_acc > best_avg_acc:\n",
    "            best_avg_acc = avg_acc\n",
    "            torch.save({\n",
    "                \"video_model\": video_model.state_dict(),\n",
    "                \"audio_model\": audio_model.state_dict(),\n",
    "                \"behavior_label_to_id\": behavior_train.label_to_id,\n",
    "                \"emotion_label_to_id\": emotion_train.label_to_id,\n",
    "                \"sound_label_to_id\": sound_train.label_to_id,\n",
    "                \"best_epoch\": epoch+1,\n",
    "                \"best_acc\": best_avg_acc,\n",
    "                \"history\": history\n",
    "            }, \"pet_omni_best.pth\")\n",
    "            print(f\"  ğŸ’¾ Saved new best model! (Acc: {best_avg_acc:.4f})\")\n",
    "    \n",
    "    # ê·¸ë˜í”„\n",
    "    print(\"\\nğŸ“ˆ Generating training history plot...\")\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(131)\n",
    "    plt.plot([h['acc_b'] for h in history], 'b-', label='Behavior', linewidth=2)\n",
    "    plt.xlabel('Epoch'); plt.ylabel('Accuracy')\n",
    "    plt.title('Behavior Accuracy'); plt.ylim(0, 1); plt.grid(True, alpha=0.3); plt.legend()\n",
    "    \n",
    "    plt.subplot(132)\n",
    "    plt.plot([h['acc_e'] for h in history], 'r-', label='Emotion', linewidth=2)\n",
    "    plt.xlabel('Epoch'); plt.ylabel('Accuracy')\n",
    "    plt.title('Emotion Accuracy'); plt.ylim(0, 1); plt.grid(True, alpha=0.3); plt.legend()\n",
    "    \n",
    "    plt.subplot(133)\n",
    "    plt.plot([h['acc_s'] for h in history], 'g-', label='Sound', linewidth=2)\n",
    "    plt.xlabel('Epoch'); plt.ylabel('Accuracy')\n",
    "    plt.title('Sound Accuracy'); plt.ylim(0, 1); plt.grid(True, alpha=0.3); plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('pet_omni_history.png', dpi=150, bbox_inches='tight')\n",
    "    print(\"  âœ… Saved: pet_omni_history.png\")\n",
    "    \n",
    "    print(f\"\\nğŸ‰ Training Finished!\")\n",
    "    print(f\"  Best Average Acc: {best_avg_acc:.4f} ({best_avg_acc*100:.1f}%)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb70b40",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd408c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Loading best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 211/211 [00:00<00:00, 418.50it/s, Materializing param=wav2vec2.masked_spec_embed]                                            \n",
      "\u001b[1mWav2Vec2ForSequenceClassification LOAD REPORT\u001b[0m from: facebook/wav2vec2-base\n",
      "Key                          | Status     | \n",
      "-----------------------------+------------+-\n",
      "project_hid.weight           | UNEXPECTED | \n",
      "quantizer.codevectors        | UNEXPECTED | \n",
      "quantizer.weight_proj.weight | UNEXPECTED | \n",
      "project_q.weight             | UNEXPECTED | \n",
      "project_hid.bias             | UNEXPECTED | \n",
      "quantizer.weight_proj.bias   | UNEXPECTED | \n",
      "project_q.bias               | UNEXPECTED | \n",
      "projector.bias               | MISSING    | \n",
      "classifier.bias              | MISSING    | \n",
      "classifier.weight            | MISSING    | \n",
      "projector.weight             | MISSING    | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\u001b[3m\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ Loading TEST datasets...\n",
      "\n",
      "ğŸ“Š TEST Results:\n",
      "  Behavior Acc: 0.7130 (71.3%)\n",
      "  Emotion Acc:  0.7584 (75.8%)\n",
      "  Sound Acc:    0.8017 (80.2%)\n",
      "  Average Acc:  0.7577 (75.8%)\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    from transformers import Wav2Vec2FeatureExtractor\n",
    "    FEATURE_EXTRACTOR = Wav2Vec2FeatureExtractor.from_pretrained(\n",
    "        \"facebook/wav2vec2-base\"\n",
    "    )\n",
    "\n",
    "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    BATCH_SIZE = 16\n",
    "    SR = 16000\n",
    "    MAX_AUDIO_LEN = SR * 5\n",
    "\n",
    "    print(\"ğŸ” Loading best model...\")\n",
    "    checkpoint = torch.load(\"pet_omni_best.pth\", map_location=DEVICE)\n",
    "\n",
    "    behavior_label_to_id = checkpoint[\"behavior_label_to_id\"]\n",
    "    emotion_label_to_id = checkpoint[\"emotion_label_to_id\"]\n",
    "    sound_label_to_id = checkpoint[\"sound_label_to_id\"]\n",
    "\n",
    "    # -----------------------------\n",
    "    # ëª¨ë¸ ë³µì›\n",
    "    # -----------------------------\n",
    "    video_model = VideoMultiBackbone(\n",
    "        len(behavior_label_to_id),\n",
    "        len(emotion_label_to_id)\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    audio_model = AudioModel(\n",
    "        len(sound_label_to_id)\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    video_model.load_state_dict(checkpoint[\"video_model\"])\n",
    "    audio_model.load_state_dict(checkpoint[\"audio_model\"])\n",
    "\n",
    "    video_model.eval()\n",
    "    audio_model.eval()\n",
    "\n",
    "    print(\"ğŸ“¦ Loading TEST datasets...\")\n",
    "\n",
    "    TEST_DIR = os.path.join(\"files\", \"work\", \"omni_dataset\", \"test\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Train ì˜ì¡´ ì—†ëŠ” Dataset ì •ì˜\n",
    "    # -----------------------------\n",
    "    class TestImageDataset(Dataset):\n",
    "        def __init__(self, task_dir, label_to_id):\n",
    "            self.samples = []\n",
    "            self.label_to_id = label_to_id\n",
    "\n",
    "            for label in os.listdir(task_dir):\n",
    "                if label not in label_to_id:\n",
    "                    continue\n",
    "\n",
    "                label_dir = os.path.join(task_dir, label)\n",
    "                for file in os.listdir(label_dir):\n",
    "                    if file.lower().endswith(('.jpg','.png','.jpeg')):\n",
    "                        self.samples.append(\n",
    "                            (os.path.join(label_dir,file),\n",
    "                             label_to_id[label])\n",
    "                        )\n",
    "\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize((224,224)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(\n",
    "                    [0.485,0.456,0.406],\n",
    "                    [0.229,0.224,0.225]\n",
    "                )\n",
    "            ])\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.samples)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            path, label_id = self.samples[idx]\n",
    "            img = Image.open(path).convert(\"RGB\")\n",
    "            img = self.transform(img)\n",
    "            return img, label_id\n",
    "\n",
    "\n",
    "    class TestAudioDataset(Dataset):\n",
    "        def __init__(self, task_dir, label_to_id):\n",
    "            self.samples = []\n",
    "            self.label_to_id = label_to_id\n",
    "\n",
    "            for label in os.listdir(task_dir):\n",
    "                if label not in label_to_id:\n",
    "                    continue\n",
    "\n",
    "                label_dir = os.path.join(task_dir, label)\n",
    "                for file in os.listdir(label_dir):\n",
    "                    if file.lower().endswith(('.wav','.mp3','.m4a')):\n",
    "                        self.samples.append(\n",
    "                            (os.path.join(label_dir,file),\n",
    "                             label_to_id[label])\n",
    "                        )\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.samples)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            path, label_id = self.samples[idx]\n",
    "            waveform, _ = librosa.load(path, sr=SR, mono=True)\n",
    "\n",
    "            if len(waveform) > MAX_AUDIO_LEN:\n",
    "                waveform = waveform[:MAX_AUDIO_LEN]\n",
    "            else:\n",
    "                waveform = np.pad(\n",
    "                    waveform,\n",
    "                    (0, MAX_AUDIO_LEN - len(waveform))\n",
    "                )\n",
    "\n",
    "            inputs = FEATURE_EXTRACTOR(\n",
    "                waveform,\n",
    "                sampling_rate=SR,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "\n",
    "            return inputs.input_values.squeeze(0), label_id\n",
    "\n",
    "\n",
    "    # -----------------------------\n",
    "    # Loader\n",
    "    # -----------------------------\n",
    "    behavior_loader = DataLoader(\n",
    "        TestImageDataset(\n",
    "            os.path.join(TEST_DIR,\"behavior\"),\n",
    "            behavior_label_to_id\n",
    "        ),\n",
    "        BATCH_SIZE, False\n",
    "    )\n",
    "\n",
    "    emotion_loader = DataLoader(\n",
    "        TestImageDataset(\n",
    "            os.path.join(TEST_DIR,\"emotion\"),\n",
    "            emotion_label_to_id\n",
    "        ),\n",
    "        BATCH_SIZE, False\n",
    "    )\n",
    "\n",
    "    sound_loader = DataLoader(\n",
    "        TestAudioDataset(\n",
    "            os.path.join(TEST_DIR,\"sound\"),\n",
    "            sound_label_to_id\n",
    "        ),\n",
    "        BATCH_SIZE, False\n",
    "    )\n",
    "\n",
    "    # -----------------------------\n",
    "    # Evaluation\n",
    "    # -----------------------------\n",
    "    def evaluate(loader, task):\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in loader:\n",
    "                x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "\n",
    "                if task in [\"behavior\",\"emotion\"]:\n",
    "                    logits = video_model(x, task)\n",
    "                else:\n",
    "                    logits = audio_model(x)\n",
    "\n",
    "                pred = logits.argmax(-1)\n",
    "                correct += (pred == y).sum().item()\n",
    "                total += y.size(0)\n",
    "\n",
    "        return correct / total if total > 0 else 0\n",
    "\n",
    "\n",
    "    acc_b = evaluate(behavior_loader, \"behavior\")\n",
    "    acc_e = evaluate(emotion_loader, \"emotion\")\n",
    "    acc_s = evaluate(sound_loader, \"sound\")\n",
    "\n",
    "    avg_acc = (acc_b + acc_e + acc_s) / 3\n",
    "\n",
    "    print(\"\\nğŸ“Š TEST Results:\")\n",
    "    print(f\"  Behavior Acc: {acc_b:.4f} ({acc_b*100:.1f}%)\")\n",
    "    print(f\"  Emotion Acc:  {acc_e:.4f} ({acc_e*100:.1f}%)\")\n",
    "    print(f\"  Sound Acc:    {acc_s:.4f} ({acc_s*100:.1f}%)\")\n",
    "    print(f\"  Average Acc:  {avg_acc:.4f} ({avg_acc*100:.1f}%)\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
