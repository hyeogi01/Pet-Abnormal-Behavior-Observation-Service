{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "790f7a53",
   "metadata": {},
   "source": [
    "## í´ë˜ìŠ¤ë³„ íŒŒì¼ ê°œìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5a2acf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               JPG Count\n",
      "dog_happy          17355\n",
      "dog_sad            14206\n",
      "dog_anxious        11590\n",
      "dog_relaxed         8699\n",
      "dog_angry           8564\n",
      "dog_confused        3286\n",
      "cat_relaxed         2999\n",
      "cat_happy           1221\n",
      "cat_attentive        997\n",
      "cat_sad              171\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "import pandas as pd  # í…Œì´ë¸” ë³´ê¸° í¸í•¨\n",
    "\n",
    "root_dir = Path('./files/2_Animal_emotions')\n",
    "jpg_counts = Counter()\n",
    "\n",
    "# 1_Animal_Behavior ë°”ë¡œ ì•„ë˜ í´ë”ë§Œ ëŒ€ìƒ\n",
    "for subdir in root_dir.iterdir():\n",
    "    if subdir.is_dir():\n",
    "        jpg_count = len(list(subdir.rglob('*.jpg')))\n",
    "        jpg_counts[subdir.name] = jpg_count\n",
    "\n",
    "# í…Œì´ë¸” ì¶œë ¥\n",
    "df = pd.DataFrame.from_dict(jpg_counts, orient='index', columns=['JPG Count']).sort_values('JPG Count', ascending=False)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f7a330",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b8343e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ Device: cuda:1\n",
      "\n",
      "ğŸ“¦ Collecting behavior...\n",
      "  â†’ 757113 samples, 25 classes\n",
      "  ğŸ¯ Target: 100000 samples\n",
      "  ğŸ“Š 25 classes â†’ max 4000 per class\n",
      "    CAT_ARCH: 2296/2296\n",
      "    CAT_ARMSTRETCH: 4000/38483\n",
      "    CAT_FOOTPUSH: 4000/9517\n",
      "    CAT_GETDOWN: 4000/13421\n",
      "    CAT_GROOMING: 4000/65029\n",
      "    CAT_HEADING: 4000/11237\n",
      "    CAT_LAYDOWN: 4000/21474\n",
      "    CAT_LYING: 4000/12119\n",
      "    CAT_ROLL: 4000/8513\n",
      "    CAT_SITDOWN: 4000/18401\n",
      "    CAT_TAILING: 4000/36960\n",
      "    CAT_WALKRUN: 4000/30498\n",
      "    DOG_BODYLOWER: 4000/79772\n",
      "    DOG_BODYSCRATCH: 4000/15783\n",
      "    DOG_BODYSHAKE: 4000/15296\n",
      "    DOG_FEETUP: 4000/34365\n",
      "    DOG_FOOTUP: 4000/52506\n",
      "    DOG_HEADING: 4000/19052\n",
      "    DOG_LYING: 4000/32129\n",
      "    DOG_MOUNTING: 4000/5211\n",
      "    DOG_SIT: 4000/79182\n",
      "    DOG_TAILING: 4000/35824\n",
      "    DOG_TAILLOW: 4000/8376\n",
      "    DOG_TURN: 4000/21554\n",
      "    DOG_WALKRUN: 4000/90115\n",
      "  âœ… Total sampled: 98296\n",
      "\n",
      "ğŸ“¦ Collecting emotion...\n",
      "  â†’ 69113 samples, 10 classes\n",
      "  ğŸ¯ Target: 100000 samples\n",
      "  ğŸ“Š 10 classes â†’ max 10000 per class\n",
      "    cat_attentive: 997/997\n",
      "    cat_happy: 1221/1221\n",
      "    cat_relaxed: 2999/2999\n",
      "    cat_sad: 171/171\n",
      "    dog_angry: 8589/8589\n",
      "    dog_anxious : 10000/11590\n",
      "    dog_confused: 3286/3286\n",
      "    dog_happy: 10000/17355\n",
      "    dog_relaxed: 8699/8699\n",
      "    dog_sad: 10000/14206\n",
      "  âœ… Total sampled: 55962\n",
      "\n",
      "ğŸ“¦ Collecting sound...\n",
      "  â†’ 1248 samples, 16 classes\n",
      "  â„¹ï¸  Sound: Using all samples (no limit)\n",
      "\n",
      "ğŸ“‹ Splitting & Copying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Dataset ready\n",
      "\n",
      "ğŸ”„ Loading datasets...\n",
      "  ğŸ“Š behavior: 11864 samples, 25 classes\n",
      "  ğŸ“Š behavior: 5301 samples, 25 classes\n",
      "  ğŸ“Š emotion: 44766 samples, 10 classes\n",
      "  ğŸ“Š emotion: 5592 samples, 10 classes\n",
      "  ğŸ“Š sound: 995 samples, 16 classes\n",
      "  ğŸ“Š sound: 121 samples, 16 classes\n",
      "\n",
      "ğŸ“¦ DataLoaders:\n",
      "  Behavior: 742 train batches, 332 val batches\n",
      "  Emotion: 2798 train batches, 350 val batches\n",
      "  Sound: 63 train batches, 8 val batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 211/211 [00:00<00:00, 506.19it/s, Materializing param=wav2vec2.masked_spec_embed]                                            \n",
      "\u001b[1mWav2Vec2ForSequenceClassification LOAD REPORT\u001b[0m from: facebook/wav2vec2-base\n",
      "Key                          | Status     | \n",
      "-----------------------------+------------+-\n",
      "project_q.weight             | UNEXPECTED | \n",
      "project_q.bias               | UNEXPECTED | \n",
      "quantizer.weight_proj.weight | UNEXPECTED | \n",
      "project_hid.weight           | UNEXPECTED | \n",
      "quantizer.codevectors        | UNEXPECTED | \n",
      "quantizer.weight_proj.bias   | UNEXPECTED | \n",
      "project_hid.bias             | UNEXPECTED | \n",
      "classifier.weight            | MISSING    | \n",
      "projector.bias               | MISSING    | \n",
      "projector.weight             | MISSING    | \n",
      "classifier.bias              | MISSING    | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\u001b[3m\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Epoch 1/50\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.9307\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.7987\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.5614\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 1.9307 | Acc 0.1062 (10.6%)\n",
      "  Emotion:  Loss 0.7987 | Acc 0.6178 (61.8%)\n",
      "  Sound:    Loss 1.5614 | Acc 0.2562 (25.6%)\n",
      "  Average Acc: 0.3268 (32.7%)\n",
      "  ğŸ’¾ Saved new best model! (Acc: 0.3268)\n",
      "\n",
      "============================================================\n",
      "Epoch 2/50\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.5757\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.6730\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.3482\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 1.5757 | Acc 0.1973 (19.7%)\n",
      "  Emotion:  Loss 0.6730 | Acc 0.6604 (66.0%)\n",
      "  Sound:    Loss 1.3482 | Acc 0.4793 (47.9%)\n",
      "  Average Acc: 0.4457 (44.6%)\n",
      "  ğŸ’¾ Saved new best model! (Acc: 0.4457)\n",
      "\n",
      "============================================================\n",
      "Epoch 3/50\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.2432\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.6145\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.1711\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 1.2432 | Acc 0.2579 (25.8%)\n",
      "  Emotion:  Loss 0.6145 | Acc 0.6736 (67.4%)\n",
      "  Sound:    Loss 1.1711 | Acc 0.5620 (56.2%)\n",
      "  Average Acc: 0.4978 (49.8%)\n",
      "  ğŸ’¾ Saved new best model! (Acc: 0.4978)\n",
      "\n",
      "============================================================\n",
      "Epoch 4/50\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.9857\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.5678\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.0627\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 0.9857 | Acc 0.3216 (32.2%)\n",
      "  Emotion:  Loss 0.5678 | Acc 0.6924 (69.2%)\n",
      "  Sound:    Loss 1.0627 | Acc 0.6281 (62.8%)\n",
      "  Average Acc: 0.5474 (54.7%)\n",
      "  ğŸ’¾ Saved new best model! (Acc: 0.5474)\n",
      "\n",
      "============================================================\n",
      "Epoch 5/50\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.8166\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.5262\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.9703\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 0.8166 | Acc 0.3762 (37.6%)\n",
      "  Emotion:  Loss 0.5262 | Acc 0.6912 (69.1%)\n",
      "  Sound:    Loss 0.9703 | Acc 0.5950 (59.5%)\n",
      "  Average Acc: 0.5541 (55.4%)\n",
      "  ğŸ’¾ Saved new best model! (Acc: 0.5541)\n",
      "\n",
      "============================================================\n",
      "Epoch 6/50\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.6871\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.4929\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.8975\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 0.6871 | Acc 0.3639 (36.4%)\n",
      "  Emotion:  Loss 0.4929 | Acc 0.6885 (68.8%)\n",
      "  Sound:    Loss 0.8975 | Acc 0.5702 (57.0%)\n",
      "  Average Acc: 0.5409 (54.1%)\n",
      "\n",
      "============================================================\n",
      "Epoch 7/50\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.5600\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.4580\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.8264\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 0.5600 | Acc 0.3982 (39.8%)\n",
      "  Emotion:  Loss 0.4580 | Acc 0.7110 (71.1%)\n",
      "  Sound:    Loss 0.8264 | Acc 0.6033 (60.3%)\n",
      "  Average Acc: 0.5708 (57.1%)\n",
      "  ğŸ’¾ Saved new best model! (Acc: 0.5708)\n",
      "\n",
      "============================================================\n",
      "Epoch 8/50\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.4902\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.4261\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.7611\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 0.4902 | Acc 0.4169 (41.7%)\n",
      "  Emotion:  Loss 0.4261 | Acc 0.7116 (71.2%)\n",
      "  Sound:    Loss 0.7611 | Acc 0.6612 (66.1%)\n",
      "  Average Acc: 0.5965 (59.7%)\n",
      "  ğŸ’¾ Saved new best model! (Acc: 0.5965)\n",
      "\n",
      "============================================================\n",
      "Epoch 9/50\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.4163\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.4087\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.6643\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 0.4163 | Acc 0.4414 (44.1%)\n",
      "  Emotion:  Loss 0.4087 | Acc 0.7124 (71.2%)\n",
      "  Sound:    Loss 0.6643 | Acc 0.6446 (64.5%)\n",
      "  Average Acc: 0.5995 (60.0%)\n",
      "  ğŸ’¾ Saved new best model! (Acc: 0.5995)\n",
      "\n",
      "============================================================\n",
      "Epoch 10/50\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.3526\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.3887\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.6146\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 0.3526 | Acc 0.4958 (49.6%)\n",
      "  Emotion:  Loss 0.3887 | Acc 0.7114 (71.1%)\n",
      "  Sound:    Loss 0.6146 | Acc 0.6281 (62.8%)\n",
      "  Average Acc: 0.6117 (61.2%)\n",
      "  ğŸ’¾ Saved new best model! (Acc: 0.6117)\n",
      "\n",
      "============================================================\n",
      "Epoch 11/50\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.3233\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.3652\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.5785\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 0.3233 | Acc 0.4810 (48.1%)\n",
      "  Emotion:  Loss 0.3652 | Acc 0.7058 (70.6%)\n",
      "  Sound:    Loss 0.5785 | Acc 0.6612 (66.1%)\n",
      "  Average Acc: 0.6160 (61.6%)\n",
      "  ğŸ’¾ Saved new best model! (Acc: 0.6160)\n",
      "\n",
      "============================================================\n",
      "Epoch 12/50\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.2815\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.3522\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.5525\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 0.2815 | Acc 0.4686 (46.9%)\n",
      "  Emotion:  Loss 0.3522 | Acc 0.7273 (72.7%)\n",
      "  Sound:    Loss 0.5525 | Acc 0.6777 (67.8%)\n",
      "  Average Acc: 0.6245 (62.5%)\n",
      "  ğŸ’¾ Saved new best model! (Acc: 0.6245)\n",
      "\n",
      "============================================================\n",
      "Epoch 13/50\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.2588\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.3382\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.5024\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 0.2588 | Acc 0.4807 (48.1%)\n",
      "  Emotion:  Loss 0.3382 | Acc 0.7253 (72.5%)\n",
      "  Sound:    Loss 0.5024 | Acc 0.6860 (68.6%)\n",
      "  Average Acc: 0.6306 (63.1%)\n",
      "  ğŸ’¾ Saved new best model! (Acc: 0.6306)\n",
      "\n",
      "============================================================\n",
      "Epoch 14/50\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.2335\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.3228\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.5024\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 0.2335 | Acc 0.4712 (47.1%)\n",
      "  Emotion:  Loss 0.3228 | Acc 0.7332 (73.3%)\n",
      "  Sound:    Loss 0.5024 | Acc 0.6942 (69.4%)\n",
      "  Average Acc: 0.6329 (63.3%)\n",
      "  ğŸ’¾ Saved new best model! (Acc: 0.6329)\n",
      "\n",
      "============================================================\n",
      "Epoch 15/50\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.2214\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.3138\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.4256\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 0.2214 | Acc 0.4933 (49.3%)\n",
      "  Emotion:  Loss 0.3138 | Acc 0.7310 (73.1%)\n",
      "  Sound:    Loss 0.4256 | Acc 0.6860 (68.6%)\n",
      "  Average Acc: 0.6368 (63.7%)\n",
      "  ğŸ’¾ Saved new best model! (Acc: 0.6368)\n",
      "\n",
      "============================================================\n",
      "Epoch 16/50\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.1927\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.3055\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.4299\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 0.1927 | Acc 0.4831 (48.3%)\n",
      "  Emotion:  Loss 0.3055 | Acc 0.7391 (73.9%)\n",
      "  Sound:    Loss 0.4299 | Acc 0.6694 (66.9%)\n",
      "  Average Acc: 0.6305 (63.1%)\n",
      "\n",
      "============================================================\n",
      "Epoch 17/50\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.1863\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.2956\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.3836\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 0.1863 | Acc 0.4882 (48.8%)\n",
      "  Emotion:  Loss 0.2956 | Acc 0.7462 (74.6%)\n",
      "  Sound:    Loss 0.3836 | Acc 0.6860 (68.6%)\n",
      "  Average Acc: 0.6401 (64.0%)\n",
      "  ğŸ’¾ Saved new best model! (Acc: 0.6401)\n",
      "\n",
      "============================================================\n",
      "Epoch 18/50\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.1664\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Emotion:  22%|â–ˆâ–ˆâ–       | 625/2798 [00:23<01:26, 25.02it/s]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import Wav2Vec2ForSequenceClassification, Wav2Vec2FeatureExtractor\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet34, ResNet34_Weights\n",
    "from PIL import Image\n",
    "import librosa\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# =========================\n",
    "# 0. ì„¤ì •\n",
    "# =========================\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "BEHAVIOR_ROOT = \"files/1_Animal_Behavior\"\n",
    "EMOTION_ROOT = \"files/2_Animal_emotions\"\n",
    "SOUND_ROOT = \"files/3_Animal_Sound\"\n",
    "WORK_DIR = \"files/work/omni_dataset\"\n",
    "\n",
    "# ğŸ”¥ ìƒ˜í”Œ ì œí•œ ì„¤ì •\n",
    "MAX_SAMPLES_BEHAVIOR = 100000  # Behavior ì´ ìƒ˜í”Œ ìˆ˜\n",
    "MAX_SAMPLES_EMOTION = 100000    # Emotion ì´ ìƒ˜í”Œ ìˆ˜\n",
    "# SoundëŠ” ë°ì´í„°ê°€ ì ìœ¼ë¯€ë¡œ ì „ì²´ ì‚¬ìš©\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 50\n",
    "LR_VIDEO = 1e-4\n",
    "LR_AUDIO = 1e-5\n",
    "DEVICE = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "NUM_WORKERS = 12\n",
    "SR = 16000\n",
    "MAX_AUDIO_LEN = SR * 5\n",
    "\n",
    "LOSS_WEIGHTS = {\n",
    "    \"behavior\": 1.0,\n",
    "    \"emotion\": 0.8,\n",
    "    \"sound\": 0.6\n",
    "}\n",
    "\n",
    "AUDIO_MODEL_NAME = \"facebook/wav2vec2-base\"\n",
    "FEATURE_EXTRACTOR = Wav2Vec2FeatureExtractor.from_pretrained(AUDIO_MODEL_NAME)\n",
    "\n",
    "print(f\"ğŸ¯ Device: {DEVICE}\")\n",
    "\n",
    "# =========================\n",
    "# 1. Dataset Preparation (ê°œì„ )\n",
    "# =========================\n",
    "def collect_samples(root, exts):\n",
    "    \"\"\"ëª¨ë“  ìƒ˜í”Œ ìˆ˜ì§‘\"\"\"\n",
    "    samples = []\n",
    "\n",
    "    for class_dir in sorted(os.listdir(root)):\n",
    "        class_path = os.path.join(root, class_dir)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "\n",
    "        for root_dir, _, files in os.walk(class_path):\n",
    "            for filename in files:\n",
    "                if any(filename.lower().endswith(ext) for ext in exts):\n",
    "                    file_path = os.path.join(root_dir, filename)\n",
    "                    samples.append((class_dir, file_path))\n",
    "\n",
    "    print(f\"  â†’ {len(samples)} samples, {len(set(s[0] for s in samples))} classes\")\n",
    "    return samples\n",
    "\n",
    "\n",
    "def sample_balanced(samples, max_total_samples):\n",
    "    \"\"\"\n",
    "    í´ë˜ìŠ¤ë³„ ê· ë“± ìƒ˜í”Œë§\n",
    "    ê° í´ë˜ìŠ¤ë‹¹ max_samples_per_class = max_total_samples / num_classes\n",
    "    \"\"\"\n",
    "    # í´ë˜ìŠ¤ë³„ ê·¸ë£¹í™”\n",
    "    class_samples = defaultdict(list)\n",
    "    for label, path in samples:\n",
    "        class_samples[label].append(path)\n",
    "    \n",
    "    num_classes = len(class_samples)\n",
    "    max_per_class = max_total_samples // num_classes\n",
    "    \n",
    "    print(f\"  ğŸ¯ Target: {max_total_samples} samples\")\n",
    "    print(f\"  ğŸ“Š {num_classes} classes â†’ max {max_per_class} per class\")\n",
    "    \n",
    "    # í´ë˜ìŠ¤ë³„ ìƒ˜í”Œë§\n",
    "    sampled = []\n",
    "    for label, paths in class_samples.items():\n",
    "        n_samples = min(len(paths), max_per_class)\n",
    "        selected = random.sample(paths, n_samples)\n",
    "        sampled.extend([(label, p) for p in selected])\n",
    "        print(f\"    {label}: {n_samples}/{len(paths)}\")\n",
    "    \n",
    "    print(f\"  âœ… Total sampled: {len(sampled)}\")\n",
    "    return sampled\n",
    "\n",
    "\n",
    "def split_and_copy(samples, task_name):\n",
    "    \"\"\"8:1:1 split í›„ ë³µì‚¬\"\"\"\n",
    "    random.shuffle(samples)\n",
    "    class_samples = defaultdict(list)\n",
    "\n",
    "    for label, path in samples:\n",
    "        class_samples[label].append(path)\n",
    "\n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        os.makedirs(os.path.join(WORK_DIR, split, task_name), exist_ok=True)\n",
    "\n",
    "    for label, paths in class_samples.items():\n",
    "        n = len(paths)\n",
    "        n_train = int(n * 0.8)\n",
    "        n_val = int(n * 0.1)\n",
    "\n",
    "        splits = {\n",
    "            \"train\": paths[:n_train],\n",
    "            \"val\": paths[n_train:n_train+n_val],\n",
    "            \"test\": paths[n_train+n_val:]\n",
    "        }\n",
    "\n",
    "        for split_name, split_paths in splits.items():\n",
    "            for src in tqdm(split_paths, desc=f\"{task_name}/{split_name}/{label}\", leave=False):\n",
    "                dst_dir = os.path.join(WORK_DIR, split_name, task_name, label)\n",
    "                os.makedirs(dst_dir, exist_ok=True)\n",
    "\n",
    "                dst_path = os.path.join(\n",
    "                    dst_dir,\n",
    "                    f\"{label}_{os.path.basename(src)}\"\n",
    "                )\n",
    "                shutil.copy(src, dst_path)\n",
    "\n",
    "\n",
    "def prepare_dataset():\n",
    "    \"\"\"ë°ì´í„°ì…‹ ì¤€ë¹„ (ìƒ˜í”Œ ì œí•œ ì ìš©)\"\"\"\n",
    "    if os.path.exists(WORK_DIR):\n",
    "        shutil.rmtree(WORK_DIR)\n",
    "\n",
    "    print(\"\\nğŸ“¦ Collecting behavior...\")\n",
    "    behavior_all = collect_samples(BEHAVIOR_ROOT, ['.jpg', '.png', '.jpeg'])\n",
    "    behavior = sample_balanced(behavior_all, MAX_SAMPLES_BEHAVIOR)\n",
    "\n",
    "    print(\"\\nğŸ“¦ Collecting emotion...\")\n",
    "    emotion_all = collect_samples(EMOTION_ROOT, ['.jpg', '.png', '.jpeg'])\n",
    "    emotion = sample_balanced(emotion_all, MAX_SAMPLES_EMOTION)\n",
    "\n",
    "    print(\"\\nğŸ“¦ Collecting sound...\")\n",
    "    sound = collect_samples(SOUND_ROOT, ['.wav', '.mp3', '.m4a'])\n",
    "    print(\"  â„¹ï¸  Sound: Using all samples (no limit)\")\n",
    "\n",
    "    print(\"\\nğŸ“‹ Splitting & Copying...\")\n",
    "    split_and_copy(behavior, \"behavior\")\n",
    "    split_and_copy(emotion, \"emotion\")\n",
    "    split_and_copy(sound, \"sound\")\n",
    "\n",
    "    print(\"\\nâœ… Dataset ready\")\n",
    "\n",
    "# =========================\n",
    "# 2. Dataset Classes\n",
    "# =========================\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, task_dir, augment=False):\n",
    "        self.samples = []\n",
    "        self.label_to_id = {}\n",
    "\n",
    "        for label in sorted(os.listdir(task_dir)):\n",
    "            label_dir = os.path.join(task_dir, label)\n",
    "            if not os.path.isdir(label_dir):\n",
    "                continue\n",
    "\n",
    "            self.label_to_id[label] = len(self.label_to_id)\n",
    "\n",
    "            for file in os.listdir(label_dir):\n",
    "                if file.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
    "                    self.samples.append((os.path.join(label_dir, file), label))\n",
    "\n",
    "        print(f\"  ğŸ“Š {os.path.basename(task_dir)}: {len(self.samples)} samples, {len(self.label_to_id)} classes\")\n",
    "\n",
    "        if augment:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize((256,256)),\n",
    "                transforms.RandomCrop(224),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ColorJitter(0.2, 0.2, 0.2),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize((224,224)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "            ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.samples[idx]\n",
    "        img = Image.open(path).convert(\"RGB\")\n",
    "        img = self.transform(img)\n",
    "        return img, self.label_to_id[label]\n",
    "\n",
    "\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, task_dir):\n",
    "        self.samples = []\n",
    "        self.label_to_id = {}\n",
    "\n",
    "        for label in sorted(os.listdir(task_dir)):\n",
    "            label_dir = os.path.join(task_dir, label)\n",
    "            if not os.path.isdir(label_dir):\n",
    "                continue\n",
    "\n",
    "            self.label_to_id[label] = len(self.label_to_id)\n",
    "\n",
    "            for file in os.listdir(label_dir):\n",
    "                if file.lower().endswith(('.wav','.mp3','.m4a')):\n",
    "                    self.samples.append((os.path.join(label_dir,file), label))\n",
    "\n",
    "        print(f\"  ğŸ“Š {os.path.basename(task_dir)}: {len(self.samples)} samples, {len(self.label_to_id)} classes\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.samples[idx]\n",
    "\n",
    "        try:\n",
    "            waveform, _ = librosa.load(path, sr=SR, mono=True)\n",
    "        except:\n",
    "            waveform = np.zeros(MAX_AUDIO_LEN)\n",
    "\n",
    "        if len(waveform) > MAX_AUDIO_LEN:\n",
    "            waveform = waveform[:MAX_AUDIO_LEN]\n",
    "        else:\n",
    "            waveform = np.pad(waveform,(0,MAX_AUDIO_LEN-len(waveform)))\n",
    "\n",
    "        inputs = FEATURE_EXTRACTOR(waveform, sampling_rate=SR, return_tensors=\"pt\")\n",
    "        return inputs.input_values.squeeze(0), self.label_to_id[label]\n",
    "\n",
    "# =========================\n",
    "# 3. Models\n",
    "# =========================\n",
    "class VideoMultiHead(nn.Module):\n",
    "    def __init__(self, num_b, num_e):\n",
    "        super().__init__()\n",
    "        backbone = resnet34(weights=ResNet34_Weights.IMAGENET1K_V1)\n",
    "        self.backbone = nn.Sequential(*list(backbone.children())[:-1])\n",
    "        self.behavior_head = nn.Linear(512, num_b)\n",
    "        self.emotion_head = nn.Linear(512, num_e)\n",
    "\n",
    "    def forward(self, x, task):\n",
    "        feat = self.backbone(x).squeeze(-1).squeeze(-1)\n",
    "        if task == \"behavior\":\n",
    "            return self.behavior_head(feat)\n",
    "        else:\n",
    "            return self.emotion_head(feat)\n",
    "\n",
    "\n",
    "class AudioModel(nn.Module):\n",
    "    def __init__(self, num_classes, freeze_backbone=True):\n",
    "        super().__init__()\n",
    "        self.model = Wav2Vec2ForSequenceClassification.from_pretrained(\n",
    "            AUDIO_MODEL_NAME,\n",
    "            num_labels=num_classes,\n",
    "            ignore_mismatched_sizes=True\n",
    "        )\n",
    "\n",
    "        if freeze_backbone:\n",
    "            for param in self.model.wav2vec2.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(input_values=x).logits\n",
    "\n",
    "# =========================\n",
    "# 4. Training (ì§„í–‰ ìƒí™© ì¶”ì  ì¶”ê°€)\n",
    "# =========================\n",
    "def train():\n",
    "    prepare_dataset()\n",
    "\n",
    "    print(\"\\nğŸ”„ Loading datasets...\")\n",
    "    behavior_train = ImageDataset(os.path.join(WORK_DIR,\"train\",\"behavior\"), augment=True)\n",
    "    behavior_val = ImageDataset(os.path.join(WORK_DIR,\"val\",\"behavior\"), augment=False)\n",
    "    \n",
    "    emotion_train = ImageDataset(os.path.join(WORK_DIR,\"train\",\"emotion\"), augment=True)\n",
    "    emotion_val = ImageDataset(os.path.join(WORK_DIR,\"val\",\"emotion\"), augment=False)\n",
    "    \n",
    "    sound_train = AudioDataset(os.path.join(WORK_DIR,\"train\",\"sound\"))\n",
    "    sound_val = AudioDataset(os.path.join(WORK_DIR,\"val\",\"sound\"))\n",
    "\n",
    "    behavior_train_loader = DataLoader(behavior_train, BATCH_SIZE, True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "    behavior_val_loader = DataLoader(behavior_val, BATCH_SIZE, False, num_workers=NUM_WORKERS//2, pin_memory=True)\n",
    "    \n",
    "    emotion_train_loader = DataLoader(emotion_train, BATCH_SIZE, True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "    emotion_val_loader = DataLoader(emotion_val, BATCH_SIZE, False, num_workers=NUM_WORKERS//2, pin_memory=True)\n",
    "    \n",
    "    sound_train_loader = DataLoader(sound_train, BATCH_SIZE, True, num_workers=2, pin_memory=True)\n",
    "    sound_val_loader = DataLoader(sound_val, BATCH_SIZE, False, num_workers=2, pin_memory=True)\n",
    "\n",
    "    print(f\"\\nğŸ“¦ DataLoaders:\")\n",
    "    print(f\"  Behavior: {len(behavior_train_loader)} train batches, {len(behavior_val_loader)} val batches\")\n",
    "    print(f\"  Emotion: {len(emotion_train_loader)} train batches, {len(emotion_val_loader)} val batches\")\n",
    "    print(f\"  Sound: {len(sound_train_loader)} train batches, {len(sound_val_loader)} val batches\")\n",
    "\n",
    "    # ëª¨ë¸\n",
    "    video_model = VideoMultiHead(\n",
    "        len(behavior_train.label_to_id),\n",
    "        len(emotion_train.label_to_id)\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    audio_model = AudioModel(\n",
    "        len(sound_train.label_to_id),\n",
    "        # freeze_backbone=True\n",
    "        freeze_backbone=False\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    # Optimizer\n",
    "    video_opt = torch.optim.AdamW(video_model.parameters(), lr=LR_VIDEO, weight_decay=0.01)\n",
    "    audio_opt = torch.optim.AdamW(audio_model.parameters(), lr=LR_AUDIO, weight_decay=0.01)\n",
    "\n",
    "    # Scaler\n",
    "    video_scaler = torch.amp.GradScaler(\"cuda\")\n",
    "    audio_scaler = torch.amp.GradScaler(\"cuda\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    best_avg_acc = 0\n",
    "    history = []\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        video_model.train()\n",
    "        audio_model.train()\n",
    "\n",
    "        # Taskë³„ loss ëˆ„ì \n",
    "        loss_b_total, loss_e_total, loss_s_total = 0, 0, 0\n",
    "\n",
    "        # -------- 1. Behavior --------\n",
    "        print(f\"\\nğŸ¾ Training Behavior...\")\n",
    "        for imgs, labels in tqdm(behavior_train_loader, desc=\"Behavior\", leave=False):\n",
    "            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "            with torch.amp.autocast(\"cuda\"):\n",
    "                logits = video_model(imgs, \"behavior\")\n",
    "                loss = criterion(logits, labels) * LOSS_WEIGHTS[\"behavior\"]\n",
    "\n",
    "            video_opt.zero_grad()\n",
    "            video_scaler.scale(loss).backward()\n",
    "            video_scaler.step(video_opt)\n",
    "            video_scaler.update()\n",
    "\n",
    "            loss_b_total += loss.item()\n",
    "\n",
    "        avg_loss_b = loss_b_total / len(behavior_train_loader)\n",
    "        print(f\"  â†’ Avg Loss: {avg_loss_b:.4f}\")\n",
    "\n",
    "        # -------- 2. Emotion --------\n",
    "        print(f\"\\nğŸ˜Š Training Emotion...\")\n",
    "        for imgs, labels in tqdm(emotion_train_loader, desc=\"Emotion\", leave=False):\n",
    "            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "            with torch.amp.autocast(\"cuda\"):\n",
    "                logits = video_model(imgs, \"emotion\")\n",
    "                loss = criterion(logits, labels) * LOSS_WEIGHTS[\"emotion\"]\n",
    "\n",
    "            video_opt.zero_grad()\n",
    "            video_scaler.scale(loss).backward()\n",
    "            video_scaler.step(video_opt)\n",
    "            video_scaler.update()\n",
    "\n",
    "            loss_e_total += loss.item()\n",
    "\n",
    "        avg_loss_e = loss_e_total / len(emotion_train_loader)\n",
    "        print(f\"  â†’ Avg Loss: {avg_loss_e:.4f}\")\n",
    "\n",
    "        # -------- 3. Sound --------\n",
    "        print(f\"\\nğŸ”Š Training Sound...\")\n",
    "        for audios, labels in tqdm(sound_train_loader, desc=\"Sound\", leave=False):\n",
    "            audios, labels = audios.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "            with torch.amp.autocast(\"cuda\"):\n",
    "                logits = audio_model(audios)\n",
    "                loss = criterion(logits, labels) * LOSS_WEIGHTS[\"sound\"]\n",
    "\n",
    "            audio_opt.zero_grad()\n",
    "            audio_scaler.scale(loss).backward()\n",
    "            audio_scaler.step(audio_opt)\n",
    "            audio_scaler.update()\n",
    "\n",
    "            loss_s_total += loss.item()\n",
    "\n",
    "        avg_loss_s = loss_s_total / len(sound_train_loader)\n",
    "        print(f\"  â†’ Avg Loss: {avg_loss_s:.4f}\")\n",
    "\n",
    "        # -------- Validation --------\n",
    "        print(f\"\\nğŸ” Validation...\")\n",
    "        video_model.eval()\n",
    "        audio_model.eval()\n",
    "\n",
    "        # Behavior Val\n",
    "        correct_b, total_b = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in tqdm(behavior_val_loader, desc=\"Val Behavior\", leave=False):\n",
    "                imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "                logits = video_model(imgs, \"behavior\")\n",
    "                pred = logits.argmax(-1)\n",
    "                correct_b += (pred == labels).sum().item()\n",
    "                total_b += labels.size(0)\n",
    "        acc_b = correct_b / total_b\n",
    "\n",
    "        # Emotion Val\n",
    "        correct_e, total_e = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in tqdm(emotion_val_loader, desc=\"Val Emotion\", leave=False):\n",
    "                imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "                logits = video_model(imgs, \"emotion\")\n",
    "                pred = logits.argmax(-1)\n",
    "                correct_e += (pred == labels).sum().item()\n",
    "                total_e += labels.size(0)\n",
    "        acc_e = correct_e / total_e\n",
    "\n",
    "        # Sound Val\n",
    "        correct_s, total_s = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for audios, labels in tqdm(sound_val_loader, desc=\"Val Sound\", leave=False):\n",
    "                audios, labels = audios.to(DEVICE), labels.to(DEVICE)\n",
    "                logits = audio_model(audios)\n",
    "                pred = logits.argmax(-1)\n",
    "                correct_s += (pred == labels).sum().item()\n",
    "                total_s += labels.size(0)\n",
    "        acc_s = correct_s / total_s\n",
    "\n",
    "        avg_acc = (acc_b + acc_e + acc_s) / 3\n",
    "\n",
    "        print(f\"\\nğŸ“Š Results:\")\n",
    "        print(f\"  Behavior: Loss {avg_loss_b:.4f} | Acc {acc_b:.4f} ({acc_b*100:.1f}%)\")\n",
    "        print(f\"  Emotion:  Loss {avg_loss_e:.4f} | Acc {acc_e:.4f} ({acc_e*100:.1f}%)\")\n",
    "        print(f\"  Sound:    Loss {avg_loss_s:.4f} | Acc {acc_s:.4f} ({acc_s*100:.1f}%)\")\n",
    "        print(f\"  Average Acc: {avg_acc:.4f} ({avg_acc*100:.1f}%)\")\n",
    "\n",
    "        # History ì €ì¥\n",
    "        history.append({\n",
    "            'epoch': epoch+1,\n",
    "            'loss_b': avg_loss_b,\n",
    "            'loss_e': avg_loss_e,\n",
    "            'loss_s': avg_loss_s,\n",
    "            'acc_b': acc_b,\n",
    "            'acc_e': acc_e,\n",
    "            'acc_s': acc_s,\n",
    "            'acc_avg': avg_acc\n",
    "        })\n",
    "\n",
    "        # Best ëª¨ë¸ ì €ì¥\n",
    "        if avg_acc > best_avg_acc:\n",
    "            best_avg_acc = avg_acc\n",
    "            torch.save({\n",
    "                \"video_model\": video_model.state_dict(),\n",
    "                \"audio_model\": audio_model.state_dict(),\n",
    "                \"behavior_label_to_id\": behavior_train.label_to_id,\n",
    "                \"emotion_label_to_id\": emotion_train.label_to_id,\n",
    "                \"sound_label_to_id\": sound_train.label_to_id,\n",
    "                \"best_epoch\": epoch+1,\n",
    "                \"best_acc\": best_avg_acc,\n",
    "                \"history\": history\n",
    "            }, \"pet_omni_best.pth\")\n",
    "            print(f\"  ğŸ’¾ Saved new best model! (Acc: {best_avg_acc:.4f})\")\n",
    "\n",
    "    # ê·¸ë˜í”„\n",
    "    print(\"\\nğŸ“ˆ Generating training history plot...\")\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    plt.subplot(131)\n",
    "    plt.plot([h['acc_b'] for h in history], 'b-', label='Behavior', linewidth=2)\n",
    "    plt.xlabel('Epoch'); plt.ylabel('Accuracy')\n",
    "    plt.title('Behavior Accuracy'); plt.ylim(0, 1); plt.grid(True, alpha=0.3); plt.legend()\n",
    "\n",
    "    plt.subplot(132)\n",
    "    plt.plot([h['acc_e'] for h in history], 'r-', label='Emotion', linewidth=2)\n",
    "    plt.xlabel('Epoch'); plt.ylabel('Accuracy')\n",
    "    plt.title('Emotion Accuracy'); plt.ylim(0, 1); plt.grid(True, alpha=0.3); plt.legend()\n",
    "\n",
    "    plt.subplot(133)\n",
    "    plt.plot([h['acc_s'] for h in history], 'g-', label='Sound', linewidth=2)\n",
    "    plt.xlabel('Epoch'); plt.ylabel('Accuracy')\n",
    "    plt.title('Sound Accuracy'); plt.ylim(0, 1); plt.grid(True, alpha=0.3); plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('pet_omni_history.png', dpi=150, bbox_inches='tight')\n",
    "    print(\"  âœ… Saved: pet_omni_history.png\")\n",
    "\n",
    "    print(f\"\\nğŸ‰ Training Finished!\")\n",
    "    print(f\"  Best Average Acc: {best_avg_acc:.4f} ({best_avg_acc*100:.1f}%)\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ac7284",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cap/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ Device: cuda:1\n",
      "\n",
      "ğŸ“¦ Collecting behavior...\n",
      "  â†’ 757113 samples, 25 classes\n",
      "  ğŸ¯ Target: 100000 samples\n",
      "  ğŸ“Š 25 classes â†’ max 4000 per class\n",
      "    CAT_ARCH: 2296/2296\n",
      "    CAT_ARMSTRETCH: 4000/38483\n",
      "    CAT_FOOTPUSH: 4000/9517\n",
      "    CAT_GETDOWN: 4000/13421\n",
      "    CAT_GROOMING: 4000/65029\n",
      "    CAT_HEADING: 4000/11237\n",
      "    CAT_LAYDOWN: 4000/21474\n",
      "    CAT_LYING: 4000/12119\n",
      "    CAT_ROLL: 4000/8513\n",
      "    CAT_SITDOWN: 4000/18401\n",
      "    CAT_TAILING: 4000/36960\n",
      "    CAT_WALKRUN: 4000/30498\n",
      "    DOG_BODYLOWER: 4000/79772\n",
      "    DOG_BODYSCRATCH: 4000/15783\n",
      "    DOG_BODYSHAKE: 4000/15296\n",
      "    DOG_FEETUP: 4000/34365\n",
      "    DOG_FOOTUP: 4000/52506\n",
      "    DOG_HEADING: 4000/19052\n",
      "    DOG_LYING: 4000/32129\n",
      "    DOG_MOUNTING: 4000/5211\n",
      "    DOG_SIT: 4000/79182\n",
      "    DOG_TAILING: 4000/35824\n",
      "    DOG_TAILLOW: 4000/8376\n",
      "    DOG_TURN: 4000/21554\n",
      "    DOG_WALKRUN: 4000/90115\n",
      "  âœ… Total sampled: 98296\n",
      "\n",
      "ğŸ“¦ Collecting emotion...\n",
      "  â†’ 69113 samples, 10 classes\n",
      "  ğŸ¯ Target: 100000 samples\n",
      "  ğŸ“Š 10 classes â†’ max 10000 per class\n",
      "    cat_attentive: 997/997\n",
      "    cat_happy: 1221/1221\n",
      "    cat_relaxed: 2999/2999\n",
      "    cat_sad: 171/171\n",
      "    dog_angry: 8589/8589\n",
      "    dog_anxious : 10000/11590\n",
      "    dog_confused: 3286/3286\n",
      "    dog_happy: 10000/17355\n",
      "    dog_relaxed: 8699/8699\n",
      "    dog_sad: 10000/14206\n",
      "  âœ… Total sampled: 55962\n",
      "\n",
      "ğŸ“¦ Collecting sound...\n",
      "  â†’ 1248 samples, 16 classes\n",
      "  â„¹ï¸  Sound: Using all samples (no limit)\n",
      "\n",
      "ğŸ“‹ Splitting & Copying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Dataset ready\n",
      "\n",
      "ğŸ”„ Loading datasets...\n",
      "  ğŸ“Š behavior: 11864 samples, 25 classes\n",
      "  ğŸ“Š behavior: 5301 samples, 25 classes\n",
      "  ğŸ“Š emotion: 44766 samples, 10 classes\n",
      "  ğŸ“Š emotion: 5592 samples, 10 classes\n",
      "  ğŸ“Š sound: 995 samples, 16 classes\n",
      "  ğŸ“Š sound: 121 samples, 16 classes\n",
      "\n",
      "ğŸ“¦ DataLoaders:\n",
      "  Behavior: 742 train batches, 332 val batches\n",
      "  Emotion: 2798 train batches, 350 val batches\n",
      "  Sound: 63 train batches, 8 val batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 211/211 [00:00<00:00, 482.28it/s, Materializing param=wav2vec2.masked_spec_embed]                                            \n",
      "\u001b[1mWav2Vec2ForSequenceClassification LOAD REPORT\u001b[0m from: facebook/wav2vec2-base\n",
      "Key                          | Status     | \n",
      "-----------------------------+------------+-\n",
      "project_q.weight             | UNEXPECTED | \n",
      "project_hid.bias             | UNEXPECTED | \n",
      "quantizer.codevectors        | UNEXPECTED | \n",
      "quantizer.weight_proj.bias   | UNEXPECTED | \n",
      "quantizer.weight_proj.weight | UNEXPECTED | \n",
      "project_q.bias               | UNEXPECTED | \n",
      "project_hid.weight           | UNEXPECTED | \n",
      "projector.bias               | MISSING    | \n",
      "classifier.bias              | MISSING    | \n",
      "projector.weight             | MISSING    | \n",
      "classifier.weight            | MISSING    | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\u001b[3m\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Epoch 1/50\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.9263\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.7788\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.5646\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 1.9263 | Acc 0.4886 (48.9%)\n",
      "  Emotion:  Loss 0.7788 | Acc 0.6645 (66.5%)\n",
      "  Sound:    Loss 1.5646 | Acc 0.2562 (25.6%)\n",
      "  Average Acc: 0.4698 (47.0%)\n",
      "  ğŸ’¾ Saved new best model! (Acc: 0.4698)\n",
      "\n",
      "============================================================\n",
      "Epoch 2/50\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.1526\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.6564\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.3772\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 1.1526 | Acc 0.5757 (57.6%)\n",
      "  Emotion:  Loss 0.6564 | Acc 0.6744 (67.4%)\n",
      "  Sound:    Loss 1.3772 | Acc 0.3884 (38.8%)\n",
      "  Average Acc: 0.5462 (54.6%)\n",
      "  ğŸ’¾ Saved new best model! (Acc: 0.5462)\n",
      "\n",
      "============================================================\n",
      "Epoch 3/50\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.8139\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.5916\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.2338\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 0.8139 | Acc 0.6180 (61.8%)\n",
      "  Emotion:  Loss 0.5916 | Acc 0.6774 (67.7%)\n",
      "  Sound:    Loss 1.2338 | Acc 0.6198 (62.0%)\n",
      "  Average Acc: 0.6384 (63.8%)\n",
      "  ğŸ’¾ Saved new best model! (Acc: 0.6384)\n",
      "\n",
      "============================================================\n",
      "Epoch 4/50\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.5734\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.5413\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.1018\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 0.5734 | Acc 0.6337 (63.4%)\n",
      "  Emotion:  Loss 0.5413 | Acc 0.6831 (68.3%)\n",
      "  Sound:    Loss 1.1018 | Acc 0.5289 (52.9%)\n",
      "  Average Acc: 0.6152 (61.5%)\n",
      "\n",
      "============================================================\n",
      "Epoch 5/50\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.4501\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.4972\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 1.0045\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 0.4501 | Acc 0.6403 (64.0%)\n",
      "  Emotion:  Loss 0.4972 | Acc 0.7055 (70.5%)\n",
      "  Sound:    Loss 1.0045 | Acc 0.5455 (54.5%)\n",
      "  Average Acc: 0.6304 (63.0%)\n",
      "\n",
      "============================================================\n",
      "Epoch 6/50\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.3503\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.4590\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.9120\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 0.3503 | Acc 0.6465 (64.6%)\n",
      "  Emotion:  Loss 0.4590 | Acc 0.7135 (71.4%)\n",
      "  Sound:    Loss 0.9120 | Acc 0.6198 (62.0%)\n",
      "  Average Acc: 0.6599 (66.0%)\n",
      "  ğŸ’¾ Saved new best model! (Acc: 0.6599)\n",
      "\n",
      "============================================================\n",
      "Epoch 7/50\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.2798\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.4282\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.8226\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 0.2798 | Acc 0.6555 (65.6%)\n",
      "  Emotion:  Loss 0.4282 | Acc 0.7142 (71.4%)\n",
      "  Sound:    Loss 0.8226 | Acc 0.6529 (65.3%)\n",
      "  Average Acc: 0.6742 (67.4%)\n",
      "  ğŸ’¾ Saved new best model! (Acc: 0.6742)\n",
      "\n",
      "============================================================\n",
      "Epoch 8/50\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.2686\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.3982\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.7464\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 0.2686 | Acc 0.6489 (64.9%)\n",
      "  Emotion:  Loss 0.3982 | Acc 0.7225 (72.2%)\n",
      "  Sound:    Loss 0.7464 | Acc 0.6116 (61.2%)\n",
      "  Average Acc: 0.6610 (66.1%)\n",
      "\n",
      "============================================================\n",
      "Epoch 9/50\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.2121\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.3757\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.6934\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 0.2121 | Acc 0.6520 (65.2%)\n",
      "  Emotion:  Loss 0.3757 | Acc 0.7255 (72.6%)\n",
      "  Sound:    Loss 0.6934 | Acc 0.6942 (69.4%)\n",
      "  Average Acc: 0.6906 (69.1%)\n",
      "  ğŸ’¾ Saved new best model! (Acc: 0.6906)\n",
      "\n",
      "============================================================\n",
      "Epoch 10/50\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.2010\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.3568\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.6165\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 0.2010 | Acc 0.6557 (65.6%)\n",
      "  Emotion:  Loss 0.3568 | Acc 0.7396 (74.0%)\n",
      "  Sound:    Loss 0.6165 | Acc 0.6612 (66.1%)\n",
      "  Average Acc: 0.6855 (68.6%)\n",
      "\n",
      "============================================================\n",
      "Epoch 11/50\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.1881\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.3405\n",
      "\n",
      "ğŸ”Š Training Sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.5831\n",
      "\n",
      "ğŸ” Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Results:\n",
      "  Behavior: Loss 0.1881 | Acc 0.6557 (65.6%)\n",
      "  Emotion:  Loss 0.3405 | Acc 0.7257 (72.6%)\n",
      "  Sound:    Loss 0.5831 | Acc 0.6529 (65.3%)\n",
      "  Average Acc: 0.6781 (67.8%)\n",
      "\n",
      "============================================================\n",
      "Epoch 12/50\n",
      "============================================================\n",
      "\n",
      "ğŸ¾ Training Behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Avg Loss: 0.1842\n",
      "\n",
      "ğŸ˜Š Training Emotion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Emotion:  21%|â–ˆâ–ˆâ–       | 596/2798 [00:23<01:22, 26.58it/s]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import Wav2Vec2ForSequenceClassification, Wav2Vec2FeatureExtractor\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet34, ResNet34_Weights\n",
    "from PIL import Image\n",
    "import librosa\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# =========================\n",
    "# 0. ì„¤ì •\n",
    "# =========================\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "BEHAVIOR_ROOT = \"files/1_Animal_Behavior\"\n",
    "EMOTION_ROOT = \"files/2_Animal_emotions\"\n",
    "SOUND_ROOT = \"files/3_Animal_Sound\"\n",
    "WORK_DIR = \"files/work/omni_dataset\"\n",
    "\n",
    "# ğŸ”¥ ìƒ˜í”Œ ì œí•œ ì„¤ì •\n",
    "MAX_SAMPLES_BEHAVIOR = 100000  # Behavior ì´ ìƒ˜í”Œ ìˆ˜\n",
    "MAX_SAMPLES_EMOTION = 100000    # Emotion ì´ ìƒ˜í”Œ ìˆ˜\n",
    "# SoundëŠ” ë°ì´í„°ê°€ ì ìœ¼ë¯€ë¡œ ì „ì²´ ì‚¬ìš©\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 50\n",
    "LR_VIDEO = 1e-4\n",
    "LR_AUDIO = 1e-5\n",
    "DEVICE = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "NUM_WORKERS = 12\n",
    "SR = 16000\n",
    "MAX_AUDIO_LEN = SR * 5\n",
    "\n",
    "LOSS_WEIGHTS = {\n",
    "    \"behavior\": 1.0,\n",
    "    \"emotion\": 0.8,\n",
    "    \"sound\": 0.6\n",
    "}\n",
    "\n",
    "AUDIO_MODEL_NAME = \"facebook/wav2vec2-base\"\n",
    "FEATURE_EXTRACTOR = Wav2Vec2FeatureExtractor.from_pretrained(AUDIO_MODEL_NAME)\n",
    "\n",
    "print(f\"ğŸ¯ Device: {DEVICE}\")\n",
    "\n",
    "# =========================\n",
    "# 1. Dataset Preparation (ê°œì„ )\n",
    "# =========================\n",
    "def collect_samples(root, exts):\n",
    "    \"\"\"ëª¨ë“  ìƒ˜í”Œ ìˆ˜ì§‘\"\"\"\n",
    "    samples = []\n",
    "\n",
    "    for class_dir in sorted(os.listdir(root)):\n",
    "        class_path = os.path.join(root, class_dir)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "\n",
    "        for root_dir, _, files in os.walk(class_path):\n",
    "            for filename in files:\n",
    "                if any(filename.lower().endswith(ext) for ext in exts):\n",
    "                    file_path = os.path.join(root_dir, filename)\n",
    "                    samples.append((class_dir, file_path))\n",
    "\n",
    "    print(f\"  â†’ {len(samples)} samples, {len(set(s[0] for s in samples))} classes\")\n",
    "    return samples\n",
    "\n",
    "\n",
    "def sample_balanced(samples, max_total_samples):\n",
    "    \"\"\"\n",
    "    í´ë˜ìŠ¤ë³„ ê· ë“± ìƒ˜í”Œë§\n",
    "    ê° í´ë˜ìŠ¤ë‹¹ max_samples_per_class = max_total_samples / num_classes\n",
    "    \"\"\"\n",
    "    # í´ë˜ìŠ¤ë³„ ê·¸ë£¹í™”\n",
    "    class_samples = defaultdict(list)\n",
    "    for label, path in samples:\n",
    "        class_samples[label].append(path)\n",
    "    \n",
    "    num_classes = len(class_samples)\n",
    "    max_per_class = max_total_samples // num_classes\n",
    "    \n",
    "    print(f\"  ğŸ¯ Target: {max_total_samples} samples\")\n",
    "    print(f\"  ğŸ“Š {num_classes} classes â†’ max {max_per_class} per class\")\n",
    "    \n",
    "    # í´ë˜ìŠ¤ë³„ ìƒ˜í”Œë§\n",
    "    sampled = []\n",
    "    for label, paths in class_samples.items():\n",
    "        n_samples = min(len(paths), max_per_class)\n",
    "        selected = random.sample(paths, n_samples)\n",
    "        sampled.extend([(label, p) for p in selected])\n",
    "        print(f\"    {label}: {n_samples}/{len(paths)}\")\n",
    "    \n",
    "    print(f\"  âœ… Total sampled: {len(sampled)}\")\n",
    "    return sampled\n",
    "\n",
    "\n",
    "def split_and_copy(samples, task_name):\n",
    "    \"\"\"8:1:1 split í›„ ë³µì‚¬\"\"\"\n",
    "    random.shuffle(samples)\n",
    "    class_samples = defaultdict(list)\n",
    "\n",
    "    for label, path in samples:\n",
    "        class_samples[label].append(path)\n",
    "\n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        os.makedirs(os.path.join(WORK_DIR, split, task_name), exist_ok=True)\n",
    "\n",
    "    for label, paths in class_samples.items():\n",
    "        n = len(paths)\n",
    "        n_train = int(n * 0.8)\n",
    "        n_val = int(n * 0.1)\n",
    "\n",
    "        splits = {\n",
    "            \"train\": paths[:n_train],\n",
    "            \"val\": paths[n_train:n_train+n_val],\n",
    "            \"test\": paths[n_train+n_val:]\n",
    "        }\n",
    "\n",
    "        for split_name, split_paths in splits.items():\n",
    "            for src in tqdm(split_paths, desc=f\"{task_name}/{split_name}/{label}\", leave=False):\n",
    "                dst_dir = os.path.join(WORK_DIR, split_name, task_name, label)\n",
    "                os.makedirs(dst_dir, exist_ok=True)\n",
    "\n",
    "                dst_path = os.path.join(\n",
    "                    dst_dir,\n",
    "                    f\"{label}_{os.path.basename(src)}\"\n",
    "                )\n",
    "                shutil.copy(src, dst_path)\n",
    "\n",
    "\n",
    "def prepare_dataset():\n",
    "    \"\"\"ë°ì´í„°ì…‹ ì¤€ë¹„ (ìƒ˜í”Œ ì œí•œ ì ìš©)\"\"\"\n",
    "    if os.path.exists(WORK_DIR):\n",
    "        shutil.rmtree(WORK_DIR)\n",
    "\n",
    "    print(\"\\nğŸ“¦ Collecting behavior...\")\n",
    "    behavior_all = collect_samples(BEHAVIOR_ROOT, ['.jpg', '.png', '.jpeg'])\n",
    "    behavior = sample_balanced(behavior_all, MAX_SAMPLES_BEHAVIOR)\n",
    "\n",
    "    print(\"\\nğŸ“¦ Collecting emotion...\")\n",
    "    emotion_all = collect_samples(EMOTION_ROOT, ['.jpg', '.png', '.jpeg'])\n",
    "    emotion = sample_balanced(emotion_all, MAX_SAMPLES_EMOTION)\n",
    "\n",
    "    print(\"\\nğŸ“¦ Collecting sound...\")\n",
    "    sound = collect_samples(SOUND_ROOT, ['.wav', '.mp3', '.m4a'])\n",
    "    print(\"  â„¹ï¸  Sound: Using all samples (no limit)\")\n",
    "\n",
    "    print(\"\\nğŸ“‹ Splitting & Copying...\")\n",
    "    split_and_copy(behavior, \"behavior\")\n",
    "    split_and_copy(emotion, \"emotion\")\n",
    "    split_and_copy(sound, \"sound\")\n",
    "\n",
    "    print(\"\\nâœ… Dataset ready\")\n",
    "\n",
    "# =========================\n",
    "# 2. Dataset Classes\n",
    "# =========================\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, task_dir, augment=False):\n",
    "        self.samples = []\n",
    "        self.label_to_id = {}\n",
    "\n",
    "        for label in sorted(os.listdir(task_dir)):\n",
    "            label_dir = os.path.join(task_dir, label)\n",
    "            if not os.path.isdir(label_dir):\n",
    "                continue\n",
    "\n",
    "            self.label_to_id[label] = len(self.label_to_id)\n",
    "\n",
    "            for file in os.listdir(label_dir):\n",
    "                if file.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
    "                    self.samples.append((os.path.join(label_dir, file), label))\n",
    "\n",
    "        print(f\"  ğŸ“Š {os.path.basename(task_dir)}: {len(self.samples)} samples, {len(self.label_to_id)} classes\")\n",
    "\n",
    "        if augment:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize((256,256)),\n",
    "                transforms.RandomCrop(224),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ColorJitter(0.2, 0.2, 0.2),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize((224,224)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "            ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.samples[idx]\n",
    "        img = Image.open(path).convert(\"RGB\")\n",
    "        img = self.transform(img)\n",
    "        return img, self.label_to_id[label]\n",
    "\n",
    "\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, task_dir):\n",
    "        self.samples = []\n",
    "        self.label_to_id = {}\n",
    "\n",
    "        for label in sorted(os.listdir(task_dir)):\n",
    "            label_dir = os.path.join(task_dir, label)\n",
    "            if not os.path.isdir(label_dir):\n",
    "                continue\n",
    "\n",
    "            self.label_to_id[label] = len(self.label_to_id)\n",
    "\n",
    "            for file in os.listdir(label_dir):\n",
    "                if file.lower().endswith(('.wav','.mp3','.m4a')):\n",
    "                    self.samples.append((os.path.join(label_dir,file), label))\n",
    "\n",
    "        print(f\"  ğŸ“Š {os.path.basename(task_dir)}: {len(self.samples)} samples, {len(self.label_to_id)} classes\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.samples[idx]\n",
    "\n",
    "        try:\n",
    "            waveform, _ = librosa.load(path, sr=SR, mono=True)\n",
    "        except:\n",
    "            waveform = np.zeros(MAX_AUDIO_LEN)\n",
    "\n",
    "        if len(waveform) > MAX_AUDIO_LEN:\n",
    "            waveform = waveform[:MAX_AUDIO_LEN]\n",
    "        else:\n",
    "            waveform = np.pad(waveform,(0,MAX_AUDIO_LEN-len(waveform)))\n",
    "\n",
    "        inputs = FEATURE_EXTRACTOR(waveform, sampling_rate=SR, return_tensors=\"pt\")\n",
    "        return inputs.input_values.squeeze(0), self.label_to_id[label]\n",
    "\n",
    "# =========================\n",
    "# 3. Models\n",
    "# =========================\n",
    "class VideoMultiBackbone(nn.Module):\n",
    "    def __init__(self, num_b, num_e):\n",
    "        super().__init__()\n",
    "\n",
    "        # ğŸ”µ Behavior Backbone\n",
    "        backbone_b = resnet34(weights=ResNet34_Weights.IMAGENET1K_V1)\n",
    "        self.behavior_backbone = nn.Sequential(*list(backbone_b.children())[:-1])\n",
    "        self.behavior_head = nn.Linear(512, num_b)\n",
    "\n",
    "        # ğŸ”´ Emotion Backbone\n",
    "        backbone_e = resnet34(weights=ResNet34_Weights.IMAGENET1K_V1)\n",
    "        self.emotion_backbone = nn.Sequential(*list(backbone_e.children())[:-1])\n",
    "        self.emotion_head = nn.Linear(512, num_e)\n",
    "\n",
    "    def forward(self, x, task):\n",
    "\n",
    "        if task == \"behavior\":\n",
    "            feat = self.behavior_backbone(x)\n",
    "            feat = feat.squeeze(-1).squeeze(-1)\n",
    "            return self.behavior_head(feat)\n",
    "\n",
    "        elif task == \"emotion\":\n",
    "            feat = self.emotion_backbone(x)\n",
    "            feat = feat.squeeze(-1).squeeze(-1)\n",
    "            return self.emotion_head(feat)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Task must be 'behavior' or 'emotion'\")\n",
    "\n",
    "class AudioModel(nn.Module):\n",
    "    def __init__(self, num_classes, freeze_backbone=True):\n",
    "        super().__init__()\n",
    "        self.model = Wav2Vec2ForSequenceClassification.from_pretrained(\n",
    "            AUDIO_MODEL_NAME,\n",
    "            num_labels=num_classes,\n",
    "            ignore_mismatched_sizes=True\n",
    "        )\n",
    "\n",
    "        if freeze_backbone:\n",
    "            for param in self.model.wav2vec2.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(input_values=x).logits\n",
    "\n",
    "# =========================\n",
    "# 4. Training (ì§„í–‰ ìƒí™© ì¶”ì  ì¶”ê°€)\n",
    "# =========================\n",
    "def train():\n",
    "    prepare_dataset()\n",
    "\n",
    "    print(\"\\nğŸ”„ Loading datasets...\")\n",
    "    behavior_train = ImageDataset(os.path.join(WORK_DIR,\"train\",\"behavior\"), augment=True)\n",
    "    behavior_val = ImageDataset(os.path.join(WORK_DIR,\"val\",\"behavior\"), augment=False)\n",
    "    \n",
    "    emotion_train = ImageDataset(os.path.join(WORK_DIR,\"train\",\"emotion\"), augment=True)\n",
    "    emotion_val = ImageDataset(os.path.join(WORK_DIR,\"val\",\"emotion\"), augment=False)\n",
    "    \n",
    "    sound_train = AudioDataset(os.path.join(WORK_DIR,\"train\",\"sound\"))\n",
    "    sound_val = AudioDataset(os.path.join(WORK_DIR,\"val\",\"sound\"))\n",
    "\n",
    "    behavior_train_loader = DataLoader(behavior_train, BATCH_SIZE, True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "    behavior_val_loader = DataLoader(behavior_val, BATCH_SIZE, False, num_workers=NUM_WORKERS//2, pin_memory=True)\n",
    "    \n",
    "    emotion_train_loader = DataLoader(emotion_train, BATCH_SIZE, True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "    emotion_val_loader = DataLoader(emotion_val, BATCH_SIZE, False, num_workers=NUM_WORKERS//2, pin_memory=True)\n",
    "    \n",
    "    sound_train_loader = DataLoader(sound_train, BATCH_SIZE, True, num_workers=2, pin_memory=True)\n",
    "    sound_val_loader = DataLoader(sound_val, BATCH_SIZE, False, num_workers=2, pin_memory=True)\n",
    "\n",
    "    print(f\"\\nğŸ“¦ DataLoaders:\")\n",
    "    print(f\"  Behavior: {len(behavior_train_loader)} train batches, {len(behavior_val_loader)} val batches\")\n",
    "    print(f\"  Emotion: {len(emotion_train_loader)} train batches, {len(emotion_val_loader)} val batches\")\n",
    "    print(f\"  Sound: {len(sound_train_loader)} train batches, {len(sound_val_loader)} val batches\")\n",
    "\n",
    "    # ëª¨ë¸\n",
    "    video_model = VideoMultiBackbone(\n",
    "        len(behavior_train.label_to_id),\n",
    "        len(emotion_train.label_to_id)\n",
    "    ).to(DEVICE)\n",
    "\n",
    "\n",
    "    audio_model = AudioModel(\n",
    "        len(sound_train.label_to_id),\n",
    "        # freeze_backbone=True\n",
    "        freeze_backbone=False\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    # Optimizer\n",
    "    video_opt = torch.optim.AdamW(video_model.parameters(), lr=LR_VIDEO, weight_decay=0.01)\n",
    "    audio_opt = torch.optim.AdamW(audio_model.parameters(), lr=LR_AUDIO, weight_decay=0.01)\n",
    "\n",
    "    # Scaler\n",
    "    video_scaler = torch.amp.GradScaler(\"cuda\")\n",
    "    audio_scaler = torch.amp.GradScaler(\"cuda\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    best_avg_acc = 0\n",
    "    history = []\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        video_model.train()\n",
    "        audio_model.train()\n",
    "\n",
    "        # Taskë³„ loss ëˆ„ì \n",
    "        loss_b_total, loss_e_total, loss_s_total = 0, 0, 0\n",
    "\n",
    "        # -------- 1. Behavior --------\n",
    "        print(f\"\\nğŸ¾ Training Behavior...\")\n",
    "        for imgs, labels in tqdm(behavior_train_loader, desc=\"Behavior\", leave=False):\n",
    "            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "            with torch.amp.autocast(\"cuda\"):\n",
    "                logits = video_model(imgs, \"behavior\")\n",
    "                loss = criterion(logits, labels) * LOSS_WEIGHTS[\"behavior\"]\n",
    "\n",
    "            video_opt.zero_grad()\n",
    "            video_scaler.scale(loss).backward()\n",
    "            video_scaler.step(video_opt)\n",
    "            video_scaler.update()\n",
    "\n",
    "            loss_b_total += loss.item()\n",
    "\n",
    "        avg_loss_b = loss_b_total / len(behavior_train_loader)\n",
    "        print(f\"  â†’ Avg Loss: {avg_loss_b:.4f}\")\n",
    "\n",
    "        # -------- 2. Emotion --------\n",
    "        print(f\"\\nğŸ˜Š Training Emotion...\")\n",
    "        for imgs, labels in tqdm(emotion_train_loader, desc=\"Emotion\", leave=False):\n",
    "            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "            with torch.amp.autocast(\"cuda\"):\n",
    "                logits = video_model(imgs, \"emotion\")\n",
    "                loss = criterion(logits, labels) * LOSS_WEIGHTS[\"emotion\"]\n",
    "\n",
    "            video_opt.zero_grad()\n",
    "            video_scaler.scale(loss).backward()\n",
    "            video_scaler.step(video_opt)\n",
    "            video_scaler.update()\n",
    "\n",
    "            loss_e_total += loss.item()\n",
    "\n",
    "        avg_loss_e = loss_e_total / len(emotion_train_loader)\n",
    "        print(f\"  â†’ Avg Loss: {avg_loss_e:.4f}\")\n",
    "\n",
    "        # -------- 3. Sound --------\n",
    "        print(f\"\\nğŸ”Š Training Sound...\")\n",
    "        for audios, labels in tqdm(sound_train_loader, desc=\"Sound\", leave=False):\n",
    "            audios, labels = audios.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "            with torch.amp.autocast(\"cuda\"):\n",
    "                logits = audio_model(audios)\n",
    "                loss = criterion(logits, labels) * LOSS_WEIGHTS[\"sound\"]\n",
    "\n",
    "            audio_opt.zero_grad()\n",
    "            audio_scaler.scale(loss).backward()\n",
    "            audio_scaler.step(audio_opt)\n",
    "            audio_scaler.update()\n",
    "\n",
    "            loss_s_total += loss.item()\n",
    "\n",
    "        avg_loss_s = loss_s_total / len(sound_train_loader)\n",
    "        print(f\"  â†’ Avg Loss: {avg_loss_s:.4f}\")\n",
    "\n",
    "        # -------- Validation --------\n",
    "        print(f\"\\nğŸ” Validation...\")\n",
    "        video_model.eval()\n",
    "        audio_model.eval()\n",
    "\n",
    "        # Behavior Val\n",
    "        correct_b, total_b = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in tqdm(behavior_val_loader, desc=\"Val Behavior\", leave=False):\n",
    "                imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "                logits = video_model(imgs, \"behavior\")\n",
    "                pred = logits.argmax(-1)\n",
    "                correct_b += (pred == labels).sum().item()\n",
    "                total_b += labels.size(0)\n",
    "        acc_b = correct_b / total_b\n",
    "\n",
    "        # Emotion Val\n",
    "        correct_e, total_e = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in tqdm(emotion_val_loader, desc=\"Val Emotion\", leave=False):\n",
    "                imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "                logits = video_model(imgs, \"emotion\")\n",
    "                pred = logits.argmax(-1)\n",
    "                correct_e += (pred == labels).sum().item()\n",
    "                total_e += labels.size(0)\n",
    "        acc_e = correct_e / total_e\n",
    "\n",
    "        # Sound Val\n",
    "        correct_s, total_s = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for audios, labels in tqdm(sound_val_loader, desc=\"Val Sound\", leave=False):\n",
    "                audios, labels = audios.to(DEVICE), labels.to(DEVICE)\n",
    "                logits = audio_model(audios)\n",
    "                pred = logits.argmax(-1)\n",
    "                correct_s += (pred == labels).sum().item()\n",
    "                total_s += labels.size(0)\n",
    "        acc_s = correct_s / total_s\n",
    "\n",
    "        avg_acc = (acc_b + acc_e + acc_s) / 3\n",
    "\n",
    "        print(f\"\\nğŸ“Š Results:\")\n",
    "        print(f\"  Behavior: Loss {avg_loss_b:.4f} | Acc {acc_b:.4f} ({acc_b*100:.1f}%)\")\n",
    "        print(f\"  Emotion:  Loss {avg_loss_e:.4f} | Acc {acc_e:.4f} ({acc_e*100:.1f}%)\")\n",
    "        print(f\"  Sound:    Loss {avg_loss_s:.4f} | Acc {acc_s:.4f} ({acc_s*100:.1f}%)\")\n",
    "        print(f\"  Average Acc: {avg_acc:.4f} ({avg_acc*100:.1f}%)\")\n",
    "\n",
    "        # History ì €ì¥\n",
    "        history.append({\n",
    "            'epoch': epoch+1,\n",
    "            'loss_b': avg_loss_b,\n",
    "            'loss_e': avg_loss_e,\n",
    "            'loss_s': avg_loss_s,\n",
    "            'acc_b': acc_b,\n",
    "            'acc_e': acc_e,\n",
    "            'acc_s': acc_s,\n",
    "            'acc_avg': avg_acc\n",
    "        })\n",
    "\n",
    "        # Best ëª¨ë¸ ì €ì¥\n",
    "        if avg_acc > best_avg_acc:\n",
    "            best_avg_acc = avg_acc\n",
    "            torch.save({\n",
    "                \"video_model\": video_model.state_dict(),\n",
    "                \"audio_model\": audio_model.state_dict(),\n",
    "                \"behavior_label_to_id\": behavior_train.label_to_id,\n",
    "                \"emotion_label_to_id\": emotion_train.label_to_id,\n",
    "                \"sound_label_to_id\": sound_train.label_to_id,\n",
    "                \"best_epoch\": epoch+1,\n",
    "                \"best_acc\": best_avg_acc,\n",
    "                \"history\": history\n",
    "            }, \"pet_omni_best.pth\")\n",
    "            print(f\"  ğŸ’¾ Saved new best model! (Acc: {best_avg_acc:.4f})\")\n",
    "\n",
    "    # ê·¸ë˜í”„\n",
    "    print(\"\\nğŸ“ˆ Generating training history plot...\")\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    plt.subplot(131)\n",
    "    plt.plot([h['acc_b'] for h in history], 'b-', label='Behavior', linewidth=2)\n",
    "    plt.xlabel('Epoch'); plt.ylabel('Accuracy')\n",
    "    plt.title('Behavior Accuracy'); plt.ylim(0, 1); plt.grid(True, alpha=0.3); plt.legend()\n",
    "\n",
    "    plt.subplot(132)\n",
    "    plt.plot([h['acc_e'] for h in history], 'r-', label='Emotion', linewidth=2)\n",
    "    plt.xlabel('Epoch'); plt.ylabel('Accuracy')\n",
    "    plt.title('Emotion Accuracy'); plt.ylim(0, 1); plt.grid(True, alpha=0.3); plt.legend()\n",
    "\n",
    "    plt.subplot(133)\n",
    "    plt.plot([h['acc_s'] for h in history], 'g-', label='Sound', linewidth=2)\n",
    "    plt.xlabel('Epoch'); plt.ylabel('Accuracy')\n",
    "    plt.title('Sound Accuracy'); plt.ylim(0, 1); plt.grid(True, alpha=0.3); plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('pet_omni_history.png', dpi=150, bbox_inches='tight')\n",
    "    print(\"  âœ… Saved: pet_omni_history.png\")\n",
    "\n",
    "    print(f\"\\nğŸ‰ Training Finished!\")\n",
    "    print(f\"  Best Average Acc: {best_avg_acc:.4f} ({best_avg_acc*100:.1f}%)\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
